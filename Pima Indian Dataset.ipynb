{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25fd2937",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "The data set we will be using is the PIMA Indian Diabetes data set. The PIMA Indians are a tribe in Arizona and more about \n",
    "their history can be found here https://en.wikipedia.org/wiki/Pima_people\n",
    "\n",
    "The data set consist of females over the age of 21. There are a total of 9 features including outcome, which is what we will be \n",
    "trying to predict - \n",
    "\n",
    "1. Number of times pregnant \n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "3. Diastolic blood pressure (mm Hg)\n",
    "4. Triceps skin fold thickness (mm)\n",
    "5. 2-Hour serum insulin (mu U/ml)\n",
    "6. Body mass index (weight in kg/(height in m)^2)\n",
    "7. Diabetes pedigree function (A function that scores the likelihood of diabetes based on family history)\n",
    "8. Age (years)\n",
    "9. Outcome (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ffa262",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55beeadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Size - (768, 9)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Importing Datasets\n",
    "\n",
    "dataset = pd.read_csv('diabetes.csv')\n",
    "display(dataset)\n",
    "print(f'\\nDataset Size - {dataset.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dd8a88",
   "metadata": {},
   "source": [
    "### Check for Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00500884",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd296c06",
   "metadata": {},
   "source": [
    "### Coorelation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edfec811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvsAAAIYCAYAAADzUSNiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAADOeUlEQVR4nOzdd3gU1dfA8e+dhJ4A6aF3CL2G3qQXQVSwoFQRqYqgiKjYFQVB+dko0hQUREB6701ASgAJvSchjTRCS/a+f+ySZMkCAZLdsO/5PE+eZGfuzJ6TOztz586dWaW1RgghhBBCCOF8DEcHIIQQQgghhMga0tgXQgghhBDCSUljXwghhBBCCCcljX0hhBBCCCGclDT2hRBCCCGEcFLS2BdCCCGEEMJJSWNfCCGEEEIIB1NKTVdKhSulDt9lvlJKTVJKnVRKBSmlamVkvdLYF0IIIYQQwvFmAu3uMb89UM7y0x/4KSMrlca+EEIIIYQQDqa13gJE36PIU8BsbbYLKKiUKnS/9UpjXwghhBBCiOyvCHAhzeuLlmn35Jpl4Yj/T7SjAxBCCCGEU1GODgDAFFY+09o4LoVOvIZ5+M1tU7TWUx5gFbb+J/eNTxr7IlOYwso7OoQsZ/gfB6B5+68dHIl9bFo5EoBmncY5OJKst3np2wC0devl4EjsY3XCLADaFejr4Eiy3qrY6QC0q/yegyOxj1VHPgegfdHXHRxJ1lt5cRIApX//wsGR2MfpF0cDENhngoMjyXp7Zgx3dAgpTJgybV2Whv2DNO7vdBEoluZ1USDkfgvJMB4hhBBCCCGyvyVAT8tTeeoDsVrr0PstJD37QgghhBBC2JCsM69n/36NbqXU70BzwFspdRH4EMgBoLX+GVgBdABOAolAn8x4XyGEEEIIIf5fMtnxtkSt9Yv3ma+BwQ+6XhnGI4QQQgghhJOSnn0hhBBCCCFsyMwbdB1FGvtCCCGEEELYkKwf/6eLyzAeIYQQQgghnJT07AshhBBCCGGDPW/QzSrS2BdCCCGEEMKGZCdo7MswHiGEEEIIIZyU9OwLIYQQQghhgwzjEUIIIYQQwknJ03iEEEIIIYQQ2Zb07AshhBBCCGHD4/+VWtLYf2hKqWTgEOb/4VGgl9Y60bFR3Z9SqjNQSWs91tGxPIz3xsKmneDpAUtnOjqaR1e3dimGDGiJi6FYviqIuX/+YzW/eFFP3hnennJl/fhl1lbm/bUHgJw5XPhuXHdy5HDBxcVg87ZjzPxtuyNSeCB1a5Vk6KstMQzF8rVBzF2w22p+8aKejHqjPeXK+DLt123MW7THar5hKKZM6EFEdALvfrLQnqFn2MBxL1G3TXWuX7vJN69N5eTBc+nK+JXwZvTMQbh75OPkwXN83W8ySbeSyZs/D+9Mew3fYl64uLqw4LuVrPltKz5FPHl7an88/AqgTZoVMzay+Me1DsguvYFfdSewTVVuJN7km0G/cPLg+XRl/Ep48+70ASn5jus/laRbyXR9vR1PdKsPgIurQbEKhXm+zBskXLkKmOt70uYxRIXE8OHz39k1rzvVblyOgaM6YrgYrPprL/OnbUlXZuC7HQlsWoEb127xzXt/cfJoCABvfvoM9ZpVICb6KgO6TEopXzqgEEPHdCZnrhwkJ5n4/rMlHD900W453c+AT54lsEUlbly7yTdvzuHU4fSx+RXzZNSPvXEvmJeThy4y/o1fSbqVTP02Ven5dgdMJk1ykokpHy3kyJ7TKcsZhmLSireJDIvho95T7JnWfTUtVJoxtVpjKMX8Uwf5+ehOq/n1fIszpUlXLlyNBWD1hWP878i2lPmGUvzdtg+XE+Ppt+VPu8b+oBpUKcmI7s0xDIO/txxi1grrfW67+gH07BAIwLUbtxg7ex0nLkTi5+nGR/3a41UgL1prFm0+xB9r9zsihSwnT+P5/+2a1rqG1roKcBMYkHamUsrFMWHdm9Z6yePa0Afo0h6mjHN0FJnDMBRvDG7FOx/8Sa/XfqFF84qUKO5lVSYu/jqTfl6f0si/7eatZIaP+oN+g2fSb/BM6tYuRaWAQvYM/4EZhmLYgNaM/GgBvQZPp2XTipQoZiPfKevTNfJv69qpNucuRtkj3IcS2KYaRcr406f6SL4bOoOh3/ayWa7fp8+z8IfV9K3xDgkxV2nXqxkAnfu35HxwCAMbfMDb7b+k/xcv4JrDheSkZKa8+zuv1n6XN574hE6vtqJ4QGF7pmZTYOuqFC7jR9+a7/LdG7MYMqGnzXKvfNyNRT+u4ZVa75IQc5W2PZsAsGDSKgY3+YjBTT5ixsd/cWj7sZSGPkCXga25cCzULrnci2EoBr/XifcHzKJ/5+9o3qEaxcv4WJUJbFKewiW86dt+At99tJghYzqnzFu7eB/vvzYr3XpfGd6WOT9uZPCz3/Pr9+voN7xtlueSUYEtKlG4lA+vNP6USe/MY8iXz9ks13f0Uyyeuol+TT4jITaRti80AODAtmMMav0VQ9p+zcS35vLGuBetlnvqleacPxmW5Xk8KEMpPq7dlj6b5tF2xRQ6lahE2fze6crtibjAk6t+4clVv1g19AH6lA/kVGz23U/dZijFyB4teGPiIp57byZt6gVQqrCnVZmQyFheGzuf7mN+5ZcluxjdqzUAScmab+dt5rn3ZtHns9/p2qJGumVF9iGN/cyxFSirlGqulNqolJoLHFJKuSilximl9iilgpRSrwEopQyl1I9KqSNKqWVKqRVKqa6WeWeVUh8rpfYppQ4ppQIs0+sqpXYopfZbflewTO+tlFqolFqllDqhlPr6dlBKqXaW9RxUSq1PU/57y98+Sqm/LPHtUUo1skxvppQ6YPnZr5Ryt+c/814Cq0PBbBPNowkoX4hLITGEhsWSlGRiw+ajNKpf1qpMTGwix46HkZyU/kLiteu3AHB1NXB1dSG730NUsVwhLoVeIfSyJd8twTSulz7f4BNhJNnI18fLjfqBpVm25pC9Qn5gDZ6sxbrfzVdYgvecIl+BvHj6FUhXrnqzimy1nNCsnbONBk/WAkBryOOeG4Dc+XIRf+UqyUkmoi/HplwhuJZwnQvHQvAu5GGPlO6pQcearP99BwDBe0/jdrd8mwawdfFeANbN3UHDjrXSlWnetR6bFqRe2fIu7EFg22qsmp2+B93eKlQtSuiFaMIuXiHpVjKbVwTR4ImKVmUatKjI+iXmns3goAu4uefG09u8szr871niY21f+M3rlguAfO65iYqIz8IsHkz9NlVZb7nyFrzvLG758+Dhmz9dueqNyrF1+QEA1v25mwZtqwJwPfFmSpnceXKi0+ygvAsVpG7LSqyea91jnh1U9yzMuYQrXLgawy2TiWXn/6N10XIZXt4/jztPFC7LvNMHsi7ITFK5tD8XwmO4FBFLUrKJtbuDaVazjFWZoJOhxCfeAODQqVB8Pc3bdFTsVY6dCwcg8fotzoZG4VPQzb4J2EmyzrwfR5FhPI9IKeUKtAdWWSbVBaporc8opfoDsVrrQKVULmC7UmoNUBsoCVQFfDEPA5qeZrWRWutaSqlBwFtAPyAYaKq1TlJKtQK+AJ61lK8B1ARuAMeUUv8DrgNTLcucUUrZOuX+Dpiotd6mlCoOrAYqWt5zsNZ6u1LKzbIukcl8vN2ISHNwj4iMp1KFjPfWGoZiyqSeFCnswaJl+zmaDXpA78Xby43wyDT5RsVTsXzGr0YMebUFP8/YTN48ObMivEzhXciDiDRXHiJDovEq7EH05diUafm93Lgak4gp2XxCE3npCt6FzQ33JZPX8fH8Ycw9+R153XLzRa8frRpJAH7FvSlTvQTBe0/ZIaN78yrkQcSl6JTXEbby9XTjamxqvhEh0XgVKmi1nlx5clKnVRV+eHtOyrTXxr7IL2P+JK9b7qxNIgO8/PITEZqaU+TlOCpUK2Zdxjc/EWGpZSIux+Hll5/oyLs34H8eu5zPp/Tm1bfaoQyD4S9NzvzgH5KXfwEiQ2JSXkeGxuDtX4Ar4XEp0/J75ONq3LXUbTk0Bi//1JO9hu2q0XtUJwp6uzGmZ2pur330DL98voQ8lhOd7MQ/rzuhiak5hibGU8Mr/X65pncRlrd7hcvXEvhy/3pOxEUC8EGt1ow9sIF8ObLvfuo2Hw83Lkenbp+XoxOoUubu++SnmlZhx6Ez6aYX8spPheK+HDmd/a7UZAZnGLMvPfsPL49S6gCwFzgP/GKZvltrffvT0AboaSn3D+AFlAMaA39qrU1a6zBg4x3rvj0Y+V/MJwUABYA/lVKHgYlA5TTl12utY7XW14H/gBJAfWDL7Vi01tGk1wr43hLfEiC/pRd/OzBBKfU6UFBrnZTh/4p4ACrdFP0AYwNNJk2/IbPo1uMnKpYvRKkS6S81ZycqfbpkNN0GgaWJiU3k+KnLmRpTprOR451XXJSNf8TtBn3tVlU4FXSe7mXfYFDDDxj8TQ/yuqc2dnPny8UHc4by8ztzSIx3/Dm4rTq98+TEdr7Wr+u1r86RXSdThvDUbVudmIg4Th5If7+DIyhbn9UM5XnvDfzJ5+sy+asV9Gg1jslfLefNT59+tEAzUUbqzWaZNH/vWBVE/+af88kr0+j5dkcA6rasTExkPCcPXcjMcLPUnbV4JDqMJkt+oOOqX5h9fC+Tm3YFoEXhskTduMrhK49Ho9fmLvku22ztgGJ0blKF7+dvtZqeJ1cOvhrSiQm/b+Lq9Zs2lxWOJz37D++a1rpG2gmWHd/VtJOAoVrr1XeU63ifdd+w/E4mtY4+BTZqrZ9WSpUENtkon3YZxf2bUgbQQGt97Y7pY5VSy4EOwC6lVCutdfAdOfQH+gNMnjyZfp0RDygiMh4fn9QxST7e7kRGJTzwehKu3uBA0Hnq1inFmXORmRlipoqITMDXO02+Xu5ERmcs3yoVi9Cwblnq1S5Nzpyu5Mubk/eGd+TzCcuzKtwM69S/Je17m8fcH//3DD5FvYATAHgX9iQ69IpV+djIePIVzIvhYmBKNuFdxIOo0BgA2rzchPmWnEJOhxN2LoJi5Qtz7N/TuLi68MGcoWyYt4PtS/61W3536tSvBe16NQXg+P4z+BRJvWjoU9iTaEsut8VGxZOvQGq+PoU9iQ6zLtPsGeshPJXrl6V++xrUbV2NHLlzkNc9NyOnvMrX/admWV73Enk5Fp9CqT3W3n75iU7Tw51SJk2vto9ffqLD7z0sp9VTtfjpS3N9b119mGGfOLax/2SvJrTrbh5zf/zgebwLF0yZ512oIFFprtgAxEYnkC9/ntRtuVBBosOsywAc/ucUhUp4k98jH5UCS1O/TVUCW1QiRy5z3b49qQfjXv81S3PLqLDEeArlTR2uVCivO+HXrOsxISm1Ubsp9BSfqLZ45MxDbZ+itCxSjuaFypDLxRW3HLmY0KAzw3cusVv8DyL8SgJ+nqn7ZD9PNyJj0u+Tyxb15v0+rXljwkJir6Z2Mri4GHw1pBOrdh5l478n7RKzIyTbPC16vEjPftZaDQxUSuUAUEqVV0rlA7YBz1rG7vsBzTOwrgLAJcvfvTNQfifQTClVyvLetobxrAGG3H6hlKph+V1Ga31Ia/0V5isXAXcuqLWeorWuo7Wu079//wyEI+507HgoRQt74O9XAFdXgxbNKrJjV8Z2mAUK5MEtn/kSeM6crtSuWYLzF2xdvMk+gk/ckW/TALbvzli+U2dvpVufn3mh3xQ++Xop+4LOZ4uGPsDSKesZ1HAMgxqOYceyfbR6sREAAYFlSIy7ZjWk5baDW47S5GnzEy5av9SYncv3ARBxMZoazSsBUNA3P0XLFSL0rHlc7PAfX+HCsRAWfr863frsaem0DSk31e5ctp+WLzYEIKBOaa7GJdrMN2hrME261AGgVfeG7FyR+tSOvPnzUK1xeatpMz7+ix6V3qJXtZGM7fszB7cEO6yhD3Ds8CUKF/fCr4gHrjlcaNahGrs2WvV/sGtjMC071wQgoFoxribcuOcQHoCo8DiqBZYCoEa90oScc+xNnctmbWVI268Z0vZrdq4KomXXugAE1CrJ1fjrVkN4bgvacYImHWsA0KpbXXZa7qkpVDL1SmOZKkVxzelC3JWrzBy7lB6BY+jd4GPGDp7Jwe3Hs01DHyAoOoSS7h4UzVeAHIbBk8Urse7iCasy3rnzpfxdzbMQhlJcuXmNcQc30ejv72m69Ede37GYnZfPZtuGPsB/Z8Io7luQwt75cXUxaF03gC37T1uV8fN05+shnflw6krOX46xmvdBnzacDYlm7pp9doza/kw6834cRXr2s9Y0zMNw9ilzt38E0AX4C2gJHAaOYx7ik/4Iae1rYJZSajiw4X5vrLWOsPS+L1RKGUA40PqOYq8DPyilgjBvC1swP1VomFLqCcxXCf4DVt43UzsZ8THsPgAxsdC8KwzpA13vd50km0o2ab77aR3jPuuG4aJYueYQZ89H0blDDQCWrDiAp0c+Jk/qSd68OdEmTdcudej12i94ebjx7lsdMAyFoRQbtx5j527Hj+G+l2ST5tuf1zH+464YhsGKdZZ821UHYMmqg3gWzMfkiT3IlzcnJpOma+fa9Bo0ncRrj8fl4d2rDxLYthozgsZx49oNvhkwLWXep38NZ+Lg6USHxfDLB/MZPXMQvT94lpNB51g9y3wT6pyxf/PW5Ff5+Z/PUErxywfziYtKoHKDcrTq3ojThy/w445PAJjx0QL2rAlySJ637V4TRGCbakw/MJYbiTeZMDj11qNP/hzGt0NnmvP9cAHvTn+NXu8/zamg86yenToUoNGTtfh3wxFuJGbfOjYlm/jx86V8PqU3hqFYs2gf506F0+E5c2N4xfzd7N5yjMCm5Zm+cjg3rt9iwvupj4YdNe45qgWWJn/BvPy6fiS//bCe1Qv/5buPFjNgVEdcXA1u3kjiu48WOyjD9PZs+I/AFpWZvm0M16/fZOLw1PspPpn9Gt++/TvRl+OY/sUSRv3Ym54jO3Lq8EXW/LELgMYdatDy2UCSkpK5ef0WYwfOdFAmDyZZaz7au4ZZzV/AUAZ/nj7IibhIupc1n8jNPbmf9sUCeKlcLZJNJq4nJ/H6jsWODfohJZs0X8/ZyKQRz+JiKJZsPczpkCieaV4NgIWbguj3VH0KuOXmnR4tAUhKNtHrk7lUL1eYjo0qceJCBHM+fhmAH/7azo6g9GP6heOp+40pFFlDKeWmtU5QSnkBu4FGlvH7jyNtCivv6BiynOF/HIDm7b++T0nnsGnlSACadXKSZ53ew+albwPQ1s32ozKdzeoE82Mg2xXo6+BIst6qWPMJSLvK7zk4EvtYdeRzANoXfd3BkWS9lRfN31lQ+vcvHByJfZx+cTQAgX0mODiSrLdnxnCwfVuB3f13oUimNZQrFbvkkJykZ99xlimlCgI5gU8f44a+EEIIIYRTcoYx+9LYdxCtdXNHxyCEEEIIIZybNPaFEEIIIYSwwaSlZ18IIYQQQgin5AzDeOTRm0IIIYQQQjgp6dkXQgghhBDChmQn6BeXxr4QQgghhBA2yJh9IYQQQgghnJSM2RdCCCGEEEJkW9KzL4QQQgghhA3J+vHvF5fGvhBCCCGEEDaYnGAQzOOfgRBCCCGEEMIm6dkXQgghhBDCBme4QVca+0IIIYQQQtjgDGP2H/8MhBBCCCGEEDZJz74QQgghhBA2mJxgGI/SWjs6BvH4k41ICCGEEJkpW7SyV5ypkmltnA6lDjskJxnGI4QQQgghhJOSYTwiUzRv/7WjQ8hym1aOBMAUVt7BkdiH4X8cgCZdxjk4kqy3dfHbALSp+4mDI7GPNbvHAFD53YkOjiTrHfnyTQDq9p7g4EjsY/fM4QA06+j8++TNy8375JqDnH87Btj/o3lbLvnjeAdHkvXODnrL0SGkcIYbdKWxL4QQQgghhA3ypVpCCCGEEEKIbEt69oUQQgghhLAhWWeL+4QfiTT2hRBCCCGEsCHZCQbBPP4ZCCGEEEIIIWySnn0hhBBCCCFsMMnTeIQQQgghhHBOMoxHCCGEEEIIkW1Jz74QQgghhBA2yNN4hBBCCCGEcFLypVpCCCGEEEKIbEt69oUQQgghhLAhWZ7GI4QQQgghhHMy8fiP2X/8T1eEEEIIIYQQNknPvhBCCCGEEDbIMB6RqZRSfsBEoD5wBbgJfG35+y2t9ZMODM9u6tYuxZABLXExFMtXBTH3z3+s5hcv6sk7w9tTrqwfv8zayry/9gCQM4cL343rTo4cLri4GGzedoyZv213RAqZ5r2xsGkneHrA0pmOjubR1a1Zkjf6tcQwFMvWBjFn4W6r+cWLePLu0PaUL+PL1N+28cffe1LmzZ/Sn8RrNzGZNMnJJl5961d7h39fdeqXYeCIthiGwaq/9zNvdvrtb9CItgQ2LMeN67cY/8nfnDwWBsDsxa9zLfFGSn5Dek0DYPTnz1KshBcA+dxyczXhOgNfnmK/pDKocfkSjHqyOS6GwV97DjNt8x6r+U9ULM3Q1g3RWpNk0ny1bBP7zoWQ09WF2f2fI6erCy6GwZrDJ/hh3U4HZZEx9auWZET35hiGwd9bDjF7uXWubRsE0LNDIADXrt/iq9nrOHEhEl9PNz56tT1eBfKitWbRpkPMW7vfESk8kLq1SzG0v/lzu3yN7X3yqGHmffK02VuZt9D6/2EYiinf9iQiKoF3P/7LnqE/lIaVSvB2t+YYymDxjsPMWGOdT/vAAHq3qQPAtRu3+OL39Ry/FAmAW55cfPhSa8oU9kKj+fjXtQSdCbV7DhnVrFhJxjRugYuhmPffIX7av9tmuWq+/ix6pjtD1ixj5enjlC7owfdtOqXML5a/ABN3b2d60D57hW43zvClWtLYzyaUUgpYDMzSWne3TCsBdMbc2P9/wTAUbwxuxVuj5xMRGc/P3/Vk+z8nOXc+KqVMXPx1Jv28nsYNylkte/NWMsNH/cG167dwcTH43/ju7N57mv+Cs++O9n66tIfuz8CoLxwdyaMzDMXw11rz5ofziYiKZ+q4HmzffYqzF9PUbcJ1vpu2nib1ytpcxxvvzyM2/pq9Qn4ghqEYMrI9o4b8RmR4HP+b1Y+dW49x/kxkSpnAhmUpUsyLPs9+T0CVIrz+Tkde7/tLyvy3B84mLtY6vy/eS20c9X+jNVcTbmR9Mg/IUIr3Orfg1V8WcjkunnmDu7Px6ClOhUenlPnn1AU2Hv0NgPL+3nzzYkc6TZzFzaRk+k5bQOLNW7gaBr8OeI6tx84QdCHMUenck6EUI3u0YMi4vwiPjmfWhy+xdf8pzoSk5hoSEcuAL+cTn3iDBlVL8m7v1vT99HeSkzXf/bGZY+fCyZs7B7M/epndR85ZLZvdGIZi2MBWjHjfvE+ePLEn23ed5NyFO/bJk9Pvk2/r2rk25y5EkTdvLnuF/dAMpRj1fAsGTlrI5Zh45rzTnc1BpzgdlqZ+o2LpN+FP4q/doFGlkrzfvRU9x/0BwMhuzdnx31nenrYMVxeD3DlzOCqV+zKU4pOmrXh56Z+EJcSzpOvLrD17ipNXotKVG1W/KVsunE2ZdjrmCh3mz06Z/0+vAaw+fdKe4YsH8PifrjiPFsBNrfXPtydorc9prf+XtpBS6iOl1FtpXh9WSpW0/N1TKRWklDqolPrVMq2EUmq9Zfp6pVRxy/RulmUPKqW2WKa5KKXGKaX2WMq/lvVpWwsoX4hLITGEhsWSlGRiw+ajNKpv3fCLiU3k2PEwkpNM6Za/dv0WAK6uBq6uLmhtl7CzTGB1KOju6CgyR8VyhbgUeoXQy+a6Xb8tmMb10tdt8MkwkpLT1212V6FyEUIuXiEsJIakJBOb1xyhYdMKVmUaNq3A2hUHAQg+fIl87rnw9HLL8Hs0a1WJjWsOZ2rcmaFqMX8uRMVw8Uost5JNrDh4jCcqlrEqk3jzVsrfeXLmQKPTzXN1MXA1DLLzx7ZyaX8uXo4hJCKWpGQTa/4JpmlN61wPnQwlPtF8Unb4VCi+nuYPcVTsVY6dCwcg8fotzoRE4eOR8fp3hIp37pO3HKWxjX1y8Ikwkmzsk3283KgfWIZlq4PsFfIjqVLSnwsRMVyKMtfv6n+P0by6df0ePB1K/DVz/QadCcXPw1y/+XLnpFbZIizaYf6MJiWbSLiW/U7Ob6vh68+52CtciIvllsnE0pPBtClVJl253lVrsvL0caKuJdpcT6OixTkXG8OlhLisDtkhTFpl2o+jSM9+9lEZeOjrX0qpysB7QCOtdaRSytMy63tgttZ6llKqLzAJ6AKMAdpqrS8ppQpayr4CxGqtA5VSuYDtSqk1WuszDxvXg/LxdiMiIj7ldURkPJUqFM7w8oahmDKpJ0UKe7Bo2X6OHnt8e/WdjY+nG+GRaeo2Kp6K5QpleHmtNRM+6oZG8/fqgyxdk70aD94+7kRcjk15HREeR0DlIlZlvHzdibicekCMDI/Hy9ed6KgEQPPl/14GrVm+aB8rFlvvDqrWLM6V6KuEXMh+vcB++d0IjU2t28txCVQr5p+uXMtKZRjWtjFebnkZOGtxynRDKf4c0p3iXgX5fddBDmXTXn0AHw83Lken5hp+JYHKpe++HXduWoWdQel3oYW881OhhC9HTmXfXAG8ve743EbGU/EB9slD+rfk5xmbyJsnZ1aEl+l8C7px+UqabflKAlVKpt+Wb+vSqArbj5jrt4h3Aa4kXOPjHm0oX9SHo+cv8/Wfm7h+MynL434YfvncCUlIzTU0IYEafoXuKONG21LleHHJfKr72v4/dCobwJITwVkaqyM5wzCexz8DJ6WU+sHS677n/qUB85WBBVrrSACt9e0WQQNgruXvX4HGlr+3AzOVUq8CLpZpbYCeSqkDwD+AF2DzuqxSqr9Saq9Sau+UKZk5fjj9ma9+gH4+k0nTb8gsuvX4iYrlC1GqhHcmxiYeySN2agwaNZdXRszmrU/+4pn2NaleqWjmxJVZbOR355ar7lFoWL8ZDO45lfeGzaVTtzpUrVncqljzNlXYuDr79erfjbZxWW39f6foNHEWQ39dwtDWDVOmm7Tm2f/NocXYaVQt6k9ZPy97hvpAlM3t2PY+qnZAMTo3rcL387daTc+TKwdjh3RiwtxNXL1+M/ODzETKZsIZ2yc3CCxDTGwix09eztyg7M52vnXKF6VLw8p8t3gbAK6GQUAxX/7cGsSLX87h2s0k+rYJtGegD8RW1d75uR3T6AnG7tqC6S6XyXMYBq1KlmHFqWNZEaLIJNKzn30cAZ69/UJrPVgp5Q3svaNcEtYnabktvxUZ2wNry/oHKKXqAR2BA0qpGpZ1DNVar77vSrSeAtxu5eu5i77OwFvfX0RkPD4+qeNWfLzdiYxKeOD1JFy9wYGg89StU4oz5yLvv4DIchFRCfh6p6lbL3ciozNet1FXrgLmIQNb/jlBxXKFOPjfxUyP82FFhsfj41cg5bWPb36i01ylMpeJw8cvf8prb193oixloiPN/4uYK4ns2HSMCpWKcGj/eQAMF0Xj5gEM7jU1q9N4KJfjEihUILVu/fK7ER539a7l/z17iWKeBSiYNzcxiddTpsdfv8HuMxdpXL4kJy9H3XV5RwqPTsDPMzVXXw83Iq6k347LFvXmvb6tGfbNQmKvpubo4mLw1ZBOrN55lE3/Zv8xzhGR8daf2wfYJ1epVISG9cpSr05pcuZ0IV+eXLz3Vkc+H788q8J9ZOExCSnDcgD8PNyIiE2/LZcr4s2Yl1oz5IdFKfV7OSae8Jh4Dp81X61Zt+8EfdrWsU/gDyEsIZ7Cbqm5FnJzIzzRum6r+frzv9bmZ4N45MlD8+KlSdYm1pwxb7vNi5ficGQ4kXcZ4uMMTE7wNJ7HPwPnsQHIrZQamGZaXhvlzgK1AJRStYBSlunrgeeUUl6WebeH8ewAXrD8/RKwzTK/jNb6H631GCASKAasBgYqpXJYypRXSuXLnPQy5tjxUIoW9sDfrwCurgYtmlVkx66MHRALFMiDWz7zDWA5c7pSu2YJzmfDIQ//XwWfCKVoIQ8K+ZrrtmXjALbtzljd5s6Vgzy5c6T8HVijJKfPR2RluA/s2H+XKFLME//CBXF1NWjWpjI7tx63KrNz63Fad6gOQECVIlxNuEF0VAK5c+cgT17zMIfcuXNQq15pzp4KT1muVmBpLpyLIjLc+uQhuzh8MYzi3h4U8chPDheDDtUrsPHoaasyxb1ST4QqFvYlh4sLMYnX8ciXB/fc5s9tLlcXGpQpzpmI7Pu5/e9MGMX8ClLYOz+uLgZt6gWwdb91rn6e7nw1tDMfTlnJ+csxVvM+6NuGM6HRzF39eDy1JPh4KEWLpNknN63I9n8y9rmdOmsL3Xr9xAt9J/PJV0vZF3Q+Wzf0AY6cC6O4rweFvcz127Z2BTYFWdevv4c741/txAezVnE+PCZlelRcImFXEijh6wFA3YBinA7NvtvywfAwShbwoKh7AXIYBp3KBrD2zCmrMk1+m0pjy8/KU8f5YMu6lIY+QOdyFVnqxEN4AJJRmfaTEUqpdkqpY0qpk0qpUTbmF1BKLbWM/jiilOpzv3VKz342obXWSqkuwESl1EggArgKvHNH0b9IHWqzBzhuWf6IUupzYLNSKhnYD/QGXgemK6Xetqzz9kYxTilVDnNv/nrgIBAElAT2WZ4OFIF5fL/dJJs03/20jnGfdcNwUaxcc4iz56Po3KEGAEtWHMDTIx+TJ/Ukb96caJOma5c69HrtF7w83Hj3rQ4YhsJQio1bj7Fz96l7v2E2N+Jj2H0AYmKheVcY0ge6dnR0VA8n2aSZOHUd33zYFcPFYPm6Q5y9EMVTbc2N379XH8SzYD6mju9Bvrw5MWlNt0616TF0OgXy5+GLUV0Ac8/o2i1H2b3/rOOSscGUrPl+3Eq+mPQShqFYvfQA505H0PGZ2gAsX/gvu7efoG7DssxcOMT86M1PlwBQ0DMfH457DjDnt3H1YfbuSt12m7epnC1vzL0t2aT5fMkGpvR9BkMpFu09wqnwKJ6rWw2A+buDaF25HJ1rVSIpOZnrSUm89bu50efjno8vurXFUObP7epDx9kcbLfbhB5Yskkz7reNTHrrWQxDsXTrYU6HRPHME+ZcF24Mot9T9Snglpt3erY0L5NsotfHc6lerjAdGlXixIUIfvvkZQB+XLCdHTbG9GcXySbNtz+tY/yn3TAMxYq1ln1y+xoALFlp2Sd/29P8uTVpuj5Vh14DfiHxWvYeomRLsknz1bwN/DjkGQxD8ffOI5wOjaJrE3P9LtgaRP8O9Sjolpt3n2+RssxLX5lHy341fyNf9GmPq6vBpchYPpy9xmG53E+y1ozZup7ZnZ7FRRnMDz7EiStRvFTZvE+ec+TgPZfP7epK42IlGL05++b4uFFKuQA/AK2Bi8AepdQSrfV/aYoNBv7TWndSSvkAx5RSc7TWd/3AKVvjKoV4QLp5+8wZxpOdbVo5EgBTWHkHR2Ifhr+5V7pJl3EOjiTrbV38NgBt6n7i4EjsY83uMQBUfneigyPJeke+fBOAur0nODgS+9g9czgAzTo6/z5583LzPrnmIOffjgH2/2jelkv+ON7BkWS9s4Pegke+0ytzfP1f+0xrKI+stPKeOSmlGgAfaa3bWl6/C6C1/jJNmXcxj8YYjLmDdi1QXmt918fYSc++EEIIIYQQNmR0+E1GKKX6A/3TTJpiuQfytiLAhTSvLwL17ljN98ASIARwB56/V0MfpLEvhBBCCCFElrvj4Sa2ZOTxV22BA5ifwlgGWKuU2qq1vusXHcgNukIIIYQQQthg0kam/WTARcxDdG4rirkHP60+wEJtdhI4AwTca6XSsy+EEEIIIYQNyfZ99OYeoJxSqhRwCfPTFLvfUeY80BLYqpTyAyoAp7kHaewLIYQQQgjhYFrrJKXUEMyPQncBpluetjjAMv9n4FPMX4p6CPOwn3duf6Hq3UhjXwghhBBCCBtMdn4okNZ6BbDijmk/p/k7BGjzIOuUxr4QQgghhBA22HkYT5Z4/DMQQgghhBBC2CQ9+0IIIYQQQthg0tniu70eiTT2hRBCCCGEsCHZCQbBPP4ZCCGEEEIIIWySnn0hhBBCCCFskGE8QgghhBBCOCmTEwyCefwzEEIIIYQQQtgkPftCCCGEEELYkOwEw3iU1trRMYjHn2xEQgghhMhM2aKV/cb+FzOtjfNdzd8dkpMM4xFCCCGEEMJJyTAekSmadRrn6BCy3OalbwPQpIvz5wqwdbE5X1NYeQdHkvUM/+MA1OsxwcGR2Mc/vw4HoFWzLxwcSdZbt3k0ANVfn+jgSOzj4KQ3AWhb80MHR5L1Vu//GIDar/7/qNt/p5rrtk2DTx0cSdZbs/MDR4eQwqQf/35xaewLIYQQQghhQ3L2GE30SKSxL4QQQgghhA3O8Jz9x//ahBBCCCGEEMIm6dkXQgghhBDCBhmzL4QQQgghhJMyOcGY/cf/dEUIIYQQQghhk/TsCyGEEEIIYYMzfIOuNPaFEEIIIYSwwRnG7D/+GQghhBBCCCFskp59IYQQQgghbHCG5+xLY18IIYQQQggb5Gk8QgghhBBCiGxLevaFEEIIIYSwQYbxCCGEEEII4aTkaTxCCCGEEEKIbEt69u+glEoGDgEKSAaGaK13KKVKAsu01lUy4T02AW9prfcqpc4C8YAJuAz01FqHPep7PM7q1irJ0FdbYhiK5WuDmLtgt9X84kU9GfVGe8qV8WXar9uYt2iP1XzDUEyZ0IOI6ATe/WShPUN/YHVrluSNfuZcl60NYs7CO3It4sm7Q9tTvowvU3/bxh9/p+Y6f0p/Eq/dxGTSJCebePWtX+0dfqZ6byxs2gmeHrB0pqOjeXT1q5ZkeI/mGIbBkk2HmL3Mejtt2zCAHh0DAbh24xZfz1zHifORALzfrw2NapbmSlwi3d+dbffYMyqwbmkGDW2NYShWLj/IH3N3pisz+PXW1K1Xhhs3kvj6y6WcPHEZgGe7BdK+Yw20hjNnwhk3dhm3biZTuowvw0a0I0+enISFxfLlp3+TmHjT3qndU8OKJXjnGXPdLtp5mOnrrOu2Q50A+rSsA0DizVt8Pm89x0PMdfty85o806AqWmtOhEYyZs4abiYl2z2H+6nTsCwD3m6Pi6FYuXgf82dsS1dm4Mj21G1UjuvXb/HNh4s5GRyaMs8wFP+b8xpR4XGMeWMuAE1aVaLHgCcoVsqb13tM5cR/IXbL50E0qFyCt15ojothsHjrYWausq7f9vUC6NXOUr/Xb/HlnPWcuBiZMt9Qil/f705ETALD/ve3XWPPiDr1yzBwWFsMF8WqJfuZ9+uOdGUGvdmWwIZluXH9FuM/XcLJ4+ZmST63XAx/txMly/igNXzz+RKOHr5Ej1ea0v6pmsReSQRg+s8b2bPzpF3zyirOMIxHevbTu6a1rqG1rg68C3xph/d8wvJ+e4HRaWcoM7vUk1LKxR7vcy+GoRg2oDUjP1pAr8HTadm0IiWKeVmViYu/zqQp69M18m/r2qk25y5G2SPcR2IYiuGvteatTxbQY+h0WjWpSMmid+SacJ3vpq3nj8W2c33j/Xn0fXPWY9/QB+jSHqaMc3QUmcNQird7tWDYuEW88M5M2jQIoFRhT6syIRGxDPx8Pi+/9yvTF+9iVN/WKfOWbT3CsK+z94mqYSiGDmvL6JHzeKXXFJ5oWYniJbytytStV4YiRT3p9dLPTBy/gjeGtwPAy9uNLs8GMqj/DF7tMxUXw+CJFpUAGDGyA9Mmb+LVPtPYvvUYz71Q3+653YuhFKO7tWDQz4t5+otZtKtdgdL+1nV7KSqWvpP+pNtXvzFl1T+MeaEVAL4F8tG9WU1eHD+HZ8f+imEYtKtVwRFp3JNhKAaP6sj7Q37j1Wd/4Il2VSle2seqTGDjchQp7kWfpybx3WdLGTr6Sav5XbrX58KZCKtpZ0+F88mIPzi071yW5/CwDKUY1b0Fr3+3mK5jZtG2bgVKFbqjfiNjeXXcn7zw8W9MW/4P7/doZTX/xVY1ORsabc+wM8wwFENGtOO94XN59cWfaN66CsVLWn9uAxuUpUgxT/p0+4Fvxy7n9ZEdUuYNerMte3ad5JUXfmJAj8mcP5t6krPwj38Y2GsqA3tNdZqGPpifxpNZP44ijf17yw9cuXOiUiq3UmqGUuqQUmq/UuqJ+0zPo5T6QykVpJSaB+S5y/ttAcoqpUoqpY4qpX4E9gHFlFJvK6X2WNbxsWW9+ZRSy5VSB5VSh5VSz1umj1VK/WcpO94ybaZSqmuaHBIsv5srpTYqpeYCh5RSLkqpcWne67VM+l9mSMVyhbgUeoXQy7EkJZnYsCWYxvXKWpWJiU0k+EQYSUmmdMv7eLlRP7A0y9YcslfID+3OXNdvu0uuJ8NISk6fq7MJrA4F3R0dReaoVMafi5djCImIJSnZxNpdwTStXcaqzKETocQn3gDg8MlQfD1Skz9w7BJxV6/bNeYHVaFiYUIuXSE0NIakJBObNvxHo8blrMo0bFyetavNn8Wj/4Xg5pYbT898ALi4GOTK5YrhosiVy5WoyAQAihbzIujgeQD+3XOGJs0C7JjV/VUp4c+FiBguRZnrdtW+YzSval23B8+EEn/NXLdBZ0PxS7NhuxgGuXK44mIo8uRwJSIuwa7xZ0SFKkUIuRBN2KUrJCUls2n1YRo0t66HBs0CWLfsAADBhy6Szz03nt5uAHj75qdu4/KsXLTPapkLZyK5eC57d8RULmWp30hz/a7Zc4zmNazrN+hU6mf30Gnrz66vhxuNq5Zi8bbDdo07oypUKkzIxSuEhZg/t5vXHaFhU+sTzoZNy7N2ZRAAwUcukc8tN55ebuTNm5OqNYqzaukBAJKSTFxNuGHvFMRDkGE86eVRSh0AcgOFgBY2ygwG0FpXVUoFAGuUUuXvMX0gkKi1rqaUqoa5AW/Lk5iHEAFUAPporQcppdoA5YC6mIcXLVFKNQV8gBCtdUcApVQBpZQn8DQQoLXWSqmCGci5LlBFa31GKdUfiNVaByqlcgHblVJrtNZnMrCeR+bt5UZ4ZHzK64ioeCqWL5Th5Ye82oKfZ2wmb56cWRFepvLxtJFruYznqrVmwkfd0Gj+Xn2QpWuCsiJM8RB8Pdy4HJ1at+HRCVQuc/e67dy8CjuD7PIRyzTe3u6Eh8elvI6IiCegYuE7yrgRcUcZbx93jh8L488//mHu/CHcuJnEv3tO8+9ec/5nz0TQsFE5dmw/QdMnKuLjm73OAH0LuhEWk6ZuYxKoWsL/ruWfblCFbUfNuYXHXmXWhn9Z/XE/rt9KYmfwOXYGn8/ymB+Ul29+Ii7HpryOvBxLQJWiVmW8fd2JCItLUyYOL9/8REcmMODtdkz7bg158+ayW8yZxbeg9Wf38pUEqpS6e/12aVyFHYdTP7sjnm/Odwu2ki939jwGefvkt/5MhscRULmIVRkvH3ciLqep24g4vHzcSU42EROTyFvvd6Z0OT9OBIfy08TVXL9+C4DOXQNp1b4ax4NDmTJpLQnx2bvDIqNkGI9zuj2MJwBoB8xWSt1Z042BXwG01sHAOaD8PaY3BX6zTA8C7myVbbScYOQnddjQOa31LsvfbSw/+zGfKARgbvwfAloppb5SSjXRWscCccB1YJpS6hkgMQM5707TmG8D9LTE8w/gZXkvK0qp/kqpvUqpvVOmTMnAW2RMuv80gM7Ysg0CSxMTm8jxU5czLZ4s9Yj7j0Gj5vLKiNm89clfPNO+JtUrFb3/QsI+bNSt1rY35NoVi9GpaRW+n7c1i4PKXDY/q+nKpC+kNbi55aZh43K8/MKPPP/MJHLnzkHL1pUBGP/Vcjo/XZsfp/Qhb56cJN3KXuPZbe6i7lK3geWK8nT9ynz7t3m8u3ueXDxRtTQdPp5O6/enkidnDjrWyV5XLuAuOaYrZKtuNfWalCcm+ionj4amm/84sLVd67schOpUKMpTjSsz6S9z/TapVoorcYkEnw/PyhAfTQb2Tcp2IVxcDMqVL8SyhXsZ1Gsq16/d5PmejQBYuvBfenf9noE9pxAdmUD/11unX8djyqRVpv04ivTs34PWeqdSyhtzD3pad6uxe9XkvZqsT2itUwa+WXrjr96x3i+11pPTvaFStYEOwJeWHvhPlFJ1gZbAC8AQzFcnkrCc3FlOXtJ2O9z5XkO11qvvES9a6ynA7Va+nrM0cwZbR0Qm4Oud2pPn4+VOZHTGLnNXqViEhnXLUq92aXLmdCVf3py8N7wjn09YnimxZbaIqIfPFSDqirnaYmIT2fLPCSqWK8TB/y5mepziwYVHJ+DnmebSvqcbkTHp67ZsMW9Gv9KaYeMXEpfwePWCRUTE4+ubP+W1j487UWmuVN0u42OjTK06JQkLjSE21twXsW3rMSpXKcr6tUe4cD6KUW/9AUCRop7Ua2A9tM3RLsck4J9mWI5vQTfC466mK1eusDcfvtiawT8tIjbRXLf1KxTnUlQcVxKuAbD+4EmqlyrM8r3B9gk+gyLD4/DxK5Dy2tuvAFER1nUbeTkOH//8acrkJzoiniatKlO/WQUCG5cjZ05X8ubLxcjPnuHr97P3PSi3Xb5i/dn183AjMiZ9/ZYt4s0HPVszdNIiYi1D7qqXKUzTGqVpVLUkOXO44pY7J5++0o4Pflllt/jvJzI8zvozabkaY1UmIg4fvzR165OfqMgEtNZERMQRbLmxeuvGozzfw9zYj7mS+j9a+fc+Ph3/QlamIR6Q9Ozfg2Uojgtw5yDDLcBLljLlgeLAsQxOrwJUe8BQVgN9lVJulnUUUUr5KqUKYx4e9BswHqhlKVNAa70CGAbUsKzjLFDb8vdTQI57vNdApVSO23kopfI9YLwPLfhEKEULe+DvVwBXV4MWTQPYvjtjN/pMnb2Vbn1+5oV+U/jk66XsCzqfbRv6YMm1kAeFfM25tmwcwLYM5po7Vw7y5M6R8ndgjZKcPh9xn6WEvRw9HUYx/4IU8smPq4tB6/oBbNl32qqMn5c7Y9/ozEeTV3IhLMYxgT6CY8EhFCnqgb+/eftt3qISO7afsCqzc/txWretCkDFSoW5evUG0dFXCb8cR8VKRciVy9zfVLNWSc5bxnIXLJgXMPewvtyzEcuW3G3Uo2McOR9GcR8Pinia67ZdrQpsPmRdt/4e7kx4pRPv/bqKcxExKdPDrsRTrWQhcucw512vfHHOXM5+N3IeOxJCkeKe+BUuiKurC83bVmHXJusTkl2bg2n1ZA0AAqoWJTHhOtGRCcz43zpebjeBXh2/5ctRCzi458xj09AH+O9sGMV8PSjsba7fNoEV2Hzwjvr1dGf8oE58MH0V5y/HpEz/ftF2OoycRqd3pzN6ygr2HLuQrRr6AMeOhlCkmCf+hQri6mrQrFVldm49blVm59bjtG5vbqYEVC7C1avXiY5K4Er0VSIux1G0uPlBEjXrlOL8WfNxx9PLLWX5Rs0DOHvaeY5H0rPvnG6P2QdzL3cvrXXyHZejfwR+Vkodwtxj3ltrfcNyQ62t6T8BM5RSQcABwPr5ivehtV6jlKoI7LTEkQC8DJQFximlTMAtzPcGuAN/K6VyW+J/07KaqZbpu4H1WPfmpzUNKAnss1wBiAC6PEi8jyLZpPn253WM/7grhmGwYt0hzp6PonO76gAsWXUQz4L5mDyxB/ny5sRk0nTtXJteg6aTeC17PZ7vfpJNmolT1/HNh10xXAyWrzvE2QtRPNXWnOvfq825Th1vyVVrunWqTY+h0ymQPw9fjOoCmG90XLvlKLv3n3VcMplgxMew+wDExELzrjCkD3Tt6OioHk6ySTN+9kYmvf0shqFYuuUwZy5F8XQL8wF00YYgXulSnwJuuRnZq6V5mWQTvT80P6Lw00EdqFWxKAXd8rD0u1eZsnAnSzdnrxv+TMma/327hrHjX8AwDFatOMi5s5E82bkmAMuW7OefXaeoW78ss+cO5MaNW4wbuwyA4KMhbNkczE9TXyE52cTJk2EsX7ofgCdaVuapp2sBsG3LMVatyF73oiSbNF8u2MBPg57BMBSLdx3hVFgU3RqZ6/bP7UG81q4eBfPlZnS3FinLdB8/l0Pnwlh74AR/jHyJ5GQTwZciWLAj+z1MwJRs4oevVvDFjz0wDIM1f+/n3OkIOnY1P25y+YK97N52gsDG5Zmx5A1uXL/FNx8tvu96Gz4RwKB3OlDAIx+fTnqJU8fCeG9w9nqSWLJJ8/XcDXw/7BlclOLv7Uc4HRLFs83M9fvX5iBefbIeBfLlZtRLlvpN1vT4fK4jw84wU7Lm+29W8cW33TEMxeplBzl3JoKOls/c8kX72L3jJHUblmXmn4O5cSOJ8Z8tSVn+hwmrGPVRF1xzuBB2KYbxn5vn9RvckjLl/dFaczk0lu++yr4dbQ/KGcbsq7uNNRTiAehmnZzkmYn3sHnp2wA06eL8uQJsXWzO1xRW3sGRZD3D39yzVa/HBAdHYh///DocgFbNvnBwJFlv3Wbz04yrvz7RwZHYx8FJ5v6dtjU/dHAkWW/1/o8BqP3q/4+6/XequW7bNPjUwZFkvTU7P4BHvrMtc3Tc8nqmNZSXN53kkJykZ18IIYQQQggbHPl8/MwijX0hhBBCCCFscIZhPHKDrhBCCCGEEE5KevaFEEIIIYSwwRl69qWxL4QQQgghhA3O0NiXYTxCCCGEEEI4KenZF0IIIYQQwgZn6NmXxr4QQgghhBA2aCdo7MswHiGEEEIIIZyU9OwLIYQQQghhg3yplhBCCCGEEE7KGcbsyzAeIYQQQgghnJT07AshhBBCCGGDM9ygK419IYQQQgghbJBhPEIIIYQQQohsS3r2hRBCCCGEsMEZhvEorbWjYxCPP9mIhBBCCJGZskUru+6q0ZnWxtnd7guH5CTDeIQQQgghhHBSMoxHZIq2br0cHUKWW50wC4A2dT9xcCT2sWb3GADq9Zjg4Eiy3j+/DgfAFFbewZHYh+F/HIDS3zp/3Z4eZq7b8l9MdHAk9nF89JsANHz+GwdHkvV2zBsBQGujm4MjsY+1pj8BaN3oMwdHkvXWbn/f0SGkcIYBMNLYF0IIIYQQwgZn+AZdGcYjhBBCCCGEk5KefSGEEEIIIWxwhqfxSGNfCCGEEEIIG+RLtYQQQgghhBCZQinVTil1TCl1Uik16i5lmiulDiiljiilNt9vndKzL4QQQgghhA32fBqPUsoF+AFoDVwE9iillmit/0tTpiDwI9BOa31eKeV7v/VKY18IIYQQQggb7Dxmvy5wUmt9GkAp9QfwFPBfmjLdgYVa6/Pm+HT4/VYqw3iEEEIIIYTIYkqp/kqpvWl++t9RpAhwIc3ri5ZpaZUHPJRSm5RS/yqlet7vfaVnXwghhBBCCBsys2dfaz0FmHKPIrbe7M6BRK5AbaAlkAfYqZTapbU+freVSmNfCCGEEEIIG+z8NJ6LQLE0r4sCITbKRGqtrwJXlVJbgOrAXRv7MoxHCCGEEEIIx9sDlFNKlVJK5QReAJbcUeZvoIlSylUplReoBxy910qlZ18IIYQQQggb7Pk0Hq11klJqCLAacAGma62PKKUGWOb/rLU+qpRaBQQBJmCa1vrwvdYrjX0hhBBCCCFssPc36GqtVwAr7pj28x2vxwHjMrpOaewLIYQQQghhg70b+1lBGvs2KKXew/wc02TMl0heA+YBdbTWkXeU3aG1bniPdS0CSgFugA9wxjJrEDD3LuvsDFTSWo+9yzpLAsu01lUePLvsa+C4l6jbpjrXr93km9emcvLguXRl/Ep4M3rmINw98nHy4Dm+7jeZpFvJ5M2fh3emvYZvMS9cXF1Y8N1K1vy2FZ8inrw9tT8efgXQJs2KGRtZ/ONaB2SXqk79Mgwc0RbDMFj1937mzd6ersygEW0JbFiOG9dvMf6Tvzl5LAyA2Ytf51riDUwmTXKyiSG9pgEw+vNnKVbCC4B8brm5mnCdgS/f64Z/x6hftSTDezTHMAyWbDrE7GV7rOa3bRhAj46BAFy7cYuvZ67jxHnzx+P9fm1oVLM0V+IS6f7ubLvHntneGwubdoKnByyd6ehoHl3TEiUZ08xct/MPH+LnvXtslqvm58dfz7/I6yuWs/LkiZTphlL8/eJLXE5IoN+SxXaK+uE0KV2C91o3x0UZ/HnwMFN2Wufaslxp3mjWEK01SSbNF2s38e9F8z12PQNr8lyNKigU8w8cYtae/Y5I4YHUq16SYb2fwMVQLN1wmF//3m01v0RhT94b2JbypXyZ/Md2fl+2N2Xe8x1q0alFVQBOnY/k859WcfNWsl3jfxiDvutD3fa1uJF4g3F9fuDk/jPpyjw1uB1Pv9GRImX9edanL3FR8QAUq1CYt6YPpmytUsx4/3cWfLPU3uHfU516pRk0rC2GoVi59ADzftuRrsygYW2o26AsN67fYtznSzl5PIyixT15/5NnUsr4F/Zg1rTNLJq/mx59m9Khcw1iYxIBmD55I7t3nrJbTuLepLF/B6VUA+BJoJbW+oZSyhvIebfy92roW+Y/bVlvc+AtrfWTad7rbsssIf0NGU4tsE01ipTxp0/1kQQElmHot71444lP0pXr9+nzLPxhNZsX/MPr3/WiXa9mLJu2gc79W3I+OIQPn/uWAt7u/LJvLBvm7SA5KZkp7/7OyYPnyOOWm++3fsy+DUc4H3znze32YRiKISPbM2rIb0SGx/G/Wf3YufUY58+knu8FNixLkWJe9Hn2ewKqFOH1dzryet9fUua/PXA2cbHXrNb7xXt/pfzd/43WXE24kfXJPCBDKd7u1YKhX/1FeHQ8Mz95ia37TnEmJDqlTEhELAM/n0984g0aVCvJqL6teeWj3wFYtvUIf649wIcD2jkqhUzVpT10fwZGfeHoSB6doRQfP9GCngv/IiwhnsUvvsS606c4GR2drtzIxk3Yei79iXyfGjU5FR2NW8677m6zBUMpPmzbgj6/LyQsLp6/+nRn/YlTnIpMzXXn2QusP/EbABV8vPnumY60mzyLcj5ePFejCl1n/M6t5GR+eeEZNp08w7krMQ7K5v4MpXirb0ve+HwB4VHx/PLlS2zde5Kzl1LzjUu4xsSZG2hap6zVst4ebnRrX4vuw2dy81YSnw57klYNA1ix+Yi903ggddvXpEjZQvQuP5SK9crx+o+v8nqD0enKHd4ezK5l/zJ+40dW0+OjE/jhjek06lLXThFnnGEoho5ozzvD5hAZHsf3015h57bjnD+begyq26AMRYp60vv5H6lYuQivv9We1/vP4OL5aAb0npaynt8Xv8H2zcdSlvtr3m4W/L7L7jllNTsO2c8y8jSe9AphfqTRDQCtdaTWOqVlqJTKo5RapZR61fI6wfK7ueULDhYopYKVUnPU3Vrz1oYqpfYppQ4ppQIs6+qtlPre8refUmqRUuqg5cfq5EIpVVoptV8pFWhZbqElvhNKqa/TlGujlNppea8/lVJululjlVL/KaWClFLjLdO6KaUOW95vy6P8MzOqwZO1WPe7uYc7eM8p8hXIi6dfgXTlqjeryNZF5l60tXO20eDJWoD5Bpo87rkByJ0vF/FXrpKcZCL6cmzKFYJrCde5cCwE70Ie9kjJpgqVixBy8QphITEkJZnYvOYIDZtWsCrTsGkF1q44CEDw4Uvkc8+Fp5dbht+jWatKbFxzz3t1HKJSGX8uXo4hJCKWpGQTa3cF07R2Gasyh06EEp9oPlE5fDIUXw/3lHkHjl0i7up1u8aclQKrQ0H3+5d7HFT39+dcbAwX4mK5ZTKx7HgwrcuUSVeuV40arD5xgshriVbT/d3ceKJUaeYdPmSvkB9atcL+nLsSw4UYc67L/ztGq3LWuSbeupXyd56cOdCWO/zKeHly8FIo15OSSNaa3ecv0rqCdQM5u6lU1vK5DTd/btftOEaTQOuYr8Rd4+ipyyQlm9It72IY5MrpiouhyJ3TlcgrCfYK/aE1eCqQdb9uBuDoPydwK5gPT/+C6cqdOnCWy+ci0k2PiYjj+N5TJN1KyupQH1iFioUJuRidcgzatP4IDZuUtyrToHEF1q0yfxaPHrmEm3vudMegmnVKEXrpCuGXY+0Wu6NorTLtx1GksZ/eGqCYUuq4UupHpVSzNPPcgKXAXK31VBvL1gSGAZWA0kCjDLxfpNa6FvAT8JaN+ZOAzVrr6kAtIKVLRClVAfgL6KO1vn0duQbwPFAVeF4pVcxydeJ9oJXlvfYCw5VSnsDTQGWtdTXgM8s6xgBtLe/ZOQM5PDLvQh5EXIxKeR0ZEo1XYetGeX4vN67GJGKyHFAiL13B21JmyeR1FK9QmLknv2PyP5/z08g5KQfY2/yKe1OmegmC9zru0qK3jzsRaXaOEeFxePlYt/i8fN2JuByX8joyPB4v39tlNF/+72V+mNWPDl1qpVt/1ZrFuRJ9lZAL0enmOZqvhxuXo+NTXodHJ+DjcffWbufmVdgZlP7Such+/PO5ERqfWreh8Qn45bOuW798brQpU445h4LSLf9Bs+aM3bYF02PQh+bn7kZYXGquYfEJ+LmnPxlvXb4Mq17rxZTnuvDucvPQwRMRUdQpVpSCeXKT29WVZmVKUih/xk/kHcHH043LUan5RkTF4+ORsZgjryTw+7I9LPrxVZZMHkDCtZvsDkp/VSe78S7sSfiFNMeji1F4F/F0YESZx9vHnYhw6+OL9x3HIG8fd8KtysSlK9O8ZSU2rrO+QvPUs3WYPOtVRrz7JG6WzjeRPUhj/w5a6wTM30zWH4gA5imleltm/w3M0FrfbcDwbq31Ra21CTgAlMzAWy60/P73LuVbYD4RQGudrLW+3VL0scTzstb6QJry67XWsVrr68B/QAmgPuYTkO1KqQNAL8v0OOA6ME0p9Qxwu7ttOzDTcvXCJQM5PDobJ7x3Pu7K1oWS2w362q2qcCroPN3LvsGghh8w+Jse5E2zs8mdLxcfzBnKz+/MITHegb3DtvJMV+TuhYb1m8HgnlN5b9hcOnWrQ9Waxa2KNW9ThY2rs1+vPnCXOrbduKtdsRidmlbh+3lbszgokSlsbrLWdftBs+Z8tW0rpjvqvEWpUkQlJnI4PDwrI8w0tr/eMv12vPb4KdpNnsWgBUsY1tR8QfZUVDRTd+1hxovP8MsLTxMcHkmSKZuf4Nja72ZwUfd8uWhSpyxdh0yj84DJ5MmVg7aNK2ZufFnA9rHGAYFkgYzkZmtMQtp9taurQYPG5dm8IfXR7ksX/Uuv535gQO+pREcl8NqQVpkWs8PpTPxxEBmzb4PWOhnYBGxSSh3C3DgGcyO4vVJqrrbdSkk7UDqZjP1/by+T0fK3xQIXMF89SHt6bSsGBazVWr9450qUUnUxf+XyC8AQoIXWeoBSqh7QETiglKqhtY66Y7n+mE+ImDx58gOEnapT/5a0722+cHL83zP4FPUCzDfseRf2JDr0inXCkfHkK5gXw8XAlGzCu4gHUaExALR5uQnzJywHIOR0OGHnIihWvjDH/j2Ni6sLH8wZyoZ5O9i+5N+HijWzRIbH45NmeJKPb36iI+LvKBOHj1/+lNfevu5EWcpER5ovgcdcSWTHpmNUqFSEQ/vPA2C4KBo3D2BwL1sXnRwvPDoBP8/U3iFfTzciY9Jf0i9bzJvRr7Rm2PiFxCU4z7AdZxaWkEAh99S6LeTuRvhV67qt6ufHpA4dAPDInYfmJUuRpE3U8C9Ey9JlaF6qFLlcXHHLmZMJbdszfPVKu+aQUWHxCfjnT83V392N8Pirdy2/98IlinkUwCNPbq5cu86Cg0dYcNC8yx7erBFh8fF3XTY7iIiKx88rNV8fL/cMD8WpU7UEIeGxxMSb7zHatPsEVSsUZvW2e37/j0N0HtSWDv3MDdRje0/iW8wr5cDqXdSLqJDsd7X0YUSEx+Hje8fxJTL+jjLx+PrmT83fNz9Rkal1Hli/LCePhxFzJXW7T/v3iiX7+XTc81mTgAM4w9N4pGf/DkqpCkqpcmkm1QBuX3ccA0QBP9oxpPXAQEtsLkqp25/Sm0AXoKdSqvt91rELaKSUKmtZT16lVHnLuP0Clme6DsOcK0qpMlrrf7TWY4BIrL+6GQCt9RStdR2tdZ3+/fs/VGJLp6xnUMMxDGo4hh3L9tHqRfOop4DAMiTGXSPaxljAg1uO0uRp89NaWr/UmJ3L9wEQcTGaGs0rAVDQNz9FyxUi9Ky5p3D4j69w4VgIC79f/VBxZqZj/12iSDFP/AsXxNXVoFmbyuzcav0N1zu3Hqd1h+oABFQpwtWEG0RHJZA7dw7y5DXfvJg7dw5q1SvN2VOpvaG1Aktz4VwUkeHZs/Fw9HQYxfwLUsgnP64uBq3rB7Bl32mrMn5e7ox9ozMfTV7JhbAYxwQqHlhQWBglCxakaP785DAMniwfwLpT1nXbbMYvNJ1u/ll58gQfbljP2lOnGLd9G41+mUrT6b/w+srl7LxwIds29AEOhYRR0sODogXMuXasVIH1J6xzLe6RekJfyc+XnC4uXLlmPnH1zJsHgEL53WkTUJZl/x0jOzt6KoyiaT63rRpWYFsGh0JejoyjcrlC5Mpp7seqU6W41Y292cmSH1czoNbbDKj1NtsX76FVD3NHVMV65bgam0i0k+yPjgWHUKSoJ/6FzMeg5i0rs3PbHcegbcdp1c78BKWKlYtwNeE60VGpjf0nWldm41rrITxpx/Q3alaBs6fT38sgHEd69tNzA/6nlCoIJAEnMfdg336KzjBgulLqa631SDvE8wYwRSn1Cuae+oFAKIDW+qpS6klgrVLqrl1LWusIy1Ck35VSuSyT3wfigb+VUrkx9/6/aZk3znLCozCfbBzM/LSs7V59kMC21ZgRNI4b127wzYBpKfM+/Ws4EwdPJzoshl8+mM/omYPo/cGznAw6x+pZ5vuH54z9m7cmv8rP/3yGUopfPphPXFQClRuUo1X3Rpw+fIEfd5if7jPjowXsWZN+3LA9mJI1349byReTXsIwFKuXHuDc6Qg6PlMbgOUL/2X39hPUbViWmQuHmB+9+an5wUwFPfPx4bjnAHBxMdi4+jB7d6UedJu3qZwtb8y9LdmkGT97I5PefhbDUCzdcpgzl6J4ukU1ABZtCOKVLvUp4Jabkb1ampdJNtH7w7kAfDqoA7UqFqWgWx6WfvcqUxbuZOnm7Jvv/Yz4GHYfgJhYaN4VhvSBrh0dHdXDSdaajzZuZNbTz2IoxZ9HDnMiOoruVc11O9fGOP3HVbLWfLJmA7+88AwuhmLBwSOcjIzihZrmXP/YH0TbCuXoUrUSSaZkrt9KYtii5SnLf/9sJwrmyU1SsomPV28g7nr2e3JWWskmzYTpG5g4+llcDINlmw5z5mIUXVqZ8128LgjPAnmZ/uXL5MuTE5PWPN+hFt1HzOS/k2Fs/OcEM8f2INlk4viZcP5el/23hd0r9lGvQ01mnfgfNxJvMr7vDynzPl/2LhNe/Zmo0Ct0Gdqe595+Ck//gkw5OJ7dK/cz4dWf8fAryA97xpI3fx60SfPMGx3pV/lNEuOv3eNd7cOUrPl+4iq+nPAihovB6mUHOHcmkict94AtW7yP3TtPUq9BWWbNH2w+Bn2R+ujQXLlcqR1Yim+/tvrOJ14d1JIy5fzQWnM5LDbd/MeZMwzhUncbMyvEA9Bt3Xrdv9RjbnXCLADa1E3/SFBntGb3GADq9Zjg4Eiy3j+/DgfAFFb+PiWdg+Fv7skr/a3z1+3pYea6Lf/FRAdHYh/HR5v7bBo+/42DI8l6O+aNAKC10c3BkdjHWtOfALRu9Nl9Sj7+1m5/H2zfImN3ZeZ9nmkN5VPPv+eQnGQYjxBCCCGEEE5KhvEIIYQQQghhixPcoCuNfSGEEEIIIWxwhtHuMoxHCCGEEEIIJyU9+0IIIYQQQtjiBD370tgXQgghhBDCBvlSLSGEEEIIIUS2JT37QgghhBBC2CLDeIQQQgghhHBOMoxHCCGEEEIIkW1Jz74QQgghhBC2yDAeIYQQQgghnJUM4xFCCCGEEEJkU9KzL4QQQgghhC0yjEcIIYQQQggn5QSNfRnGI4QQQgghhJNSWjvBKYtwNNmIhBBCCJGZssWdsSVnfJ1pbZyzfUY6JCcZxiOEEEIIIYQNztAnLo19kSnaFejr6BCy3KrY6QBUfneigyOxjyNfvglAq2ZfODiSrLdu82gASn87wcGR2MfpYcMBMIWVd3AkWc/wPw5A/Ze+cXAk9rFrzggAGj7v/PnumGfOtX2hwQ6OxD5Whv4AQLMOXzs4kqy3ecVIR4fgVKSxL4QQQgghhC3Ssy+EEEIIIYST0tni1oFHIk/jEUIIIYQQwklJz74QQgghhBA2KBnGI4QQQgghhJNygsa+DOMRQgghhBDCSUnPvhBCCCGEELY4wQ260tgXQgghhBDCFhnGI4QQQgghhMiupGdfCCGEEEIIW5ygZ18a+0IIIYQQQtjiBI19GcYjhBBCCCGEk5KefSGEEEIIIWyRp/EIIYQQQgjhnOQbdIXdKKUStNZumbi+ksAyrXUVpVQdoKfW+vXMWv/DGPhVdwLbVOVG4k2+GfQLJw+eT1fGr4Q3704fgLtHPk4ePMe4/lNJupVM19fb8US3+gC4uBoUq1CY58u8QcKVqwAYhmLS5jFEhcTw4fPf2TWve2lcvgSjnmyOi2Hw157DTNu8x2r+ExVLM7R1Q7TWJJk0Xy3bxL5zIeR0dWF2/+fI6eqCi2Gw5vAJfli300FZ3Ftg3dIMGtoaw1CsXH6QP+amj3Pw662pW68MN24k8fWXSzl54jIAz3YLpH3HGmgNZ86EM27sMm7dTKZ0GV+GjWhHnjw5CQuL5ctP/yYx8aa9U7unpiVKMqZZcwzDYP7hQ/y8d4/NctX8/Pjr+Rd5fcVyVp48kTLdUIq/X3yJywkJ9Fuy2E5RZ433xsKmneDpAUtnOjqazFe/Wkne7PEEhqFYsukwvy7dbTW/bcMAenSqC0Di9Vt8PWMdJ89HOCLUh1KvekmG9X4CF0OxdMNhfv3bOr8ShT15b2BbypfyZfIf2/l92d6Uec+1r0nnltUAWLLhEPNX7LNr7Bk14NNuBLaszI1rN/lm2K+cOnQhXRm/Yl6M+rkv7gXzcvLQBcYPnUXSreSU+eWrF2fC8rcZ+9p0ti3fj3fhgrw1qRcevvnRJs3K37bx97RNdszq/urWLsXQ11piGIrlq4OY++c/VvOLF/Vk1JvtKVfWj2mztjJvoXk/ljOHC5O+7k6OHC64uBhs3naMGXO2OyIFkQEyZl+gtd7r6IZ+YOuqFC7jR9+a7/LdG7MYMqGnzXKvfNyNRT+u4ZVa75IQc5W2PZsAsGDSKgY3+YjBTT5ixsd/cWj7sZSGPkCXga25cCzULrlklKEU73VuwYAZi+k8cRYdqlegjK+nVZl/Tl3gmUm/8ez/5vDBX2v4+JnWANxMSqbvtAXmeZN+o3H5ElQr5u+INO7JMBRDh7Vl9Mh5vNJrCk+0rETxEt5WZerWK0ORop70eulnJo5fwRvD2wHg5e1Gl2cDGdR/Bq/2mYqLYfBEi0oAjBjZgWmTN/Fqn2ls33qM516ob/fc7sVQio+faEGfxYtoO3smnSoEUNbT02a5kY2bsPXcuXTz+tSoyanoaHuEm+W6tIcp4xwdRdYwlOKt3i158+uFvDhyJm0aVKBkEeu6DomIY+Cn83j53dnMWLyTd19p7aBoH5yhFG/1bcmILxfSffhMWjVKn19cwjUmztzA70v3Wk0vXcyLzi2r8croOfQaOZtGtUpT1L+gHaPPmMAWlSlc2odXGn7EpLfnMmTsCzbL9X2/C4unbKBfo49JiE2k7YsNU+YZhqLP+13Yt+loyrTkJBNTP17Ia00/5c2O43iyd1OKl88++2nDUAwb1IqRY/6k14BfaNmsIiWKeVmViYu/zqSf1zPvL+vOipu3knnz3T94ZchMXhkyk7p1SlGpQiF7hm8/OhN/HEQa+48ZpVRzpdQmpdQCpVSwUmqOUkpZ5o1VSv2nlApSSo23TJuplOqaZvmEu6xzmeXvj5RS0y3vcVopZZeTgAYda7L+9x0ABO89jVuBvHj6FUhXrnrTALYuNh9Q1s3dQcOOtdKVad61HpsWpPZOeBf2ILBtNVbN3pJF0T+cqsX8uRAVw8UrsdxKNrHi4DGeqFjGqkzizVspf+fJmQOdZm9xe56ri4GrYWTLBwZUqFiYkEtXCA2NISnJxKYN/9GocTmrMg0bl2ft6kMAHP0vBDe33Hh65gPAxcUgVy5XDBdFrlyuREWaN9+ixbwIslz5+XfPGZo0C7BjVvdX3d+fc7ExXIiL5ZbJxLLjwbQuUyZduV41arD6xAkiryVaTfd3c+OJUqWZd/iQvULOUoHVoaC7o6PIGpXK+HPxcgwhEbEkJZtYu+sYTWuXtSpz6EQI8Yk3ADh8IhQfz0y7SJvlKpW15Bduzm/djmM0CbTO70rcNY6eukxSsslqeokiXhw+EcqNm0kkmzT7/7tIs7rWn//soH67aqy39GgH7zuLW/48ePjmT1eueuPybF22H4B18/+hQftqKfM6v9Kc7csPEBMZnzLtSnhcyhWCa1dvcOHEZbyy0clOxfKFuBQSQ2hYLElJJjZsOUrjBtZ1GxObSPCJsHR1C3DtuuUY5Grg6uKSLY9Bwkwa+4+nmsAwoBJQGmiklPIEngYqa62rAZ89wvoDgLZAXeBDpVSORwv3/rwKeRBxKbUXMyIkGq/CHlZl8nu6cTU2EZNlpxMREo1XoYJWZXLlyUmdVlXYtuTflGmvjX2RX8b8iTZlr12RX343QmNTDwyX4xLwK5C+EdCyUhmWvtmLn3p14YO/1qZMN5Tir6EvsfW919h58jyHLoTZJe4H4e3tTnh4XMrriIh4vLzd7yjjRsQdZbx93ImKTODPP/5h7vwhzF/4Blev3uDfvWcAOHsmgoaNzI2Gpk9UxMc3e7Uk/fO5ERqfWreh8Qn45bOO0S+fG23KlGPOoaB0y3/QrDljt23BJIfPbM/H043wqNS6Do+Ox8fj7o35Ts2rsuvgWTtEljl8PN24nCa/iKh755fW6QuR1AgoQn633OTK6UrDmqXw9cpen1UAL/8CRIbEpLyODI3B+45jS37PfFyNvZZy/IkMvZLScPfyL0DD9tVZMXvrXd/Dt6gnZaoW5di+s5kc/cPz9nIjPM3JSURkPN4PUD+GoZj2v14snjuEvfvPcjSbXT0XqaSx/3jarbW+qLU2AQeAkkAccB2YppR6Bki8++L3tVxrfUNrHQmEA36PGO99KRs3u2ut7yiTvtAdRajXvjpHdp1MGcJTt211YiLiOHkg/TCJ7OjOnAHW/3eKThNnMfTXJQxtnXrZ2KQ1z/5vDi3GTqNqUX/K+nmlW9bRbNVr+jK269XNLTcNG5fj5Rd+5PlnJpE7dw5atq4MwPivltP56dr8OKUPefPktBo3my3Y2p7vaLh/0Kw5X23biumOOm9RqhRRiYkcDg/PyghFJlG2K9umWpWK0bl5Fb7/I3tdZbwnW5/PDC567lI0vy3Zw3fvd2Xi6Gc5cS6CZBs9xI5mex+UkeOPucxrn3Rl+meLMd2lQyl33ly8/8urTB6zgMSE65kQceawlVO6g+o9mEyafkNn0a3nT1QsX4hSdwzRdBZKZ96Po8gNuo+nG2n+TgZctdZJSqm6QEvgBWAI0AJIwnJSZxnuk/Nh1n9nAaVUf6A/wOTJkx8iBejUrwXtejUF4Pj+M/ikGQfqU9iT6NAYq/KxUfHkK5AXw8XAlGwylwmzLtPsGeshPJXrl6V++xrUbV2NHLlzkNc9NyOnvMrX/ac+VMyZ6XJcAoUKpPai+OV3Izzu6l3L/3v2EsU8C1Awb25iElMPGPHXb7D7zEUaly/JyctRWRrzg4qIiMc3zeVwHx93otL0JN0u42OjTK06JQkLjSE21nzeum3rMSpXKcr6tUe4cD6KUW/9AUCRop7Uu+PSs6OFJSRQyD21bgu5uxF+1XoEXVU/PyZ16ACAR+48NC9ZiiRtooZ/IVqWLkPzUqXI5eKKW86cTGjbnuGrV9o1B5Ex4dHxVr3Vvp7uRMSkGy1J2WLejO7Xhje/XkhcNmrw3U9EVDx+afLz8XIn8kr6/O5m2cbDLNt4GIDXXmhMRHT8fZawjyd7N6XdS40AOH7wHN6FC6bM8y5UkKiwWKvysVEJ5CuQJ+X4413Ig+jL5jLlqhdn1M99AfMV6MCWlUlOTmbnqiBcXA3e/6UfGxfuYceKg/ZJLoMiIuPxTXOl1cfbncjojNftbQlXb7D/0Hnq1i7FmXORmRli9uAEj96Unn0noZRyAwporVdgHuJTwzLrLFDb8vdTQKYMydFaT9Fa19Fa1+nfv/9DrWPptA0pN9XuXLaflpabnQLqlOZqXGLKjjStoK3BNOlSB4BW3Ruyc8X+lHl58+ehWuPyVtNmfPwXPSq9Ra9qIxnb92cObgnOFg19gMMXwyju7UERj/zkcDHoUL0CG4+etipT3Cv1voWKhX3J4eJCTOJ1PPLlwT13LgByubrQoExxzkRkv5s5jwWHUKSoB/7+BXB1NWjeohI7tp+wKrNz+3Fat60KQMVKhbl69QbR0VcJvxxHxUpFyJXLfK5Zs1ZJzp8zn8wULJgXMHc6vtyzEcuWZK8nfASFhVGyYEGK5s9PDsPgyfIBrDtlXbfNZvxC0+nmn5UnT/DhhvWsPXWKcdu30eiXqTSd/guvr1zOzgsXpKGfjR09HUYx/4IU8smPq4tB6/oV2PrvKasyfl7ufDmsMx//tJILYVccFOnDOXoqjKJp8mvVsALb9p66/4IWHvnzAOb/QfO65Vi7PTirQn0gy2ZuYUjrLxnS+kt2rjxIy271AAioVZKr8de4kmZo4W1B24/T5MmaALR6rh47V5mH4PWp9yG9646hd90xbFu2nx9GzUuZN2zCy1w4EcaiyRvslFnGBR8PpWhhD/z9zPvnFk0rsn3XyQwtWyB/HtzymY9BOXO6UqdGCc5fzH7HIGEmPfvOwx34WymVG/Mggjct06dapu8G1gN37zp2oN1rgghsU43pB8ZyI/EmEwZPT5n3yZ/D+HboTKLDYvjlwwW8O/01er3/NKeCzrM6zRjJRk/W4t8NR7iRzR7BeDfJJs3nSzYwpe8zGEqxaO8RToVH8Vxd801f83cH0bpyOTrXqkRScjLXk5J46/flAPi45+OLbm0xlMJQitWHjrM5+Iwj07HJlKz537drGDv+BQzDYNWKg5w7G8mTnc0HzGVL9vPPrlPUrV+W2XMHcuPGLcaNXQZA8NEQtmwO5qepr5CcbOLkyTCWLzWfyD3RsjJPPW2+OXvblmOsWpF+3LsjJWvNRxs3MuvpZzGU4s8jhzkRHUX3qua6nWtjnL4zG/Ex7D4AMbHQvCsM6QNdOzo6qsyRbNKMn7mB7955FsMwWLb5MGcuRfG05XGTi9YH8crTDSjgnoe3+7Q0L5Nsos8HcxwZdoYlmzQTpm9g4uhncTEMlm06zJmLUXRpZc5v8bogPAvkZfqXL5MvT05MWvN8h1p0HzGTxGs3+Xx4Zwq45yEpOZnx09cTf/XGfd7R/vasP0Jgy8pM3/kR16/dZOKbv6XM++S3QXw7Yg7Rl2OZ/tliRv3cl57vdOLU4Qus+f3ejzuuXLcMrbrV48x/l/h+7bsAzPpyCXs2HMnSfDIq2aT59qd1jP+sG4ahWLHmEGfPR9G5Qw0Alqw4gKdHPiZ/15N8eXNiMmm6dqlDr9d+wcvTjdEjOmAYCqUUm7YeY+fujJ8EPlac4NYpZWuMsBAPSLcr0NfRMWS5VbHmE5DK7050cCT2ceRL8/liq2ZfODiSrLdu82gASn87wcGR2MfpYcMBMIWVd3AkWc/wPw5A/Ze+cXAk9rFrzggAGj7v/PnumGfOtX2hwQ6OxD5Whv4AQLMOXzs4kqy3ecVIsHn3k/2Vnjgh0xrKp98c7pCcpGdfCCGEEEIIG5zhG3RlzL4QQgghhBBOSnr2hRBCCCGEsMUJevalsS+EEEIIIYQtTtDYl2E8QgghhBBCOCnp2RdCCCGEEMIGZ7hBVxr7QgghhBBC2CLfoCuEEEIIIYTIDEqpdkqpY0qpk0qpUfcoF6iUSlZKdb3fOqWxL4QQQgghhC06E3/uQynlAvwAtAcqAS8qpSrdpdxXwOqMpCCNfSGEEEIIIWxQOvN+MqAucFJrfVprfRP4A3jKRrmhwF9AeEZWKo19IYQQQgghHK8IcCHN64uWaSmUUkWAp4GfM7pSaewLIYQQQghhSyYO41FK9VdK7U3z0/+Od7N1N/Cd1wS+Bd7RWidnNAV5Go8QQgghhBA2ZOajN7XWU4Ap9yhyESiW5nVRIOSOMnWAP5RSAN5AB6VUktZ68d1WKo19IYQQQgghHG8PUE4pVQq4BLwAdE9bQGtd6vbfSqmZwLJ7NfRBGvtCCCGEEELYZscv1dJaJymlhmB+yo4LMF1rfUQpNcAyP8Pj9NOSxr4QQgghhBC22PkbdLXWK4AVd0yz2cjXWvfOyDqV1k7wPcDC0WQjEkIIIURmyhZfXVv+s4mZ1sY5/v6bDslJevaFEEIIIYSwITNv0HUUaeyLTNGu8nuODiHLrTryOQB1e09wcCT2sXvmcACqvz7RwZFkvYOT3gSg/BfOnyvA8dHmfOu/9I2DI8l6u+aMAMAUVt7BkdiH4X8cgGadxjk4kqy3eenbALSrMcbBkdjHqgOfAFDtTeffTwVNfNPRITgVec6+EEIIIYQQTkp69oUQQgghhLBFhvEIIYQQQgjhnJxhzL4M4xFCCCGEEMJJSc++EEIIIYQQtjhBz7409oUQQgghhLDFCRr7MoxHCCGEEEIIJyU9+0IIIYQQQtjgDDfoSmNfCCGEEEIIW5ygsS/DeIQQQgghhHBS0rMvhBBCCCGEDTKMRwghhBBCCGflBI19GcYjhBBCCCGEk5KefSGEEEIIIWxxgp59aewLIYQQQghhg4zZF9meUioZOAQoIBkYorXeoZQqCZwBPtNaf2Ap6w2EApO11kOUUh8BCVrr8VkdZ+3G5Rg4qiOGi8Gqv/Yyf9qWdGUGvtuRwKYVuHHtFt+89xcnj4YA8Oanz1CvWQVioq8yoMuklPKlAwoxdExncubKQXKSie8/W8LxQxezOpUHUr9qSUZ0b45hGPy95RCzl++xmt+2QQA9OwQCcO36Lb6avY4TFyLx9XTjo1fb41UgL1prFm06xLy1+x2RwgNpWLEE7zxjznfRzsNMX2edb4c6AfRpWQeAxJu3+Hzeeo6HRALwcvOaPNOgKlprToRGMmbOGm4mJds9h4xqUroE77Vujosy+PPgYabstM61ZbnSvNGsIVprkkyaL9Zu4t+L5m26Z2BNnqtRBYVi/oFDzNqT/es2rfrVSvJmjycwDMWSTYf5deluq/ltGwbQo1NdABKv3+LrGes4eT7CEaFmiffGwqad4OkBS2c6OppHV7dWSYa+2hLDUCxfG8TcBdb1WbyoJ6PeaE+5Mr5M+3Ub8xZZb+uGoZgyoQcR0Qm8+8lCe4aeIbUblmXgyA4YhmLVon3Mn7E1XZmBIzsQ2LgcN67f4psxizgZHEqOnK6Mn96XHDlccXE12LruCL/9tDFlmc4v1KPzC/VITjaxe+txfvl2jT3TypBGASV45+nmGMpg4T+Hmb7+jn1yrQD63t4n37jFZwtS98kvNa3Js/WrgFIs3HmI37Y8Xvup/0+kse/8rmmtawAopdoCXwLNLPNOA08CH1hedwOO2DtAw1AMfq8To1+dQeTlOCbNG8iujUc5fyr14B/YpDyFS3jTt/0EAqoVY8iYzgx78WcA1i7ex9K5u3jry65W631leFvm/LiRvduOE9ikPP2Gt2Vkn1/smtu9GEoxskcLhoz7i/DoeGZ9+BJb95/iTEh0SpmQiFgGfDmf+MQbNKhaknd7t6bvp7+TnKz57o/NHDsXTt7cOZj90cvsPnLOatnsxlCK0d1a8NoPC7kcE8/ct7qz6fApToelxnwpKpa+k/4k/toNGlUsyZgXWvHyhD/wLZCP7s1q8vQXs7hxK5mv+3SkXa0KLNn9nwMzujtDKT5s24I+vy8kLC6ev/p0Z/2JU5yKTM1159kLrD/xGwAVfLz57pmOtJs8i3I+XjxXowpdZ/zOreRkfnnhGTadPMO5KzEOyubBGErxVu+WvP7lAsKj45nx6Uts3XeSs5fSbtdxDPx0nnm7rl6Sd19pzSsfznVg1JmrS3vo/gyM+sLRkTw6w1AMG9CaER/MJyIqnskTerD9n1OcuxCVUiYu/jqTpqyncf2yNtfRtVNtzl2MIm/eXPYKO8MMQzH43ScZPWCW+fgz5zV2bQ7m/Ok0x5/G5Shc3Iu+nb8joGpRhrzXiWE9pnDrZhLvvDqT69du4uJq8M2MfuzddoLgQxepVqcUDZoHMLDbD9y6lUwBj3wOzNI2QylGP9uC/j+b98m/v2nZJ19Os0+OjqXP9+Z9cuOAknz4XCte+vYPyvp78Wz9KnSfaN5P/fTaM2z57wznI2Mcl1BWcYKefblB9/+X/MCVNK+vAUeVUnUsr58H5ts7qApVixJ6IZqwi1dIupXM5hVBNHiiolWZBi0qsn6JudcgOOgCbu658fR2B+Dwv2eJj020ue68buaDSz733ERFxGdhFg+ucml/Ll6OISQilqRkE2v+CaZpzTJWZQ6dDCU+8QYAh0+F4utpzjkq9irHzoUD5p7RMyFR+Hi42TeBB1SlhD8XImK4FGXOd9W+YzSvap3vwTOhxF8z5xt0NhS/gu4p81wMg1w5XHExFHlyuBIRl2DX+B9EtcL+nLsSw4WYWG6ZTCz/7xitylnnmnjrVsrfeXLmQGvzEaWMlycHL4VyPSmJZK3Zff4irSvYbkRlR5XKWG/Xa3cdo2lt6/gPnQhJ3a5PhOLjmb233QcVWB3SbLqPtYrlCnEp9Aqhl2NJSjKxYUswjetZ12dMbCLBJ8JISjKlW97Hy436gaVZtuaQvUJ+IBWqWI4/l66QlJTM5tWHaNA8wKpMg+YBrF92AIDgQxctxx/zNnv92k0AXF1dcHU1sHyMefK5QObP2MqtW+arj7FXrtonoQdQpbg/5yPT7JP3H+OJKnfsk8+m7pMPngvFt4B5wy7l50nQuVCu30oi2aTZe/IiLas9PvupB6Iz8cdBpGff+eVRSh0AcgOFgBZ3zP8DeEEpFYZ5mE8IUNieAXr55SciNDbldeTlOCpUK2Zdxjc/EWGpZSIux+Hll5/oyLs34H8eu5zPp/Tm1bfaoQyD4S9NzvzgH4GPhxuXo1PjD7+SQOXShe5avnPTKuwMOpNueiHv/FQo4cuRU2FZEmdm8S3oRlhMmnxjEqhawv+u5Z9uUIVtR835hsdeZdaGf1n9cT+u30piZ/A5dgafz/KYH5afuxthcam5hsUnUL1w+lxbly/DiCca45k3L/3nLwbgREQUbzZrRME8ubl+K4lmZUpyOOyyvUJ/ZD6eboRHpann6Hgql7n7dt2peVV2HTxrh8jEw/D2ciM8zX42IiqeiuXvXp93GvJqC36esZm8eXJmRXiPzMvX3erYEnk5jgpVi95Rxsbxxzc/0ZEJGIbif78PoHAxT5bO282xw+ahokVKeFG5Vgl6DWnFzRtJTJu4iuNHQuyTVAb5FXTjcpp98uXYBKoWv/s++Zl6VdgebN4nnwyNYmiHRhTIm5sbt5JoUqkkRy48Pvup/2+kZ9/5XdNa19BaBwDtgNlKKZVm/iqgNfAiMC+jK1VK9VdK7VVK7Z0yZcojBahQ6abd7uVM8373LXOnJ5+vy+SvVtCj1Tgmf7WcNz99+pHizGw2UuJup/61A4rRuWkVvp9vPZY0T64cjB3SiQlzN3H1+s3MDzIT2Ur3bnUYWK4oT9evzLd/bwPAPU8unqhamg4fT6f1+1PJkzMHHesE2Fw2O7CZq426XXv8FO0mz2LQgiUMa9oQgFNR0UzdtYcZLz7DLy88TXB4JEmmx+c6sq3P8916tGpVKkbn5lX4/o/09+iI7MHmfiqDm2ODwNLExCZy/FT2bQRm5NhyrzImk2bw8z/xcttvqFClKCXK+ALg4mLg7p6HYT2mMO3b1Yz++vksiD7z2dpPAQSWNe+TJy4175PPhEczY8Mepgx8hp9ee5pjIZEkP0b7qQehdOb9OIo09v8f0VrvBLwBnzTTbgL/AiOAvx5gXVO01nW01nX69+//SHFFXo7Fp1CBlNfefvmJDo9LX8Y/tYyPX36iw+89LKfVU7XYvtZ8C8LW1Ycpf0dvjaOFRyfg55l6rd/Xw42IK+mHppQt6s17fVvz9nd/E3v1esp0FxeDr4Z0YvXOo2z696RdYn4Ul2MS8E8ztsG3oBvhcekvbZcr7M2HL7Zm2NQlxCaa861foTiXouK4knCNJJOJ9QdPUr2UXS9APZCw+AT886fm6u/uRnj83S/j771wiWIeBfDIkxuABQeP8PT0ubz025/EXrvOuegrd102uwmPjsfXK009e7oTEWNjuy7mzeh+bXh7wt/EJVxPN19kDxGRCfh6p9anj5c7kdEZG0JXpWIRGtYtyx/T+jNmZCdqVSvOe8M7ZlWoDyXycpzVscXbLz/Rdwz5tHn8uaPM1fjrBO09Q51G5VLWu32D+Z6i44cvYTJpCnjkzao0HsrlmASroZJ+BdyIiLWxTy7kzUfPt+aNX1L3yQCL/jnC89/Mpc/3fxJ39TrnIx6f/dQDcYJhPNLY/39EKRUAuABRd8z6BnhHa33ndLs4dvgShYt74VfEA9ccLjTrUI1dG4OtyuzaGEzLzjUBCKhWjKsJN+45hAcgKjyOaoGlAKhRrzQh5xyS3l39dyaMYn4FKeydH1cXgzb1Ati6/7RVGT9Pd74a2pkPp6zk/OUYq3kf9G3DmdBo5q7eZ8eoH96R82EU9/GgiKc533a1KrD5kHW+/h7uTHilE+/9uopzETEp08OuxFOtZCFy5zCPPKxXvjhnLmffm5EPhYRR0sODogXyk8Mw6FipAutPWOda3CO18VDJz5ecLi5cuWY+kHrmzQNAofzutAkoy7L/jtkv+Ed09HQYxfwLUsjHXM+t61dg67+nrMr4ebnz5bDOfPzTSi6EOWkDwUkEnwilaGEP/P0K4Opq0KJpANt3Z6xzYersrXTr8zMv9JvCJ18vZV/QeT6fsDyLI34wx45conBxT/wKF8TV1YVmbauya/Mdx5/Nx2j5ZA0AAqoW5WrCdaIjEyjgkZd87uYT9Jy5XKlZrwwXzphv7N2x8SjVA0sDUKS4FzlyuBB7xfa9ZY5y5EIYJdLuk2tWYNORO/bJBd2Z2KcTo+dY75MBPN3ypJRpWa0sK/Y9Pvup/29kzL7zuz1mH8yjC3pprZPTXpbUWh/BAU/huc2UbOLHz5fy+ZTeGIZizaJ9nDsVTofnzI/mWzF/N7u3HCOwaXmmrxzOjeu3mPB+6uPbRo17jmqBpclfMC+/rh/Jbz+sZ/XCf/nuo8UMGNURF1eDmzeS+O6jxQ7K0LZkk2bcbxuZ9NazGIZi6dbDnA6J4pknqgGwcGMQ/Z6qTwG33LzTs6V5mWQTvT6eS/VyhenQqBInLkTw2ycvA/Djgu3ssDGmP7tINmm+XLCBnwY9g2EoFu86wqmwKLo1Muf75/YgXmtXj4L5cjO6W4uUZbqPn8uhc2GsPXCCP0a+RHKyieBLESzYkT1v+ANI1ppP1mzglxeewcVQLDh4hJORUbxQ05zrH/uDaFuhHF2qViLJlMz1W0kMW5TaCPr+2U4UzJObpGQTH6/eQNz1G45K5YElmzTjZ27gu3eexTAMlm0+zJlLUTzd0pz7ovVBvPJ0Awq45+HtPqnbdZ8P5jgy7Ew14mPYfQBiYqF5VxjSB7pmrw7tDEs2ab79eR3jP+6KYRisWHeIs+ej6NyuOgBLVh3Es2A+Jk/sQb68OTGZNF0716bXoOkkXsveQwvBcvwZu5zPf+qJYRis+Xsf505F0KGr+bkVKxbsZffW4wQ2Lsf0pcPMx58PFwHg6e3OiE/Nn3FlKLasOcLurccBWLN4P8M/7sLPCwaTdCuZ8R9kv0eOJps0X/y1gZ9eM+ew+B/LPrmhZZ+8I4gBbc375Pe6pu6TX5xgfnLWhD6dKJDXvJ/64q8NKTfyOhtneM6+ut+4ZyEyQLer/J6jY8hyq458DkDd3hMcHIl97J45HIDqr090cCRZ7+CkNwEo/4Xz5wpwfLQ53/ovfePgSLLerjkjADCFlXdwJPZh+Jsbm806jXNwJFlv89K3AWhXY4yDI7GPVQc+AaDam86/nwqa+CbYvv3J7qqOmJhpDeVD37zpkJxkGI8QQgghhBBOSobxCCGEEEIIYYsTDICRxr4QQgghhBA2ZIuxRI9IhvEIIYQQQgjhpKRnXwghhBBCCFtkGI8QQgghhBDOyRkevSnDeIQQQgghhHBS0rMvhBBCCCGELU7Qsy+NfSGEEEIIIWxxgsa+DOMRQgghhBDCSUnPvhBCCCGEEDY4ww260tgXQgghhBDCFmnsCyGEEEII4ZycoWdfxuwLIYQQQgjhpKRnXwghhBBCCFucoGdfae0EWQhHk41ICCGEEJlJOToAgFoDJ2ZaG2ffT286JCcZxiOEEEIIIYSTkmE8IlO0L/q6o0PIcisvTgKgWcevHRyJfWxePhKAtjU/dHAkWW/1/o8BaPj8Nw6OxD52zBsB/P/I93auzTqNc3Ak9rF56dsAmMLKOziSrGf4HwegXfUPHByJfaw6+CkAjbo5/+d2+58jHB1CKicYuyCNfSGEEEIIIWxxgsa+DOMRQgghhBDCSUnPvhBCCCGEEDY4w3P2pbEvhBBCCCGELU7Q2JdhPEIIIYQQQjgp6dkXQgghhBDCBuUE30cljX0hhBBCCCFsefzb+jKMRwghhBBCCGclPftCCCGEEELYIE/jEUIIIYQQwlk5QWNfhvEIIYQQQgjhpKRnXwghhBBCCBtkGI8QQgghhBDOygka+zKMRwghhBBCCCcljX0hhBBCCCFsUDrzfjL0fkq1U0odU0qdVEqNsjH/JaVUkOVnh1Kq+v3Wed9hPEqpZOAQkANIAmYB32qtTUqpOkBPrfXr91i+N1BHaz3kfu+VZpnRWusvMlr+jmVnAs2AWMAEDNZa78zgsr2xxKqUGgAkaq1nP0wcGXy/ksBR4FiayXW11jczaf29gTVa6xDL62nABK31f5mx/sw24JNnCWxRiRvXbvLNm3M4dfhiujJ+xTwZ9WNv3Avm5eShi4x/41eSbiVTv01Ver7dAZNJk5xkYspHCzmy53TKcoahmLTibSLDYvio9xR7pnVPdWuXYmj/lhiGYvmaIOb++Y/V/OJFPRk1rD3lyvoxbfZW5i3cYzXfMBRTvu1JRFQC7378lz1Dz7A6Dcsy4O32uBiKlYv3MX/GtnRlBo5sT91G5bh+/RbffLiYk8GhKfMMQ/G/Oa8RFR7HmDfmAtCkVSV6DHiCYqW8eb3HVE78F2K3fDKqXvWSDOv9BC6GYumGw/z6926r+SUKe/LewLaUL+XL5D+28/uyvSnznu9Qi04tqgJw6nwkn/+0ipu3ku0a/4N6lHyfa1+Tzi2rAbBkwyHmr9hn19gfVN1aJRn6quVzuzaIuQuscy1e1JNRb7SnXBlfpv26jXmLbHxuJ/QgIjqBdz9ZaM/Qs8R7Y2HTTvD0gKUzHR3Ng6vdsCwD3+mIYShWLfqX+dO3pisz8J0OBDYuz43rt/jmg4WcDA4lR05Xxs94hRw5XHFxNdi69gi//bTBarlnezbi1RHteK7Zl8TFJNorpQyrV6Mkw/o8gWEolq4/zG+L79iWC3vy3mDz53bK79v5feley3QPPnnzyZRyhX0LMG3ejmz/2X0odhzGo5RyAX4AWgMXgT1KqSV3tNvOAM201leUUu2BKUC9e603Iz3717TWNbTWlS1v3gH4EEBrvfdeDf1HMPoRl39ba10DGAVMfpgVaK1/fpCGvlLqYe9/OGX5/97+yZSGvkVvoPDtF1rrftm1oR/YohKFS/nwSuNPmfTOPIZ8+ZzNcn1HP8XiqZvo1+QzEmITaftCAwAObDvGoNZfMaTt10x8ay5vjHvRarmnXmnO+ZNhWZ7HgzAMxbCBrRj54Z/0GvgLLZtWpEQxL6sycfHXmTR5fbpG/m1dO9fm3IUoe4T7UAxDMXhUR94f8huvPvsDT7SrSvHSPlZlAhuXo0hxL/o8NYnvPlvK0NFPWs3v0r0+F85EWE07eyqcT0b8waF957I8h4dhKMVbfVsy4suFdB8+k1aNKlCyiKdVmbiEa0ycuSHl4Hmbt4cb3drXou+7c3j5rVkYhqJVwwB7hv/AHiXf0sW86NyyGq+MnkOvkbNpVKs0Rf0L2jH6B2MYimEDWjPyowX0Gjz97p/bKevTNfJv69qpNucuZt/P7YPq0h6mjHN0FA/HMBSDR3fi/UGz6f/0/2jerprNfVTh4l707fQt333yN0Pe7wTArZtJvNNvBoOe+4FBz/1AnUZlCahaNGU5b7/81GpQhsshMfZMKcMMQzHilZaM+HwhL71p+dwWtfG5nZ7+c3s+5Aq93/6V3m//St93fuP6zSQ27z5hz/CdVV3gpNb6tKU9+AfwVNoCWusdWusrlpe7gKLcxwMN49FahwP9gSHKrLlSahmAUqqu5XLCfsvvCmkWLaaUWmW5LPHh7YlKqZeVUruVUgeUUpOVUi5KqbFAHsu0Ofco56KUmqmUOqyUOqSUetNGyFuAsndbh2V6H6XUcaXUZqBRmtg+Ukq9Zfk70HK5ZKdSapxS6rBlem+l1J9KqaXAGqVUPqXUdKXUHsv/4SlLORfLcnss63ntXv9npVRCmr+7Wq5WYMl3kuX/e1op1TVNuZGW/8NBpdRYy7w6wBxLznmUUpssV2NQSr1oKX9YKfVV2vdWSn1uWc8upZTfvWLNLPXbVGW9pXcseN9Z3PLnwcM3f7py1RuVY+vyAwCs+3M3Ddqaez+vJ6aeI+XOkxOtU0/FvQsVpG7LSqyem6ELPHZTsXwhLoXEEBoWS1KSiQ1bjtK4flmrMjGxiQSfCCMpyZRueR8vN+oHlmHZ6iB7hfzAKlQpQsiFaMIuXSEpKZlNqw/ToLl1w7VBswDWLTsAQPChi+Rzz42ntxsA3r75qdu4PCsXWfcWXTgTycVz2bexVKmsPxcvxxASHktSsol1O47RJNC6bq/EXePoqcskJaevWxfDIFdOV1wMRe6crkReSUhXJjt5lHxLFPHi8IlQbtxMItmk2f/fRZrVLWfP8B9IxXKFuBR6hdDLtz+3wTSu96Cf29IsW3PIXiFnucDqUNDd0VE8nApVihJ6ISplH7V51SEaNK9oVabBExVZv/QAYN5HubnnSdlHXb9mPva4urrg6upi1Qn82tsdmDZxDejseYdnxbL+XAyzfG6TTKzffowmde7YluOuEXzqss1t+bY6VYpzKSyGy5HxWR2yQ9h5GE8R4EKa1xct0+7mFWDl/Vb6wGP2tdanLcv53jErGGiqta4JjAHSDsOpC7wE1AC6KaXqKKUqAs8DjSy98MnAS1rrUaReTfi/9u47PKpq6+P4d00C0nsHEaSIgogIIoKKIipYr+K1oCL2q17rtZfrtV+voq9dVLD3goKKoCJNFBGQooA0RQVCKCFUIVnvH2eSTMLQQiYnmfw+z5OHzDlnJmszM2fW7LP23v22dVz0sRq7ezt33x8YEifcE4EZ23oMM2sI/Icgye8F7LeNZg8BLnP3rtH7xuoK9Hf3o4DbgK/cvTNwJPA/M6tM8GRkRLd3Bi42s+bR+7eIJuPTzOypbfz9WA2B7sAJwIMA0cs4pwBd3P0A4CF3fw+YTPB/2sHdN+Q8gJk1Av4LHEXw/9jZzE6J7q4MfBt9nLHAxTsR026r3aA66TG9H+lLVlOnQfV8x1SrWZl1azaQHU0W0pespnbMMYce155BX9/G3a9cyqPXv5G7/dK7TuXF+z4mu4SdcOvUrkJazMlxeXomdWrv/CfmlZf05NkhX+f7YlPS1K5XjeXLMnJvpy/LoE7d/G2sU68qy5euiTlmDbWjX/Quu+E4Xvi/kXh2yW1jPHVrVWHZipjndkUmdWtW2an7pq9ay5vDv+fDpy/m4+cuY+2Gv5g0vWRewcixO+1dsDidDm0aU61KBfYon8qhBzan3i68D4rbVu/bFZnUqb1zbQW48uKjeHbImFL3mk5WtetVY/nSmHNUWga161fd+piY89jyZRm556hIxHjq7ct5a/RNTPl2PnNmBOWnhxzRhhVpa1g4t2RdUY5Vt1YV0mLet2krM6m7C6/lHD27teGLCbOLMrSSxb3IfszsEjObHPNzSYG/ZvEiiBeWmR1JkF/etKMmFLb0JF4w1YGXzaxVNLByMftGufuKaHAfECSrW4CDCOqRACoCaXEet+c2jhsG7G1mTwCfACNj7vM/M7sdWE7wH7Gtx+gCfO3uy6OxvQ20ztdQsxpAVXf/JrrpDYJEO7ZtK6O/HwOclHNFAKgANI1ubx/TE18daAXMJVrGE6fd2zLU3bOBn2J63Y8Ghrj7eoCYeLalM/nb/TpwODAU+AsYHj3uB4IvQQkXfV7yKZjDxj0m5vdvRkznmxHTadelBefdcDy3nvUUB/dsy+r0TObNWMz+XVtudf8wxWvPzhYHdu3cgtUZ65k7bxkd9t+zaAMrQjvVwrjPvdPlsNasXrmOeT8vof1BzRIQXQLt4LW6PVUr78FhnVrS98oXyFy/ifuuPZFju+/L5+N/LtoYi9JutPfXP1by2sff83+392XDxs388utysuJc7SgpduNtS9fOewfv2/nL6NCu5L5vy5J4z+dWnz1x7pdzTHa2c8UZT1O5agXufPQs9mpZj6W/r+LMiw/n1steLvJ4i5LFadmu9h2lpkbo3qkFz76x9TgH2Zq7DyKosd+W34HYk0MTYKtBaWbWHngB6J2TX2/PLif7ZrY3Qe92GhB7reseYLS7/82Cgadfx+wr+PJxgvfPy+5+y47+5LaOs2AE8rHAFcDfgQuiu26I9mznHHdkvMeI9mbv6KUd730ea12BY09z99gBt1iQ1f3T3T8vsL3ZNh4zNqYKBfZtihObsfOfrbH3i2ez53UVZ7GN10j02+glAM89V6hhEZzQ/zCOOzuouZ/742/UaVQjd1+dhjVYEdOTApCxci2Vq1UkkhIhOyubOg1rsHJp/mMAZn43n4Z71aFazcrs13lvDjlmfzoftR/l9ihHpaoVuOHxc/nfVa8WKuaitDw9k3p18nqQ6tapSvqKnSvXaLdfYw7t0pIunfamfPkUKlfcg9v+dTz3PfxJosItlPS0NdStn3f1pU796qxYnv9Sb/qyNdRtUC3mmGqsXJ7JYUe35ZAj9qFz91aUL59Kpcp7cOO9p/LQ7SV/QOPyFZnUj+mdrlu76k6X4nTafy/+TMtgdWZwMe7rSb+w/z6NSnSyvzvtBRg+eibDR88E4NIzu7N8ZcktB1ievjb/+7Z2VdJX7uT7dt/GHHpwS7octDfly6dSuVJ5brvueO4bWLLet2VJcP6JOUfVq87KtALnqALnsbr1q7Ny+Zp8x6zL3Mj07xfR6dBW/PDNPBo0rskz71wRPGb9ajz51j+4ut9zrNrJc3xxSFuZme8qWr1aO/9aznFIh+bMXbiMVRklb/BxUSnmRbW+B1pFqz/+AM4Ezs4Xj1lT4APgXHefuzMPuktlPGZWF3gWeNK3rh2oHg0MgoGhsXqZWS0zq0hQbjIB+BLoa2b1oo9dy8z2ih6/2cxyrgzEPc7M6gARd38fuAPouJ3Qt/W3vgN6mFnt6N87veAdo4MgMs3skOimM7fzdz4H/hlN7jGzA2O2/yOnTWbWOlresy3LzGxfM4sAf9vOcTlGAheYWaWc9kW3ZwLxrod/BxxhZnUsGLtwFjBmJ/5OLncf5O6d3L3TJZcUvAq1c4a/PI4rj32IK499iIkjptOz78EAtOnYjHWZG1mVtmar+0z/5hcOO74DAEeffjATo3WvDZvVyT2mRbsmpJZPYc2qdbz04DDO7Xwn53f9Dw9e8RI/TphbIhJ9gNlzl9CkcU0a1K9OamqEow7flwnfzdup+z7/8lhO7/8MZ17wHHf/dxhTpv9W4hJ9gDmz/qRx01rUb1SD1NQUehzbjm+/zn+599sxszn6hA4AtNm/CevXbmRl+lqGPPEF5xw3kP7HP8YDN7/Hj98vLBWJPsDP85fSpEENGtatRmpKhKMP3Yfxk+fv1H2Xpa+hbauG7FE++J7dqV1TFv2xo4t14dqd9gLUrFYRgPq1q9Lj4FaMKsElAbN/WUKTRrHv2zZMmLST79tXxnH6gGc586JB3P1Q9H2rRD9Uc2b9QaOmtanfODhHHXHc/nw7psA56uvZ9DyxAxCco9ZFz1HVa1aictWgP678HqkceMjeLF60nEXzlnHmkf+lf5+B9O8zkPRla7jyzGdKVKIPMHveUpo0rEHDetVITY3Qs9uuvW8BenVvw6jxJff9WiS8CH929KfctwBXEuSNPwPvuPssM7vMglkiISiVrw08HS0Bn7yNh8u1Mz37Fc1sGnlTb74KDIxz3EMEZTzXAV8V2Dc+er+WwBvuPhkgWmozMprUbiboof+V4BLHdDObEq3bj3fcBmBIdBvANq8QuPtP8R7D3b81s7uAicASYAqQEuchLgSeN7N1BFcstu5ODtwDPBaN3YBFBCU/LwDNgCnR7csJvvRsy80EpTSLgZnAdovo3H2EmXUAJpvZX8CnBDMavQQ8a2YbCMYW5By/xMxuAUYT9PJ/6u4fbe9vJNr3X/1E56PaMnj8nWzc+BePXvd67r67X7mUx254k5XL1jD4/o+5+enzOe/G45k/83dGvvUtAN37dKDnaZ3ZsiWLvzZu5sF/vBRSS3ZeVrbz2DNf8PA9pxOJGJ+OmsGi31ZwUu8OAHz82TRq1azMc4+dR+VK5cnOdvqe3In+l73I+g1FOWlT4mRnZfPUfz/l/qfPJRKJMPKjqfy6YDnH9+0EwCfvTWbS+F/o3L01Qz6+OpjW7q6hO3zcQ49sw+U39aF6zcrc83g/5s9Zym1XlIwvcRA8twMHf8Wjt55GSiTC8K9nsvD3FZxydDC95NAvplOreiUGP3AOlSuWJ9udM/p05OzrX+KneUsZ/d0vvPTguWRlZzN3YRoffVFyB2HD7rV3/Ya/uO+6k6hetSJbsrJ4ePCXZK7btIO/GJ6sbOexZ7/g4f/0JRKJ8OkX0fftccFU1x+P+JFaNSrz3KPn5r1vTzqI/pcPLjXv2111/X9g0jRYnQE9+sKVA6Dv8WFHtXOys7J5+oHh3PdM/+AcNXQKv85Po8/pnQH49N3vmTRuLp27t2bw8GvZtHEzA+8MOh1q1anK9feeRkrEsIgxduRMJo3dqY7WEiEr23n0xa8YeFv0fTs6+r7tFX3fjppOrRqVePHBvPft34/vSL9rg/ftHuVT6dx+Lx4aNCrkliQXd/+UII+L3fZszO8XARftymNaSR7cV1KYWRV3Xxv9/WagobtfHXJYJYn3bpKIGVhLls9+fxyAI45/KORIiseYT24E4NgD/72DI0u/z6f+B4BDz3gk5EiKxzdvXw+UjfbmtPWIE0vp3JC7aMywGwDIXtp6B0eWfpEGQWJ93AF3hBxJ8Rjx4z0AdDs9+d+3E969HnZcRl0sDj3jkSJLlL95+/pQ2lTYAbplzfHRnvBUgisP54cbjoiIiIgkXBL0iSvZ3wnu/jbwdthxiIiIiIjsCiX7IiIiIiJxFPNsPAmhZF9EREREJJ4kGNu6yyvoioiIiIhI6aCefRERERGROFTGIyIiIiKSrJIg2VcZj4iIiIhIklLPvoiIiIhIHCrjERERERFJVpqNR0RERERESir17IuIiIiIxKEyHhERERGRZJUEyb7KeEREREREkpR69kVERERE4lAZj4iIiIhIssou/dm+eRJMKSSh04tIREREipKFHQDAEcc/VGQ5zphPbgylTerZFxERERGJJwm6M5XsS5HY+837ww4h4RacdSsAB17+aMiRFI+pT18LwEEXJ397f3g+aGuvyOkhR1I8RmW/C0DvhleEHEnifbbkKQCO63BnyJEUjxHT7gbguAPuCDmSxBvx4z0AZC9tHXIkxSPSYC4AnS4aGHIkiTf5hevCDiFXMtTsazYeEREREZEkpZ59EREREZF4kmBsq5J9EREREZE4VMYjIiIiIiIllnr2RURERETiSYKefSX7IiIiIiJxmGr2RURERESSVHbYAew+1eyLiIiIiCQp9eyLiIiIiMShMh4RERERkWRV+nN9lfGIiIiIiCQr9eyLiIiIiMSjMh4RERERkeSkFXRFRERERKTEUs9+kjOzvwEfAPu6++yw49kZhzfcmzs79iJixjvzf+TZnyfm29+lXlMGHdaXxesyAPh88RyemDU+d3/EjI+OHcCy9ZlcNPbdYo19Vx26317ccHoPIhZh6DczGTLy+3z7e3duw/nHdAJgw6bN3P/ml8z9Ix2AKhX34N/9etGiUW0c5z+vjmL6wiXF3oZd0bXtXvzrzB6kRCIMHTeTl0YUaG+XNvQ/Lmjv+o2beeD1L/nl9/Tc/REzXr39bJavXss1T3xUrLEX1uX/N4CDe3dk0/pN/G/AU8ybunCrY06+4jj+dvXxNG7ZgNPqXsCaFZkA7LlPI/41+ApadmzOkNvf5L1HhhV3+Dt02T2n07lnWzZt+ItHrnmV+TMWb3VM/T1rc/OzF1C1RiXmzVjMw/98mS2bs3L3tz6gKQM/uYEHLx3M+E+mUqdRDf71eH9q1quGZzufvTaej174uhhbtbWDDm3JP27sQyRijPhwCu8MGbfVMf+4sQ+du7di08bNPHLnh8ybvYRy5VN5ePAFlCuXSkpqhHFfzOK1Z0bn3uekM7tw0pldyMrKZtK4ubz42MjibNY2HXRoS/5x0/HR9v7AO4PjtPemPnTu3jpo7x0f5LV3yIV57R01i9ee+Srf/U47rxsXX38cfz/iAdasXl9cTSoStz0IX0+EWjVh2EthR7P7urZtxr/O6kEkEmHouBm8/Fn+c/JxXdrQv3dnIDgnP/jaF1ufk+/oR9qqtVz7xNDiDL34qIxHSoGzgPHAmcBd4YayYxEz/nPQsZw3+k2WbljD0GMG8MUfvzBvTXq+475fvnibifyA1p2Zn7GCKuXKF0fIhRYx4+YzjuIfj3/AstWZvH7T2YyZPp8FS1fmHvPnigwuGvgumRs20W2/Ztx+9tGc97+3ALjx9B5889MibnhhOKkpESqULxdWU3ZKxIybzz6Kyx/9gGWrMnn1trMZ8+N8Fi7Ja+8f6Rlc/L93yVy/iUPbNeP2c4+m/wNv5e4/6+gDWbRkJZUrluznNsfBvQ+kccuGnN/6n+zbpRVXPX0xV3W9davjZk6YzbfDf+Dh0Xfl2565ci1PXT2YbqccXEwR75rOR7Wl0d51ufDQu2jTsRlXPngm1x7/v62Ou+D2Uxg66CvGfPQDV/73TI4961A+eSVIHiMRY8DtpzDl659zj8/aks3z//mA+TMWU7HyHjz++U1MHTub3+YuLba2xYpEjCtuOYFbL3uZ9GVrePz1S/l2zGx+W7A895jO3VvRqGltLjjp/2izfxOuvO1Erjl3EJv/2sJNF7/Exg1/kZIa4ZEhFzF5/C/MnvE77Ts1p2uPNvzj9KfYvDmL6jUrh9K+giIR44pbT+TWS18K2vvGZXz79Tbae+JjQXtvP5Frzom296Ihee196SImj5/L7Bm/A1CnfjU6dm3Bsj9Xh9S63XNKbzj7VLj5/rAj2X0RM27qdxRXDHyfZasyeeX2foydlv+c/Gd6Bpc89E7uOfm283px/v1v5u4/6+gDWbhkJZUrlI5zcmGYFtWSkszMqgDdgAsJkn3MLGJmT5vZLDMbbmafmlnf6L6DzGyMmf1gZp+bWcPijvmAWo34de0qFq9bzebsbIb/9hO9mrTa6fs3qFiVIxu15O0F0xIXZBFp16wBi5ev5o8VGWzJyubzH+bQ44AW+Y75ccESMjdsAmD6wiXUr1kVgMoVytOxZWM+/GYmAFuyslkbPa6kats82t70oL0jv59Djw752zt9/hIy1wftmLFgCfWi7QWoV7MK3fdvztDxM4s17t3R9eTOfPHqGAB+/u4XqtSoTK0GNbY6bv60RSz7dflW21cvX8PcyfPZsnlLokMtlEOOa8+X734HwOwpi6hSrSI161Xb6rgDurdm3PCpAHzxznd07d0+d99JF/ZgwifTWJ2embttVdqa3CsEG9ZtYvEvy6gd5/+tuOzTrglLFq9k6R+r2LIlizGfz6Brjzb5junaow1fDp8GwOwZv1OlagVq1akCwMYNfwGQmppCamokt6PwhL935p0h49gcvcqRsWpd8TRoB4L2rshr74gZdO2xb75juh65L18OmwbktLfiNtqbkm/mwktv6MMLj44stb2lnQ+AGlV3fFxp0LZ5AxanxZyTJ83miF08J3drvzdDx80o1rhl1ynZT26nACPcfS6w0sw6AqcCzYD9gYuArgBmVg54Aujr7gcBg4H7ijvgBpWqsmT9mtzbS9ZnUr/i1mfWA+s05pPjLmTwEWfQqlqd3O13dOzFg9O+IrsUfJDUq1GFZavyEpxlq9ZSt3qVbR5/Srd2TJgVlIA0rlOdVWs38J9zj+HNW/pxZ7+jqVC+ZF+oq1ejCstWFmhvje20t3s7vpmZV/Jy/Rk9+L/3xpGdXfKf2xx1GtUibfGK3Nvpv6+gTuNaIUZUtGo3qE56TA9t+pLV1GlYI98x1WpVZl3GBrKzsqPHrMpN3Gs3qM6hvQ/g01e2LhHJUa9JLVrs34Q5UxYVcfQ7r3a9qixfmpF7O33ZGmoX+FJTu161fMcsjzkmEjGeevsfvPXVjUz5dj5zZga93I33qk3bjnvx2KuX8NALF9C6baNiaM2OFWxLeloGtetX3fqYZbHtzSjQ3st5a/RNQXujvfqHHNGGFWlrWBjSFRrJr17N/J9BaavW5kvmCzo5zjn58ffG4qXg83a3uBfdT0iU7Ce3s4CcGoi3ore7A++6e7a7LwVyikf3AdoBo8xsGnA70KR4w42v4Ntj1sqlHPbxUxw/4kVemTuZ5w7vC8BRjVqyYtM6Zq4qzR8k8U8GnVo34ZRD2/J/Q4OxCamRCG32rMe746Zz1gOvs+GvLVxwTOfiDHSXmW29zbfV3n2acHL3tjz+ftDew9o3Z9Wa9cz+LS2RIRY5i9PoZPpcjN8+3+ljLr27L4PvHbrNL3AVKu3B7S9ezHN3vsf6tRuLIOLC2d12Zmc7V5zxDOcc+wj7tGvCXi3qAZCSEqFq1Ypcc+4gXnjsc2596IwERL/r4r5XCzxFcQ7JPSZo79Occ8zD7NOuMXu1rMceFcpx5sWH88rTXxZ5vFJ0tpW4H7TPnpx8WDueeC/4Yt69fXNWZq5n9q+l65xcKF6EPyEp2V2BUmhmVhs4CmhnZg6kELzUPtzWXYBZ7t51Jx//EuASgOeeew6K6LLm0vWZNKyU12PWsFJV0jZk5jtm7Za/cn//esl87rZjqVm+IgfVbULPxq3o0bAFe6SkUqXcHgzsehLXTfy4aIIrYmmr1+aW5QDUr1mF5RlbX8Zv1bgOd/brxZVPfUjGuiDhWbY6k7TVmcxcFHyx+WLKLww4tlPxBF5Iy1atpX6t/O1NX711e1s2rsMd5/Xin4/ntfeAFo04vMPedNu/GeXLpVKlQnnuufA47nhxRLHFv7NOuvxY+lx0NABzJs+j3p61mRXdV6dJbVb8uXLbdy4FTjj/cI7r1w2AuT/+Sp1GNXL31WlYgxUxPcIAGSvWUrl6RSIpEbKzsqnTsCYroz3CrQ5oys3PXgBAtVpV6NyzLVlZWUwcMZ2U1Ai3v3gRoz/4nm8+/bF4GrcN6cvWULdB9dzbdepXY+XyzALHZOQ7pm6cY9ZlbmT65IV06taKX+enkb5sDRO++gmAuTP/IDvbqV6zEhmrwh20ulV761VnZVqB9qatoW792PZWZ+XyNfmOWZe5kenfL6LToa344Zt5NGhck2feuSJ4zPrVePKtf3B1v+dYtWJtAlsj25K2Kv9nUL2aVVi+euvnomWTOtzRvxdX/d8Heefklo05/IAWdNu/ee45+e6LenPnC58VW/yy89Szn7z6Aq+4+17u3szd9wQWAunAadHa/fpAj+jxc4C6ZpZb1mNmbbf14O4+yN07uXunSy65pMiCnr7yT5pVrUmTytUpF4lwQtP9+OL3X/IdU6dC3iC29rUaEjFj1V8b+N+PX9Ptoyc5fNjTXPXNUCYuW1RiE32AWb8upWm9mjSqXY3UlAjHHrQPX09fkO+YBjWr8vDFJ3LHyyP4LW117vYVa9azdNVa9qpXE4CD2+zJgiUlO4n8adFS9qxXk0Z1gvYe03kfxvxYoL21qvLw5Sdyx+AR/LZsde72Jz+cQJ8bX+DEWwZz66BP+X7O4hKZ6AN8/PTnXNbxBi7reAMThn7P0eceAcC+XVqxLmM9K5euDjfA3TT8pbFc2esBruz1ABM/+5Gep3cBoE3HZqzL3MCqtDVb3Wf6hLkcdsKBABz99y5MHDEdgAFd/s35B9/J+QffyfjhU3nq5rdz910z8BwW/7KUD5/7aqvHK25zZv1Bo6a1qN+oBqmpKRxx7P58Oyb/5GbfjplDzxM6ANBm/yasW7uRlelrqV6zEpWrVgCg/B6pHNilBYsXBuMzvhn9Mwd03huAxk1rU65cSuiJPuS0tzb1G0fbe1yc9n49m54ndgB20N5D9mbxouUsmreMM4/8L/37DKR/n4GkL1vDlWc+o0Q/RD8tWsqe9WvknZMPbsPYAufk+rWq8r/LT+LOFz/Ld05+6oPxHH/j85x084vcNugTvp+9OGkTfXMvsp+wqGc/eZ0FPFhg2/vAvsDvwExgLvAdkOHuf0UH6j5uZtUJXhuPQW6nZLHIcueuySN5uceZRCzCuwt+5Jc16ZzdMkgU3pg3ld57tqFfq45kZWezMWsLV30ztDhDLDJZ2c5/3/6Kp688lUjE+GjiLBYsWUHfw4LBi++Nm84lfbpQo0oFbjnjqNz79PvvGwD8953R3D+gN6mpEf5Iz+Dfr5SMKfu2JSvbeeiNr3jymlNJMeOjCbNY8OcKTjsiaO/7Y6Zz8QldqF65Ajf3i7Y3yzn3vjfCDHu3TPp0Cl36HMjLvzzBpvV/8fAFT+Xuu2/4LQy8+FlWLFnFKf/szd9vOJlaDWow6MeHmfTZVAZe/Cw169fgqe8fpFK1ini2c+rVx3NR22tZn7khxFbl+f7LWXTu2ZbBE+9i44a/ePTa13L33f3a5Tx2/eusXJbB4HuHcvOzF3DeTScyf+ZiRr45cTuPCm0PbsHRp3dh4U9/8OSoWwB4+YGP+f6rYj0d5crOyubpBz/hvmfOIxKJMPKjKfw6fzl9+gZX0z59bzKTxs2lc/dWDB52DZs2bmbgv4OLqLXqVOX6e04lJWJYxBg7chaTxs0FYOTQqVz3n1N49r0r2LI5i4fv+CCU9hWUnZXN0w8M575n+gftHTqFX+en0ef0oFTw03e/j7a3NYOHXxu0984g9lp1qnL9vafFtHcmk8bODbM5Rer6/8CkabA6A3r0hSsHQN/jw46qcLKynf+9MZonrgmer48nzNz6nHziIVSvXIGb+vWM3ieb8+4tvefkQkmC2ktL+oEVshUzq+Lua6OlPpOAbtH6/cLyvd9MgnnIdmDBWcGUiQde/mjIkRSPqU9fC8BBFyd/e394Pmhrr8jpIUdSPEZlB9PW9m54RciRJN5nS4IvWMd1uDPkSIrHiGl3A3DcAXeEHEnijfjxHgCyl7YOOZLiEWkQfGnqdNHAkCNJvMkvXAfxh4YUu2MOubvIEuWR394ZSpvUs182DTezGkB54J7dTPRFREREklMSzLOvZL8McvceYccgIiIiUtKFWWtfVDRAV0REREQkSalnX0REREQkniTo2VeyLyIiIiISTxIk+yrjERERERFJUurZFxERERGJR7PxiIiIiIgkJ83GIyIiIiIiJZZ69kVERERE4kmCnn0l+yIiIiIi8SRBsq8yHhERERGRJKWefRERERGReJKgZ1/JvoiIiIhIPEkw9abKeEREREREkpR69kVERERE4kiGefbNk6AREjq9iERERKQoWdgBAPTe95Yiy3E++/mBUNqkMh4RERERkRLAzI4zszlmNs/Mbo6z38zs8ej+6WbWcUePqTIeKRKdBwwMO4SE+37IdQA0e/rhkCMpHosu/xcAx3S9J+RIEm/kxDsA6NXt3pAjKR6jJtwOwBF9Hgo5ksQb8+mNALS/9tGQIyke0x+9FoBupz8SciSJN+Hd6wHodFHyf/4ATH4h+AzKXto65EgSL9Jgbtgh5MkuvuIFM0sBngJ6Ab8D35vZx+7+U8xhvYFW0Z8uwDPRf7dJPfsiIiIiIvG4F93Pjh0MzHP3Be7+F/AWcHKBY04GXvHAt0ANM2u4vQdVsi8iIiIikmBmdomZTY75uaTAIY2BxTG3f49u29Vj8lEZj4iIiIhIPEU4kY27DwIGbeeQeAN4CwawM8fko2RfRERERCSe4p218ndgz5jbTYA/C3FMPirjEREREREJ3/dAKzNrbmblgTOBjwsc8zFwXnRWnkOADHdfsr0HVc++iIiIiEg8xTgbj7tvMbMrgc+BFGCwu88ys8ui+58FPgX6APOA9cCAHT2ukn0RERERkXg8u3j/nPunBAl97LZnY3534IpdeUyV8YiIiIiIJCn17IuIiIiIxFO8A3QTQsm+iIiIiEg8xViznygq4xERERERSVLq2RcRERERiUdlPCIiIiIiSSoJkn2V8YiIiIiIJCn17IuIiIiIxJMEPftK9kNiZk2Ap4D9CK6wDAducPe/tnOfW939/mIKMTRd2zXj+rN7EIlE+GjsDF7+9Pt8+487pA3n9ekMwIZNm3nwlS/4ZXE69WtV4a6LelO7eiXcnQ/HzOCtUVPDaMJOO2LPZtzZ/ShSIsbbP83gmamT4h7Xvl4DPjz1bK4cOZzPFsxl7xo1efKYE3P371mtOo9OmsDg6VOKK/Sd1umQFvzjmmOJpBgjPp7K269+s9Uxl197LJ0PbcmmjZt5+J6PmTd3KQCVq+zBdbecSLMWdXGHR+77mJ9n/sG5Fx5O75MPJGPVegAGPzua7yfOK9Z2xdOpy95cfs2xRCLGZ8Om8fZrcdp6zTEc3DVo6//uG8a8uUtp0rQWt999au4xDRrV5OUXxvDhO5M494LD6XNSBzJWR9v63GgmTZxfbG3aWQcf1Jx/XtqTSMT45PPpvPHud/n2N21Si5uv7U2rlvV54eVxvP1B8L4uXy6Fxx86m3LlUkhJiTBm/ByGvD4hjCbstG5t9uKmv/UgYhE++G4mg7/Mf47q07ENF/TsBMD6TZu5970vmftnOgD9Dj+Q0w5pB2Z8MHEGr40t2ecogC4dmnHNgCOJRIxhX87ktaH5z1NNG9XitiuOpXXzegx6cwJvDpsc3V6Tu689Ife4RvWq88Lb3/DOpyXvPBWra9tm/Ous4DNo6LgZvPxZgc+gLm3o3zv4DFq/cTMPvvYFv/yenrs/Ysard/QjbdVarn1iaHGGXuRuexC+ngi1asKwl8KOJiTZxbuoViIo2Q+BmRnwAfCMu59sZinAIOA+4Ibt3PVWIKmT/YgZN557FFc+/D7LVmby8p39GDttPgv/XJl7zJ/pGVz64Dtkrt/Eofs349b+vRhw75tsyXIee3sMc35No1KFcrzy73P4btav+e5bkkTMuPvwozln2LssXZvJx33PYdSi+cxbtWKr424+5HDGLl6Uu23B6lX0eeeV3P3f9b+MzxeEn+wWFIkYV15/HDdf/TrpaWt4YvBFTBw3l98W5X0wdu7aksZ71mLA6U/Rpm1jrrqxD1ddNBgIvgR8/+087rntPVJTI+xRoVzu/T546zvee+PbYm/TtkQixj+v781N1wRtffKFC5k4Pn9bD+7agsZNanH+GU+zb9vGXPWv3lx1yRB+/20ll53/Qu7jvDn0aiaMmZN7v/ffnsR7b5acthYUiRjXXH4019/2DsvTM3nusfOY8O08fl2c91pek7mRx5/9ku5dW+W771+bs7j2lrfYsHEzKSkRnnz4bL6bvICf5iwp7mbslIgZt552FJc8+wHLVmfy5rVn8/XM+SxYlnee+WNlBgOefJfMDZvo3qYZ//770fR77C1aNqjNaYe04+xH32RzVhbPXHoqY39ayG/pq8Nr0A5EIsb1F/bkmnveI21lJi880I/xk+ex6Pe89q5Zu4FHB3/F4Qe3zHff3/5cxfk3vJr7OEOfu5Qxk34p1vh3VcSMm/odxRUD32fZqkxeuT36GbQk/2fQJQ9FP4PaNeO283px/v1v5u4/6+gDWbhkJZUrlA+jCUXqlN5w9qlwc1JnHslPNfvhOArY6O5DANw9C7gWuMDMLjezJ3MONLPhZtbDzB4EKprZNDN7PbrvPDObbmY/mtmr0W17mdmX0e1fmlnT6PaXzOwZMxttZgvM7AgzG2xmP5vZSzF/7xgzm2hmU8zsXTOrUmz/K0DbvRuwOG01fyzPYEtWNqMmzeaIA1vkO2b6vCVkrt8EwIz5S6hXqyoAKzLWMefXNCDobVm0ZAV1axRr+LukQ70G/JqxisVrMticnc2webM5pnmLrY47f/8D+WzBXFZsWB/3cbo1acqvGav5Y+2aRIe8y/bZrxF//r6KpX+uZsuWbMZ8MYtDD98n3zGHHt6aUZ9NB2D2rD+oXKUCtWpXoVKl8uzfoSkjhk0DYMuWbNat3VTcTdhp++zbiD9/X5nb1q+/nMWhh7XOd0zX7vvwxYgZAPw86w+qVA3aGuvATs1Z8scq0pZlFFvsu2vf1g3548/VLFmawZYt2Xw19me6d82f+K3OWM/sX5ayJWvrXrINGzcDkJoaITUlhZJ80bxd0wb8lr6aP1YE56gRU+dwZLv879sfFy0hc0PwWv3x1yXUqx6co5rXr8X0X5ewcfMWsrKdyfN+p2f7llv9jZJk35YN+H3pav5MC57bLyfM4bBOBZ7bNRuYPX8ZW7Zsuwe0U7um/LF0NcvSMxMd8m5p2zz6GZQePL8jJ83miA4FPoPmx3wGLVhCvZpVc/fVq1mFbu33Zui4GcUad6J0PgBqVN3xcUnNveh+QqJkPxxtgR9iN7j7GuA3tnG1xd1vBja4ewd372dmbYHbgKPc/QDg6uihTwKvuHt74HXg8ZiHqUnwReNaYBjwaDSW/c2sg5nVAW4Hjnb3jsBk4LqiaPDOqluzCstW5n0YLFu5lro1t32mOfnwdnwzY+FW2xvWrsY+Tesxa8HShMRZFOpXrsqfa/PaumTtWupXrlrgmCoc27wVr8/6cZuPc2LLNnz8y+yExbk76tStxvK0vC8hy9PWULtu/jbWrluV5cvyjklfHhzToHFNVq9ez79uP4mnX76Ya285gQoxPfsn9e3Ms69ewnW3nUiVqhUS35gdqFO3ar62pqdlUqdAW+vUrUpavmPWbHVMj577MfqLWfm2nXxaJ557+WKuv+WEEtHWgurUrkJaTBK3PD2TOrV3PkOIRIwXnujP0DeuZPLURfxcQnv1AerXqMKy1THnqIy11Ku+7U6FU7u0Y8Ls4Bw1b8kKOu7dhOqVKlChXCqH7deM+iW4QwKgbq0qpK3Ia2/aykzq1t71mHt2a8MXE0rmeSpWvZpVWLYqpr2r1uZL5gs6uXs7vpmZ9xl0/Rk9ePy9sXgS1HlLlJJ9KSSDuJ1X29oez1HAe+6eDuDuOdcYuwJvRH9/Fegec59hHpyBZgDL3H2Gu2cDs4BmwCEEYwgmmNk0oD+wV9wGmF1iZpPNbPKgQYN2MuQdszjbtnXSPKjNnpx0WDuefGdcvu0V9yjHf688kYFvfs26jdscAhE6i9PYgm29s9uRPPjtWLK38X9QLhLh6GYt+HT+nLj7Q7cTbbT4B5GSEqFV64YM/2Ayl/d/no0b/uKM87oBMOyDHzi/75P847xBrExfyyVX9UpE9LvE4jyhBZ+2HT3nqakRunZvzZivfs7dNuzDH+j/96e47PznWbliLZdeeXSRxVxU4rV9Vz7YsrOdi/75Mqef9wz7tm5I873qFGF0iefbOG13btmEvx3SlkeHjQdgYdpKhnz1PYP+cSrPXPo35vyZTlYJX50z3vtzV3OW1NQI3Tu14KuJc4soquK1zc+gffbk5MPa8cR7wWdQ9/bNWZm5ntnRK8ySJLK96H5Copr9cMwCTovdYGbVgD2BDPJ/CdtWN97OfjGIPSanBiI75vec26lAFjDK3c/a4YO6DyIYZwDgz08cuBOh7FjaqrXUr5XXi1K/VhXSV6/d6riWTepw+4BeXD3wAzLWbczdnpIS4b9XnsiIiT8z+oeSV8Mea+naTBpVyWtrwypVSFufv63t6zXgiV7BALeaFSvSo+neZHk2IxcGbevRtDkz09NI30aJT9jS09ZQt1613Nt161VjZXr+NqYvX0Pd+nnH1KlbjRXpa3F3li9fw+yf/gRg3OifOePcINlfvWpd7vGffTSFex4+M5HN2CnLC7S1Tr2qrChQsrA8LZN69aoxK/eYoK05Oh/Sknlzl+ZrX+zvn348lXv+d0ZiGrAblqdnUq9O3mu5bp2qpK/c+n27I2vXbWLqjN84+KDmLPw1fcd3CMGy1WupH1PXUL96FZZnrNvquFYN63DXGb24fNCHZKzPO0d9+N0sPvwueAVc1acbyzJKdllL2spM6sVcpalXa9ef20M6NGfuwmWsyiiZ56lYaavWUr9AWc7ybXwG3dG/F1f9X95n0AEtG3P4AS3otn9zypdLpUqF8tx9UW/ufOGzYotfJB717IfjS6CSmZ0HEB2g+wjwErAA6GBmETPbEzg45n6bzaxczGP83cxqRx+jVnT7N0BO5tMPGL8LcX0LdDOzltHHrGRmrXdwnyL108KlNK1Xg0Z1qpGaEqHXwW0YO3VBvmPq16rKQ1eexL+f/4zflq3Ot++OAcew6M+VvDGyZM/2APBj2lKaVa9Jk6rVKReJcGLLNoxamH+WlcNee57u0Z/P5s/ljrFf5Cb6ACe12pdhJbSEB2DOz3/SeM9aNGhYg9TUCEcc3ZaJ4/L37k0cN5devdsD0KZtY9at28jKFWtZtXIdy5etoUnT2kBQy/7bouUA+ercu/Vow6IFy4upRds2Z/afNG6S19YePdsycXyBto6fy9HH7Q/Avm0bs25t0NYcR/Zqy+hR+Ut48rX1iH1KRFsLmj13CU0a1aRB/eqkpkY46vB9mfDtzn3Zrl6tIlUq7wFA+fKpdOqwF7/9XjIH1QPMWryUverWpHGt4Bx13IH78PWs/OeoBjWq8uiAE7n19RH8unx1vn21qlTMPaZn+5Z8OqWEXpWLmj1vKU0a1qBhvWqkpkbo2W0fxk/etdmgenVvw6jxJfc8FeunRUvZs37eZ9AxB7dh7I9bfwb97/KTuPPF/J9BT30wnuNvfJ6Tbn6R2wZ9wvezFyvRTwLu2UX2Exb17IfA3d3M/gY8bWZ3EHzp+pRgtp2/gIUEpTYzgdisdRAw3cymROv27wPGmFkWMBU4H7gKGGxmNwDLgQG7ENdyMzsfeNPM9ohuvh0otmuvWdnOQ6+P5vHrTyMlYnw8biYL/lzBqT2CZPCDr6dz0cmHUL1KBW46tycAW7Ky6X/3GxzQqhHHd9uPXxYv5/X/nAPAU+9P4JvpW9f0lwRZ7tw57kteOfE0UizCO7Nn8MuqFfRrewDAduv0ASqkptJ9z724dczI4gi3ULKznCcfGcH9j51NJGJ8PvxHfl24nOP/1hGATz6cwqRv5nHwoS156d0r2LRpCw/f+3Hu/Z8aOIKb7zqF1HIpLP1jNQ/fF+y76IqetGjdAHdn2ZIM/u+/n4TSvljZWc6Tj47ggYFnEUmJ8Pnwafy6MJ0TTgnaOnzoFCZNnEeXri15+Z0rgmlG7x+We/899kjloM7NeeyhT/M97sWX96RFq/pBW5dmbLW/JMjKdh575gsevvd0IhHj05EzWPTbCk7q0wGAjz+dRq2alXnu/86jcqXyZGc7fU/pRP9LX6R2rSrcen0fIhHDzPh63BwmTip5U4vmyMp27n//K5659FRSIsbQ72Yxf+kKTj80OEe9+810Lju2CzUqV+C2vkfl3uesgUF15cABJ1K9UgW2ZGVz//tf5Q7kLamysp1HX/yKgbedRkokwvDRM1n4+wpO6RW0d+io6dSqUYkXHzyHyhXLk+3O34/vSL9rX2L9hr/Yo3wqndvvxUODRoXckp2Tle38743RPHFN9DNoQvAZdNoRQXvfHzOdi088hOqVK3BTv57R+2Rz3r1vbO9hS63r/wOTpsHqDOjRF64cAH2PDzuqYlbCS+12hmkQiRQB7zygaMp4SrLvhwRjlZs9/XDIkRSPRZf/C4Bjut4TciSJN3LiHQD06nZvyJEUj1ETbgfgiD4PhRxJ4o359EYA2l/7aMiRFI/pj14LQLfTHwk5ksSb8O71AHS6KPk/fwAmvxB8BmUvLdYL7qGINJgL8YfxFbvjal1cZInyiJXPh9Im9eyLiIiIiMSTBJ3iSvZFREREROJJghV0NUBXRERERCRJqWdfRERERCQelfGIiIiIiCQnVxmPiIiIiIiUVOrZFxERERGJR2U8IiIiIiJJKgkW1VIZj4iIiIhIklLPvoiIiIhIPF76B+gq2RcRERERicNVxiMiIiIiIiWVevZFREREROJRGY+IiIiISHJSGY+IiIiIiJRY5kmwWICETi8iERERKUoWdgAAvSKnF1mOMyr73VDapGRfSiUzu8TdB4UdR3FRe5NXWWorlK32lqW2Qtlqb1lqK5S99iYblfFIaXVJ2AEUM7U3eZWltkLZam9ZaiuUrfaWpbZC2WtvUlGyLyIiIiKSpJTsi4iIiIgkKSX7UlqVtdpBtTd5laW2Qtlqb1lqK5St9paltkLZa29S0QBdEREREZEkpZ59EREREZEkpWRfRERERCRJKdkXEREREUlSSvZFREJkZjXNrH3YcYiISHLSAF0pNcysMrDB3bPNrDXQBvjM3TeHHFpCmNleQCt3/8LMKgKp7p4ZdlyJVFbabGZfAycBqcA0YDkwxt2vCzGshDKzFKA+QZsBcPffwouoaJnZdp87dx9YXLEUJzOrC1wMNCP/c3tBWDElgpnVB+4HGrl7bzPbD+jq7i+GHFpCmFkl4HqgqbtfbGatgH3cfXjIoUkhqGdfSpOxQAUzawx8CQwAXgo1ogQxs4uB94DnopuaAENDC6gYlLE2V3f3NcCpwBB3Pwg4OuSYEsbM/gksA0YBn0R/ki1pqLqDn2T1EVAd+IK85/aTUCNKjJeAz4FG0dtzgWvCCqYYDAE2AV2jt38H7g0vHNkdqTs+RKTEMHdfb2YXAk+4+0NmNjXsoBLkCuBg4DsAd//FzOqFG1LClaU2p5pZQ+DvwG1hB1MMriboFVwRdiCJ4u7/CTuGkFRy95vCDqIY1HH3d8zsFgB332JmWWEHlUAt3P0MMzsLwN03mJmFHZQUjpJ9KU3MzLoC/YALo9uS9TW8yd3/yjm3mlkqkOw1d2WpzXcT9BKOd/fvzWxv4JeQY0qkxUBG2EEkkpk9vr397n5VccVSzIabWR93/zTsQBJsnZnVJnpOMrNDSO7X9F/RUsqc9rYg6OmXUihZEyVJTtcAtwAfuvusaII0OtyQEmaMmd0KVDSzXsDlwLCQY0q0MtNmd38XeDfm9gLgtPAiSrgFwNdm9gkxCUOS1bFfBswE3gH+BMpKL+jVwK1m9heQM37K3b1aiDElwnXAx0ALM5sA1AX6hhtSQv0bGAHsaWavA92A80ONSApNA3Sl1DGzyu6+Luw4EsnMIgRXL44hSBo+B17wJH7DRi8RX0QZaLOZPURQ/7qB4AP1AOAad38t1MASxMz+HW97MpW+RHt9TwfOALYAbwPvu/uqUAOTIhO92rgPwflpTrJODpEj+po+hKC937p7esghSSEp2ZdSI1rC8yJQxd2bmtkBwKXufnnIoSWUmdUCmrj79LBjSZTol5vp7t4u7FiKg5lNc/cOZvY34BTgWmC0ux8QbmRSFKKTCJxF0Bt8k7u/GnJICWVmJwGHR29+nYwztpjZqXE2ZwAz3D2tuOMpDtEpgZuRf5alD0ILSApNZTxSmjwGHEtwKRV3/9HMDt/uPUqpeFMzmlnSTs0YnU71RzNrmkzTMW5Huei/fYA33X1lMo59M7PH3P0aMxtGnPEX7n5SCGEllJl1JEj0ewGfAT+EG1FimdmDQGfg9eimq82su7vfHGJYiXAhwcw0OaWjPYBvgdZmdneyfaEzs8FAe2AWkB3d7ICS/VJIyb6UKu6+uEBSlKyzIVR39zVmdhHB1Iz/NrOk7dmPagjMMrNJQG6ZVjImhMAwM5tNUMZzeXSu8o0hx5QIOQnQw6FGUQzM7D/ACcDPwFvALe6+JdyoikUfoIO7ZwOY2cvAVCDZkv1sYF93Xwa58+4/A3QhmBY6qZJ94BB33y/sIKRoKNmX0mSxmR0KuJmVB64i+GBNRmVtakaApKnf3hF3v9nM/guscfcsM1sPnBx2XEXN3X+I/jsm7FiKwR0EA5EPiP7cH+2YMIIBq8m8SnINYGX09+ohxpFIzXIS/ag0oHX0qlwy1u5PNLP93P2nsAOR3adkX0qTy4D/AxoTLPAxkmBu9mSUMzXjhDIyNWNZSQiB3NUprwCaApcQLNSzD0m20JSZzWA706cmWQLcPOwAQvIAMNXMRhN8sTmcYNa0ZDPOzIaTN4vWacDY6Mruq0OLKnFeJkj4lxLMoFUWvrQmLQ3QFZESwcwyyUsMyxPUta9Lwin8MLO3CWq5z3P3dtH5rCe6e4dwIytaZrbX9va7+6/FFUsYzKwOsCIZZ5SKFb0K2ZkgIfzO3ZeGHFKRi84WdirQPbppBdDQ3ZOyw8nM5hEMMJ9BXs1+0r9nk5V69qXEM7Mbo6vlPkH8QX5Jt1iNmTUBniCY29iB8cDV7v57qIElkLtXjb1tZqcQrKibjMrE6pRlKTGILrL0IEE5yz0ENdx1gIiZnefuI8KMr6iZWRt3nx0dkAzB1VaARmbWyN2nhBVbIri7m9l8ghr9vwMLgffDjSqhfnP3j8MOQoqGkn0pDXLq8ieHGkXxGgK8QTBvN8A50W29QouomLn7UDNLtkF+OcrU6pRl5KrNk8CtBDXrXwG93f1bM2sDvEmwnkIyuY6gBO2ROPscOKp4w0kMM2sNnEkww9IKgvUTzN2PDDWwxJttZm8QLGwYuxCeZuMphVTGI1IC5czDvqNtyaTAPNYRoBNwhLt3DSmkhImuEHw7sB/B2JNuwPnu/nWYcRWXnKs27n5r2LEUldj3p5n97O77xuyb6u4HhhZcAplZBXffuKNtpZWZZQPjgAvdfV502wJ33zvcyBLLzIbE2ezufkGxByO7TT37UmqY2SjgdHdfHb1dE3jL3Y8NNbDESDezcwh6BCGvVymZnRjz+xZgEUk4Qw2Au48ysynkrU55dVlanTJJr9pkx/y+ocC+ZO5V+wbouBPbSqvTCHr2R5vZCIJpVZOu5K4gdx8QdgxSdJTsS2lSNyfRB3D3VWZWL8R4EukCgrKARwkShW+i25JWGfxwqQCsIjgP72dmuPvYkGNKiG1ctUm2BPgAM1tDkAhWjP5O9HaF8MJKDDNrQDAzWkUzO5C8BLgaUCm0wIqYu38IfBiddecUgtWu65vZM8CH7j4yzPgSpSyOG0tmSvalNMmKXWE1OtNHsiUMAETbmIyLSW2TmT0E3EvQKzqCYK7ya9z9tVADS4DoHPtnsPXqlEmZ7FMGrtq4e0rYMRSzY4HzgSYEdfs5yf4agrELScXd1xGsEvy6mdUiGE91M0EZXjIq8+PGkolq9qXUMLPjgEFAznzshwOXuPvn4UWVGNFVKK8uULL0SDLXS+bUPJvZ38jrQRvt7geEG1nRM7M5QHt3T9pBuVI2mNlp7p7Ms9KUSWVx3Fgyi4QdgMjOik5d15FgNoR3gIOSMdGPal+wZAlIygF+McpF/+0DvOnuK7d3cCm3gLz2Jj0ze8jMqplZOTP70sxyxqRI6XeQmdXIuWFmNc3s3hDjkaKRbmbnmFlK9Occkn/cWNJSsi+lzR4E81hnENQ5Hx5yPIkSifbmAxC9bJzsZXfDzGw2QT33l2ZWF0iKGT3iWA9MM7PnzOzxnJ+wg0qgY9x9DXACwXzsrYEbwg1JikjvOB0TfcILR4rIBQTrCSwFlgB9SfJxY8ks2ZMHSSJlrM75EeAbM3svevt04L4Q40k4d785+hyvcfcsM1tHktV1x/g4+lNWbHXVJgnXECurUsxsj5yStOj6EXuEHJPsprI4biyZKdmX0uQUYJ+yUOfs7q+Y2WSChWkMONXdfwo5rIQys9OBEdFE/3aCkq17CXqWks1Md/8hdoOZnbitg5NAzlWbDcDlSX7Vpqx5jeBK3BCCzpcLgJfDDUl2V1kcN5bMNEBXSg0z+4xgnv21YceSaGbWNN72nJmIkpGZTXf39mbWHXgAeBi41d27hBxakYvOsd/f3WdEb59FMPNQ0rU1RzRZyLlqUwmo5u7J+EWuzDGz3kBPgo6JkUk8lqrMiLcQXDIvDpfs1LMvpUlOnfOX5F+++6rwQkqYT8ibVrQi0ByYA7QNLaLEy4r+ezzwjLt/ZGZ3hRhPIvUF3jOzfkB34DzgmHBDSrh9gWZmFvu580pYwUjRcffPgM/CjkOKVMTMakbHYJSVcWNJS0+clCZlps7Z3fePvW1mHYFLQwqnuPxhZs8BRwP/NbM9SNJJBNx9gZmdCQwFFhMMYC246mrSMLNXgRbANPK+1DlK9ku96IJp/wXqEfTsG+DuXi3UwGR3xY4bc4LBuveHG5IUlsp4REoJM5vi7smyBP1WoqUdxwEz3P0XM2sI7J9MK1Sa2QzyLwRXj2BmqU0A7t4+jLgSzcx+BvZzfeAkHTObB5zo7j+HHYsULTPbj7xxY18m+7ixZKaefSk1zKwVQS33fsQsP+/ue4cWVIKY2XUxNyMEg1WXhxROsXD39WaWRlDW8gvBSqu/hBtVkTsh7ABCMhNoQDCFnySXZUr0k4+Zveru5wI/xdkmpYySfSlNhgD/Bh4FjgQGkLdEe7KpGvP7FoIa/qRepdLM/k0wx/4+BM91OYKZPrqFGVdRcvdfAczsEGCWu2dGb1cl+BL7a4jhJVId4Cczm0T+8Taa2q/0m2xmbxOUpMU+tx+EFpEUhXzjw8wsBTgopFhkN6mMR0oNM/vB3Q8ysxk5Ne1mNs7dDws7Ntl9ZjaNYJXgKTkzPuTM0BNqYAlgZlOBjjllLWYWASYna5mWmR0Rb7u7jynuWKRoRafcLMg1RWPpZGa3ALcSTAyxnrwOtb+AQe5+S1ixSeGpZ19Kk43RpOgXM7sS+IOg5jlpmNkw8td055PkPaF/ububWU4CXDnsgBLIYuvX3T27wCw1SUVJffJy9wFhxyBFx90fAB4wsweU2CePpP1wkaR0DVAJuAq4h2DgUP8wA0qAh+Nsy0kKk7VkKcc70dl4apjZxQSL8zwfckyJssDMrgKeid6+HFgQYjwJYWaZxP/yqhlbkkTMYlr5qGe/1PvMzA4vuNHdk3HF+qSnMh6REsTMTgaauPtT0duTgLoEH6Y3ufu7YcaXKGZmQBOgDcF88wZ87u6jQg0sQcysHvA4wRdWB74kWFQrLdTARHaRmZ0Wc7MC8DfgzyRd/6TMiF5lzlEBOBj4wd2PCikk2Q1K9qXUMLPWwA3AXsRclUqmk4+ZTQDOdPfF0dvTCFamrAwMcfeeIYaXUDljMsKOQ0QKL1pq+UUynZcFzGxP4CF3PyvsWGTXqYxHSpN3gWcJSjuydnBsaVU+J9GPGu/uK4AVSV7DDvCtmXV29+/DDiRRzOxGd3/IzJ4gfumDekOltGsFNA07CClyvwPtwg5CCkfJvpQmW9z9mR0fVqrVjL3h7lfG3KxbzLEUtyOBy8xsEbCOvLruZJqNJ2c+8smhRiFSROKMy1gK3BRSOFJECnRIRAhmSvsxvIhkd6iMR0oNM7sLSAM+JP98zivDiqmomdnrwNfu/nyB7ZcCPZL5EqqZ7RVve87c9CJScphZqrtvCTsOSQwz+weQQpDwZwAL3X1CuFFJYSnZl1LDzBbG2ezJtIJudODmUIIvM1Oimw8C9gBOcfdlIYWWMNE23wq0BGYAD7j7mnCjSqzo+JN/Ac1I0vEnktzMbErOuhBm9oS7/zPsmGT3RacAvp9gNrTfCK6w7gkMBm5z980hhieFpGRfpAQys6PIW8Fwlrt/FWY8iWRmI4AfgLHACUBVdz8/1KASzMx+JBh/8gMx40/c/YfQghLZBWY2NWbxu9zEX0o3M3uUYAX3a2NW+K5GMC30Bne/Osz4pHCU7EupYWanxtmcAczQlIWll5lNc/cOMbeTPnHQzENS2hXo2U/692xZYWa/AK29QHJoZinAbHdvFU5ksjs0QFdKkwuBrsDo6O0ewLdAazO7291fDSsw2S1mZjXJWzQsJfZ2ko3JqBX9dZiZXU4Sjz+RpNfGzKYTvE9bRH+H5BxYX5Z4wUQ/ujErZ3VzKX2U7Etpkg3sm1O3bmb1CVYg7UJQAqJkv3SqTlDOErtCcM54BQeSZkwGQTudvLbeELMv2doqyW3fsAOQhPjJzM5z91diN5rZOcDskGKS3aQyHik1zGyGu+8fc9sISnjaxdaPipRUZtbV3SeGHYdIUYrOpNXK3b8ws4pAak69t5QuZtYY+ADYQF7nRGegIvA3d/8jxPCkkNSzL6XJODMbTrC4FkBfYGx0sanVoUUlu8XMtlvr6+5Ttre/lHkKUG2zJA0zuxi4BKgFtACaEAw+T9rVvpNZNJnvEjNJhAGfufuX4UYmu0M9+1JqRHvyTwW6E5yAxgPvx6svlNLDzHLGYFQAOhEs3GJAe+A7d+8eVmxFTVegJNmY2TTgYIL3as7sPPmuwopIuNSzL6WGu7uZTQYyopeLKwFVAF0uLsXc/UgAM3sLuMTdZ0RvtyOYiz6ZNDezj7e1091PKs5gRIrAJnf/K+iLyZ2nXR0wIiWIkn0pNeJcLm6MLhcnkzY5iT6Au880sw4hxpMIy4FHwg5CpAiNMbNbgYpm1gu4HBgWckwiEkNlPFJq6HJxcjOzN4F1wGsEPYPnAFXc/axQAytCmo9cko2ZRQimRT6GoPzuc+AFlVeKlBzq2ZfSRJeLk9sA4B9AzgqNYwmmVk0mi8IOQKQouXu2mb0GjHX3OWHHIyJbU8++lBpm9hDBrDvnAf8kuFz8k7vfFmZcUnTMrDywD8GXuDnuvjnkkBLGzA4FmhHT6VJwbmuRks7MTgL+B5R39+bR0ru7Nf5EpORQsi+lRnQ2novQ5eKkZGY9gJcJer8N2BPo7+5jw4sqMczsVYJxJ9OArOhmd/erQgtKpBDM7AfgKODrmPLK6VpBV6TkUBmPlArRutDp7t4OeD7seCQhHgGOySkFMLPWwJvAQaFGlRidgP30RVWSwBZ3z8gprxSRkicSdgAiO8Pds4Efzaxp2LFIwpSLrfl197lAuRDjSaSZQIOwgxApAjPN7GwgxcxamdkTwDdhByUieVTGI6WGmX1FsGz3JIJZWwDNTZ4szGwwQa3+q9FN/YBUdx8QXlSJEV1IrAPBa3lTzna9lqW0ia53chtBeSUE5ZX3uvvG8KISkVhK9qXUMLMj4m139zHFHYsUPTPbA7iCvBWSxwJPu/um7d6xFNJrWZKBmaUAn7v70WHHIiLbpmRfSjwzqwBcBrQEZgAvuvuWcKOSRChLs/GIJIPoitDnuntG2LGISHwaoCulwcvAZmAc0BvYj7y52CVJxJuNx8ySajYeMxvv7t3NLJP8a0QYwWw81UIKTaSwNgIzzGwU+csrNbOUSAmhnn0p8WJXyY0upDVJq5Amn+gUfmcXnI3H3ZNxNh6RpGBm/eNtd/eXizsWEYlPPftSGuSWcrj7Fk3xlrS2mo3HzJJyNh4zu9DdXyyw7UF3vzmsmEQKQ0m9SMmnZF9KgwPMbE30dwMqRm+r9CG5TDazF8k/G88PIcaTSH3NbKO7vw5gZk8DFUKOSWSXmdkM8pekAWQAkwlm5VlR/FGJSCyV8YhIiVDGZuOpCHwMDCYYh7LS3a8JNSiRQjCzhwhWgX4juulMgvdvBtDd3U8MKzYRCSjZFxEpJmZWK+ZmVeAjYDxwJ4C7rwwjLpHCMrMJ7t4t3rbY8VYiEh6V8YhIqLZRBpDL3dsXYziJ9gNBWy3m3z7RH4C9Q4pLpLCqmFkXd/8OwMwOBqpE92mKZJESQMm+iITthLADKEZnAIvdfQnkzmRyGsF0o3eFF5ZIoV0EDDazKgRfXtcAF5lZZeCBUCMTEUBlPCJSAplZHWCFJ9kJysymAEe7+0ozOxx4C/gn0AHY1937hhmfSGGZWXWCnGJ12LGISH7q2ReRUJnZIcCDwErgHoLZeOoAETM7z91HhBlfEUuJqcs/Axjk7u8D75vZtPDCEtk1ZnaOu79mZtcV2A6Auw8MJTAR2YqSfREJ25PArUB14Cugt7t/a2ZtgDeBpEr2zSzV3bcAPYFLYvbpfCylSeXov1VDjUJEdkhlPCISKjOb5u4dor//7O77xuyb6u4HhhZcETOz2wgG46YDTYGO7u5m1hJ4ueCsJiIiIrtLPUkiErbsmN83FNiXVL0R7n6fmX0JNARGxoxJiBDU7ouUCmb2+Pb2u/tVxRWLiGyfkn0RCVvOCsmxqyMTvZ10q8q6+7dxts0NIxaR3ZCzunU3YD/g7ejt00nela9FSiWV8YiIiEihmNlo4Bh33xy9XY7gqtWR4UYmIjkiYQcgIiIipVYj8g/SrRLdJiIlhMp4REREpLAeBKZGe/gBjkALxImUKCrjERERkUIzswZAl+jN79x9aZjxiEh+KuMRERGRQrFgFa2jgQPc/SOgvJkdHHJYIhJDPfsiIiJSKGb2DMH0uUe5+75mVpNggG7nkEMTkSjV7IuIiEhhdXH3jmY2FcDdV5lZ+bCDEpE8KuMRERGRwtpsZilEF8Azs7rkXyhPREKmZF9EREQK63HgQ6Cemd0HjAfuDzckEYmlmn0REREpNDNrA/QkWPX6S3f/OeSQRCSGavZFRERkl5hZF2AQ0AKYAVzo7j+FG5WIxKMyHhEREdlVTwH/AmoDA4FHww1HRLZFyb6IiIjsqoi7j3L3Te7+LlA37IBEJD6V8YiIiMiuqmFmp27rtrt/EEJMIhKHBuiKiIjILjGzIdvZ7e5+QbEFIyLbpWRfRERERCRJqWZfRERECsXMrjazahZ4wcymmNkxYcclInmU7IuIiEhhXeDua4BjgHrAAODBcEMSkVhK9kVERKSwLPpvH2CIu/8Ys01ESgAl+yIiIlJYP5jZSIJk/3MzqwpkhxyTiMTQAF0REREpFDOLAB2ABe6+2sxqA43dfXq4kYlIDvXsi4iISGE5sB9wVfR2ZaBCeOGISEHq2RcREZFCMbNnCMp2jnL3fc2sJjDS3TuHHJqIRGkFXRERESmsLu7e0cymArj7KjMrH3ZQIpJHZTwiIiJSWJvNLIWgnAczq4sG6IqUKEr2RUREpLAeBz4E6pnZfcB44IFwQxKRWKrZFxERkUIzszZAT4L59b90959DDklEYijZFxERkUIxs1fd/dwdbROR8KiMR0RERAqrbeyNaP3+QSHFIiJxKNkXERGRXWJmt5hZJtDezNaYWWb0dhrwUcjhiUgMlfGIiIhIoZjZA+5+S9hxiMi2KdkXERGRQjGzCHA20Nzd7zGzPYGG7j4p5NBEJErJvoiIiBSKVtAVKfm0gq6IiIgUllbQFSnhNEBXRERECksr6IqUcEr2RUREpLByVtCtH7OC7v3hhiQisVSzLyIiIoUWs4IuwFdaQVekZFHNvoiIiOyOSkBOKU/FkGMRkQJUxiMiIiKFYmZ3Ai8DtYA6wBAzuz3cqEQklsp4REREpFDM7GfgQHffGL1dEZji7vuGG5mI5FDPvoiIiBTWIqBCzO09gPnhhCIi8ahmX0RERHaJmT1BUKO/CZhlZqOit3sRzMgjIiWEynhERERkl5hZ/+3td/eXiysWEdk+JfsiIiIiIklKZTwiIiJSKGbWCngA2I+Y2n133zu0oEQkHw3QFRERkcIaAjwDbAGOBF4BXg01IhHJR8m+iIiIFFZFd/+SoCz4V3e/Czgq5JhEJIbKeERERKSwNppZBPjFzK4E/gDqhRyTiMTQAF0REREpFDPrDPwM1ADuAaoDD7n7t2HGJSJ5lOyLiIiIiCQplfGIiIjILjGzx9z9GjMbRrCYVj7uflIIYYlIHEr2RUREZFflzLjzcKhRiMgOqYxHRERECs3M6gK4+/KwYxGRrWnqTREREdklFrjLzNKB2cBcM1tuZneGHZuI5KdkX0RERHbVNUA3oLO713b3mkAXoJuZXRtqZCKSj8p4REREZJeY2VSgl7unF9heFxjp7geGE5mIFKSefREREdlV5Qom+pBbt18uhHhEZBuU7IuIiMiu+quQ+0SkmKmMR0RERHaJmWUB6+LtAiq4u3r3RUoIJfsiIiIiIklKZTwiIiIiIklKyb6IiIiISJJSsi8iIiIikqSU7IuIiIiIJCkl+yIiIiIiSer/AdtNQXJ5kxOtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(dataset.corr(), annot = True, cmap = 'viridis', linewidths = 0.1) #data.corr()-->correlation matrix\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbb5db4",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e423d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X = dataset.drop('Outcome', axis = 1)\n",
    "#Y = dataset['Outcome']\n",
    "\n",
    "X = dataset.iloc[ : , :-1].values\n",
    "Y = dataset.iloc[ : , -1].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b0f5c",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e34ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404d4f1",
   "metadata": {},
   "source": [
    "## By Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00aad9",
   "metadata": {},
   "source": [
    "### Importing class and running prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5497d2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "Predict_X_test = classifier.predict(X_test)\n",
    "\n",
    "print(np.concatenate((Predict_X_test.reshape(len(Predict_X_test),1),Y_test.reshape(len(Y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a5f208",
   "metadata": {},
   "source": [
    "### Confusion Matrix for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04f3451b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix -\n",
      "\n",
      "[[98  9]\n",
      " [18 29]]\n",
      "\n",
      "Logistic Regression Accuracy - 82.46753246753246%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "cm = confusion_matrix(Y_test, Predict_X_test)\n",
    "print(f\"Confusion Matrix -\\n\\n{cm}\")\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Predict_X_test)\n",
    "print(f\"\\nLogistic Regression Accuracy - {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9f624",
   "metadata": {},
   "source": [
    "## By Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a6ff99",
   "metadata": {},
   "source": [
    "### Building a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61774d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 8)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                288       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,377\n",
      "Trainable params: 1,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(8, )))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.05))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289680a",
   "metadata": {},
   "source": [
    "### Using random values as a standard model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c994bb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 1ms/step - loss: 0.6995 - accuracy: 0.5993\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6288 - accuracy: 0.6498\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5948 - accuracy: 0.7036\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.7036\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.7362\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.7427\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7476\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7459\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7638\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7573\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7720\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7524\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7671\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7590\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7687\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7720\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7606\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7801\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7752\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7687\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 997us/step - loss: 0.4664 - accuracy: 0.7573\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7785\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 997us/step - loss: 0.4661 - accuracy: 0.7769\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7655\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7834\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7720\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7687\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7915\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7850\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7818\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7720\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7818\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7638\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7834\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7834\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.7932\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7899\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7752\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7980\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7866\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7899\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7866\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7899\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.7818\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7964\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7915\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7850\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7736\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7948\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7866\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7915\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7915\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7948\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.7932\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.8013\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.7915\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.7850\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.7948\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.7883\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.8029\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7850\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.7980\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7899\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.7834\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.7980\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.7883\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.7964\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7964\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.8062\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.8046\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.7866\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.7948\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.7850\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.7964\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7899\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.8111\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.8013\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8127\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.7866\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.8127\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4094 - accuracy: 0.8029\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4164 - accuracy: 0.8127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8143\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.8013\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4187 - accuracy: 0.8111\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.7866\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8176\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4090 - accuracy: 0.8257\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8029\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3977 - accuracy: 0.8208\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4107 - accuracy: 0.8111\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4060 - accuracy: 0.8111\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4129 - accuracy: 0.8241\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4151 - accuracy: 0.8062\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3910 - accuracy: 0.8160\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.8208\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4133 - accuracy: 0.8111\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4071 - accuracy: 0.8176\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4024 - accuracy: 0.8208\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4054 - accuracy: 0.8225\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = \"adam\", loss =\"binary_crossentropy\" , metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 32, epochs = 100)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbdb6479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix -\n",
      "\n",
      "[[93 14]\n",
      " [19 28]]\n",
      "\n",
      "Artificial Neural Network Accuracy - 78.57%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(f\"Confusion Matrix -\\n\\n{cm}\")\n",
    "\n",
    "accuracy=((cm[0,0]+cm[1,1])/(cm[0,1]+cm[1,1]+cm[0,0]+cm[1,0]))*100\n",
    "print(\"\\nArtificial Neural Network Accuracy - {a:.2f}%\".format(a = accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f76fc00",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning - Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43588c",
   "metadata": {},
   "source": [
    "### Creating the model function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7567417c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from numpy.random import seed\n",
    "from tensorflow.python.framework.random_seed import set_random_seed\n",
    "\n",
    "def create_model(lyrs = [8], act = 'linear', opt = 'Adam', dr = 0.0):\n",
    "    \n",
    "    # set random seed for reproducibility\n",
    "    seed(42)\n",
    "    set_random_seed(42)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # create first hidden layer\n",
    "    model.add(Dense(lyrs[0], input_dim=X_train.shape[1], activation=act))\n",
    "    \n",
    "    # create additional hidden layers\n",
    "    for i in range(1,len(lyrs)):\n",
    "        model.add(Dense(lyrs[i], activation=act))\n",
    "    \n",
    "    # add dropout, default is none\n",
    "    model.add(Dropout(dr))\n",
    "    \n",
    "    # create output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))  # output layer\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c04cfc8",
   "metadata": {},
   "source": [
    "### Running the Grid Search - Batch_Size and Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3375b08e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maverick\\AppData\\Local\\Temp/ipykernel_28052/245778076.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "#Create model\n",
    "model = KerasClassifier(build_fn = create_model, verbose=0)\n",
    "\n",
    "#Define the grid search parameters\n",
    "batch_size = [8, 16, 24, 32, 64]\n",
    "epochs = [50, 100, 200]\n",
    "param_grid = dict(batch_size = batch_size, epochs = epochs)\n",
    "\n",
    "# search the grid\n",
    "# include n_jobs=-1 if you are using CPU\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = 3, verbose = 2, n_jobs = -1) \n",
    "\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d03e0c",
   "metadata": {},
   "source": [
    "### Summarized Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f0f58dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Mean TS: 0.7491950) - (Std. TS - 0.00893) - Params - {'batch_size': 8, 'epochs': 50}\n",
      "(Mean TS: 0.7491950) - (Std. TS - 0.00567) - Params - {'batch_size': 8, 'epochs': 100}\n",
      "(Mean TS: 0.7508290) - (Std. TS - 0.01018) - Params - {'batch_size': 8, 'epochs': 200}\n",
      "(Mean TS: 0.7491950) - (Std. TS - 0.00567) - Params - {'batch_size': 16, 'epochs': 50}\n",
      "(Mean TS: 0.7475689) - (Std. TS - 0.00791) - Params - {'batch_size': 16, 'epochs': 100}\n",
      "(Mean TS: 0.7475689) - (Std. TS - 0.00791) - Params - {'batch_size': 16, 'epochs': 200}\n",
      "(Mean TS: 0.7492029) - (Std. TS - 0.00959) - Params - {'batch_size': 24, 'epochs': 50}\n",
      "(Mean TS: 0.7508130) - (Std. TS - 0.00799) - Params - {'batch_size': 24, 'epochs': 100}\n",
      "(Mean TS: 0.7557150) - (Std. TS - 0.01019) - Params - {'batch_size': 24, 'epochs': 200}\n",
      "(Mean TS: 0.7491870) - (Std. TS - 0.00207) - Params - {'batch_size': 32, 'epochs': 50}\n",
      "(Mean TS: 0.7475689) - (Std. TS - 0.00791) - Params - {'batch_size': 32, 'epochs': 100}\n",
      "(Mean TS: 0.7475689) - (Std. TS - 0.00791) - Params - {'batch_size': 32, 'epochs': 200}\n",
      "(Mean TS: 0.7361709) - (Std. TS - 0.00631) - Params - {'batch_size': 64, 'epochs': 50}\n",
      "(Mean TS: 0.7459350) - (Std. TS - 0.00663) - Params - {'batch_size': 64, 'epochs': 100}\n",
      "(Mean TS: 0.7492029) - (Std. TS - 0.00959) - Params - {'batch_size': 64, 'epochs': 200}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"(Mean TS: {mean:.7f}) - (Std. TS - {stdev:.5f}) - Params - {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eed35e8",
   "metadata": {},
   "source": [
    "### Running the Grid Search - Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e77f7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maverick\\AppData\\Local\\Temp/ipykernel_28052/3560676524.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model, batch_size = 32, epochs = 100, verbose = 0)\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = KerasClassifier(build_fn = create_model, batch_size = 32, epochs = 100, verbose = 0)\n",
    "\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Nadam']\n",
    "param_grid = dict(opt = optimizer)\n",
    "\n",
    "# search the grid\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 2, n_jobs = -1)\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6537938c",
   "metadata": {},
   "source": [
    "### Summarized Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f6ea951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Mean TS: 0.7638945) - (Std. TS - 0.03094) - Params - {'opt': 'SGD'}\n",
      "(Mean TS: 0.7622818) - (Std. TS - 0.03650) - Params - {'opt': 'RMSprop'}\n",
      "(Mean TS: 0.6840597) - (Std. TS - 0.02764) - Params - {'opt': 'Adagrad'}\n",
      "(Mean TS: 0.6058377) - (Std. TS - 0.02318) - Params - {'opt': 'Adadelta'}\n",
      "(Mean TS: 0.7638945) - (Std. TS - 0.03340) - Params - {'opt': 'Adam'}\n",
      "(Mean TS: 0.7622684) - (Std. TS - 0.03546) - Params - {'opt': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"(Mean TS: {mean:.7f}) - (Std. TS - {stdev:.5f}) - Params - {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee5493d",
   "metadata": {},
   "source": [
    "### Running the Grid Search - Hidden Neuron Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cd8e3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maverick\\AppData\\Local\\Temp/ipykernel_28052/2999552793.py:6: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model, batch_size = 32, epochs = 100, verbose = 0)\n"
     ]
    }
   ],
   "source": [
    "#Setting even randomness\n",
    "seed(42)\n",
    "set_random_seed(42)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn = create_model, batch_size = 32, epochs = 100, verbose = 0)\n",
    "\n",
    "# define the grid search parameters\n",
    "layers = [[8], [16], [8,8], [8,16], [8,8,8], [8,16,8], [8,16,16]]\n",
    "param_grid = dict(lyrs=layers)\n",
    "\n",
    "# search the grid\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 2, n_jobs = -1)\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48f5f46",
   "metadata": {},
   "source": [
    "### Summarized Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b81ee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Mean TS: 0.7638945) - (Std. TS - 0.03340) - Params - {'lyrs': [8]}\n",
      "(Mean TS: 0.7622818) - (Std. TS - 0.03308) - Params - {'lyrs': [16]}\n",
      "(Mean TS: 0.7639078) - (Std. TS - 0.03451) - Params - {'lyrs': [8, 8]}\n",
      "(Mean TS: 0.7622684) - (Std. TS - 0.03656) - Params - {'lyrs': [8, 16]}\n",
      "(Mean TS: 0.7671598) - (Std. TS - 0.03662) - Params - {'lyrs': [8, 8, 8]}\n",
      "(Mean TS: 0.7638945) - (Std. TS - 0.03457) - Params - {'lyrs': [8, 16, 8]}\n",
      "(Mean TS: 0.7638945) - (Std. TS - 0.03457) - Params - {'lyrs': [8, 16, 16]}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"(Mean TS: {mean:.7f}) - (Std. TS - {stdev:.5f}) - Params - {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec850dc4",
   "metadata": {},
   "source": [
    "### Running the Grid Search - Drop Out Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "945e0ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maverick\\AppData\\Local\\Temp/ipykernel_28052/1107954984.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model, batch_size = 32, epochs = 100, verbose = 0)\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = KerasClassifier(build_fn = create_model, batch_size = 32, epochs = 100, verbose = 0)\n",
    "\n",
    "# define the grid search parameters\n",
    "drops = [0.0, 0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "param_grid = dict(dr = drops)\n",
    "\n",
    "# search the grid\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 2, n_jobs = -1)\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20368560",
   "metadata": {},
   "source": [
    "### Summarized Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75b3dffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Mean TS: 0.7638945) - (Std. TS - 0.03340) - Params - {'dr': 0.0}\n",
      "(Mean TS: 0.7639078) - (Std. TS - 0.03373) - Params - {'dr': 0.01}\n",
      "(Mean TS: 0.7639078) - (Std. TS - 0.03373) - Params - {'dr': 0.05}\n",
      "(Mean TS: 0.7639078) - (Std. TS - 0.03373) - Params - {'dr': 0.1}\n",
      "(Mean TS: 0.7655338) - (Std. TS - 0.03189) - Params - {'dr': 0.2}\n",
      "(Mean TS: 0.7590297) - (Std. TS - 0.02977) - Params - {'dr': 0.5}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"(Mean TS: {mean:.7f}) - (Std. TS - {stdev:.5f}) - Params - {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9387dd2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "26/26 [==============================] - 0s 803us/step - loss: 0.9666 - accuracy: 0.4707\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 843us/step - loss: 0.9495 - accuracy: 0.4528\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 910us/step - loss: 0.9241 - accuracy: 0.4853\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.9444 - accuracy: 0.4788\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.8967 - accuracy: 0.5049\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.8650 - accuracy: 0.5309\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 928us/step - loss: 0.8636 - accuracy: 0.5147\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.8213 - accuracy: 0.5261\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 979us/step - loss: 0.8228 - accuracy: 0.5309\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 913us/step - loss: 0.8193 - accuracy: 0.5456\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 969us/step - loss: 0.8007 - accuracy: 0.5391\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 953us/step - loss: 0.7906 - accuracy: 0.5831\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.7623 - accuracy: 0.5928\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 928us/step - loss: 0.7305 - accuracy: 0.6042\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.7444 - accuracy: 0.5814\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.6319\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7341 - accuracy: 0.5961\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.6091\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.6173\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.6221\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6705 - accuracy: 0.6368\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.6270\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.6507 - accuracy: 0.6384\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.6371 - accuracy: 0.6531\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.6262 - accuracy: 0.6612\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 0.6417\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6265 - accuracy: 0.6580\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5963 - accuracy: 0.6808\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.6153 - accuracy: 0.6612\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.6002 - accuracy: 0.6743\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5837 - accuracy: 0.6971\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5935 - accuracy: 0.6824\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.6824\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 946us/step - loss: 0.5764 - accuracy: 0.6906\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5588 - accuracy: 0.7101\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 943us/step - loss: 0.5568 - accuracy: 0.7085\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.6987\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5554 - accuracy: 0.7036\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 994us/step - loss: 0.5636 - accuracy: 0.7117\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5548 - accuracy: 0.7020\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.7215\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.7117\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.7134\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5397 - accuracy: 0.7280\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 995us/step - loss: 0.5398 - accuracy: 0.7182\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5525 - accuracy: 0.7003\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5278 - accuracy: 0.7248\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5283 - accuracy: 0.7394\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5362 - accuracy: 0.7231\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5208 - accuracy: 0.7313\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5257 - accuracy: 0.7492\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5327 - accuracy: 0.7280\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5245 - accuracy: 0.7345\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5378 - accuracy: 0.7215\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 979us/step - loss: 0.5162 - accuracy: 0.7410\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5343 - accuracy: 0.7296\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 981us/step - loss: 0.5161 - accuracy: 0.7573\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 931us/step - loss: 0.5231 - accuracy: 0.7362\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 921us/step - loss: 0.5196 - accuracy: 0.7362\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 982us/step - loss: 0.5203 - accuracy: 0.7264\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 968us/step - loss: 0.5228 - accuracy: 0.7476\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5180 - accuracy: 0.7362\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 959us/step - loss: 0.5067 - accuracy: 0.7508\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5301 - accuracy: 0.7362\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.7476\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.7378\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.7264\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7492\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7606\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.7443\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5075 - accuracy: 0.7443\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 975us/step - loss: 0.5294 - accuracy: 0.7248\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 913us/step - loss: 0.5171 - accuracy: 0.7345\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5119 - accuracy: 0.7378\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 855us/step - loss: 0.5098 - accuracy: 0.7427\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5155 - accuracy: 0.7394\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5073 - accuracy: 0.7476\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.5144 - accuracy: 0.7362\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 870us/step - loss: 0.5036 - accuracy: 0.7573\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 875us/step - loss: 0.5066 - accuracy: 0.7622\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5214 - accuracy: 0.7362\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 850us/step - loss: 0.5218 - accuracy: 0.7264\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 904us/step - loss: 0.5184 - accuracy: 0.7394\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 892us/step - loss: 0.5143 - accuracy: 0.7606\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 912us/step - loss: 0.5082 - accuracy: 0.7622\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 954us/step - loss: 0.5199 - accuracy: 0.7394\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 876us/step - loss: 0.5031 - accuracy: 0.7557\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 824us/step - loss: 0.4999 - accuracy: 0.7443\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.5124 - accuracy: 0.7443\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 886us/step - loss: 0.5198 - accuracy: 0.7280\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 856us/step - loss: 0.5230 - accuracy: 0.7492\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 875us/step - loss: 0.5103 - accuracy: 0.7427\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 852us/step - loss: 0.4972 - accuracy: 0.7427\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 812us/step - loss: 0.5040 - accuracy: 0.7541\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 855us/step - loss: 0.5193 - accuracy: 0.7264\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 828us/step - loss: 0.5270 - accuracy: 0.7362\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5158 - accuracy: 0.7378\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7622\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7459\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.7313\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7606\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7394\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.7394\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7541\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.7557\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 835us/step - loss: 0.5046 - accuracy: 0.7492\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5028 - accuracy: 0.7606\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 854us/step - loss: 0.5130 - accuracy: 0.7459\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 871us/step - loss: 0.5202 - accuracy: 0.7590\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.5266 - accuracy: 0.7378\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 826us/step - loss: 0.5060 - accuracy: 0.7590\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 819us/step - loss: 0.5142 - accuracy: 0.7492\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 809us/step - loss: 0.5219 - accuracy: 0.7410\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 758us/step - loss: 0.4996 - accuracy: 0.7524\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 783us/step - loss: 0.5178 - accuracy: 0.7345\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 823us/step - loss: 0.5075 - accuracy: 0.7313\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 828us/step - loss: 0.5167 - accuracy: 0.7557\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 815us/step - loss: 0.5161 - accuracy: 0.7476\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 798us/step - loss: 0.5148 - accuracy: 0.7541\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 845us/step - loss: 0.4887 - accuracy: 0.7541\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.5098 - accuracy: 0.7394\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 810us/step - loss: 0.5195 - accuracy: 0.7329\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 798us/step - loss: 0.5149 - accuracy: 0.7541\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 798us/step - loss: 0.5123 - accuracy: 0.7476\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.5119 - accuracy: 0.7459\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 846us/step - loss: 0.5144 - accuracy: 0.7492\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 860us/step - loss: 0.5212 - accuracy: 0.7362\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 857us/step - loss: 0.5023 - accuracy: 0.7508\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 832us/step - loss: 0.5230 - accuracy: 0.7378\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 798us/step - loss: 0.5272 - accuracy: 0.7394\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 875us/step - loss: 0.5165 - accuracy: 0.7427\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 797us/step - loss: 0.5160 - accuracy: 0.7264\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 822us/step - loss: 0.5095 - accuracy: 0.7394\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 834us/step - loss: 0.5262 - accuracy: 0.7248\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 858us/step - loss: 0.5058 - accuracy: 0.7606\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 803us/step - loss: 0.5112 - accuracy: 0.7394\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 849us/step - loss: 0.5149 - accuracy: 0.7524\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 807us/step - loss: 0.4950 - accuracy: 0.7557\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 837us/step - loss: 0.5074 - accuracy: 0.7476\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 823us/step - loss: 0.5141 - accuracy: 0.7410\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 826us/step - loss: 0.5033 - accuracy: 0.7590\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 885us/step - loss: 0.5141 - accuracy: 0.7443\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 844us/step - loss: 0.5286 - accuracy: 0.7378\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 799us/step - loss: 0.5154 - accuracy: 0.7655\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 843us/step - loss: 0.5215 - accuracy: 0.7459\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.5214 - accuracy: 0.7280\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 914us/step - loss: 0.5191 - accuracy: 0.7459\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 877us/step - loss: 0.5214 - accuracy: 0.7329\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 891us/step - loss: 0.5170 - accuracy: 0.7590\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 846us/step - loss: 0.5128 - accuracy: 0.7573\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 910us/step - loss: 0.5089 - accuracy: 0.7394\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 888us/step - loss: 0.5001 - accuracy: 0.7606\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 864us/step - loss: 0.5245 - accuracy: 0.7329\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.5250 - accuracy: 0.7313\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 871us/step - loss: 0.5158 - accuracy: 0.7524\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 891us/step - loss: 0.4959 - accuracy: 0.7638\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 899us/step - loss: 0.5177 - accuracy: 0.7459\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 889us/step - loss: 0.5112 - accuracy: 0.7427\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 908us/step - loss: 0.5076 - accuracy: 0.7606\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 857us/step - loss: 0.5126 - accuracy: 0.7296\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 838us/step - loss: 0.5070 - accuracy: 0.7394\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 865us/step - loss: 0.5255 - accuracy: 0.7443\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 859us/step - loss: 0.5032 - accuracy: 0.7557\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 833us/step - loss: 0.5201 - accuracy: 0.7443\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 853us/step - loss: 0.5039 - accuracy: 0.7638\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.5092 - accuracy: 0.7508\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5010 - accuracy: 0.7590\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5113 - accuracy: 0.7492\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.5085 - accuracy: 0.7492\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 848us/step - loss: 0.5189 - accuracy: 0.7394\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 839us/step - loss: 0.5137 - accuracy: 0.7329\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.5021 - accuracy: 0.7590\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 869us/step - loss: 0.5179 - accuracy: 0.7313\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.5188 - accuracy: 0.7492\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.7329\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.7443\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 949us/step - loss: 0.5036 - accuracy: 0.7606\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 872us/step - loss: 0.5105 - accuracy: 0.7508\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 895us/step - loss: 0.5191 - accuracy: 0.7313\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 896us/step - loss: 0.5084 - accuracy: 0.7590\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 903us/step - loss: 0.5166 - accuracy: 0.7443\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 889us/step - loss: 0.5172 - accuracy: 0.7427\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 931us/step - loss: 0.5265 - accuracy: 0.7410\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 921us/step - loss: 0.5066 - accuracy: 0.7459\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.5115 - accuracy: 0.7410\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 876us/step - loss: 0.5159 - accuracy: 0.7410\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 870us/step - loss: 0.4965 - accuracy: 0.7573\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 955us/step - loss: 0.5183 - accuracy: 0.7443\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 967us/step - loss: 0.5299 - accuracy: 0.7492\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 903us/step - loss: 0.5124 - accuracy: 0.7459\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 882us/step - loss: 0.5161 - accuracy: 0.7329\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 893us/step - loss: 0.5248 - accuracy: 0.7345\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5043 - accuracy: 0.7573\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5138 - accuracy: 0.7590\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 888us/step - loss: 0.5070 - accuracy: 0.7557\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 870us/step - loss: 0.5218 - accuracy: 0.7541\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 872us/step - loss: 0.5224 - accuracy: 0.7427\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 950us/step - loss: 0.5006 - accuracy: 0.7638\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 955us/step - loss: 0.5117 - accuracy: 0.7345\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 950us/step - loss: 0.5192 - accuracy: 0.7394\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 0s 949us/step - loss: 0.9268 - accuracy: 0.4235\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 899us/step - loss: 0.8879 - accuracy: 0.4300\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.8076 - accuracy: 0.4739\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.7539 - accuracy: 0.5358\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 871us/step - loss: 0.7184 - accuracy: 0.5765\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.7090 - accuracy: 0.5635\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.6643 - accuracy: 0.6173\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 906us/step - loss: 0.6448 - accuracy: 0.6498\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.6244 - accuracy: 0.6352\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 921us/step - loss: 0.6157 - accuracy: 0.6612\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 954us/step - loss: 0.6227 - accuracy: 0.6515\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 933us/step - loss: 0.6069 - accuracy: 0.6694\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 923us/step - loss: 0.5895 - accuracy: 0.6645\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 873us/step - loss: 0.5878 - accuracy: 0.6906\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 898us/step - loss: 0.5970 - accuracy: 0.6726\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5567 - accuracy: 0.7036\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 881us/step - loss: 0.6055 - accuracy: 0.6531\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.5699 - accuracy: 0.6906\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 947us/step - loss: 0.5691 - accuracy: 0.7020\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 915us/step - loss: 0.5509 - accuracy: 0.6971\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 951us/step - loss: 0.5706 - accuracy: 0.7248\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 965us/step - loss: 0.5546 - accuracy: 0.6971\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.5889 - accuracy: 0.6792\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 932us/step - loss: 0.5589 - accuracy: 0.6954\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5466 - accuracy: 0.7150\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 885us/step - loss: 0.5404 - accuracy: 0.7117\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5494 - accuracy: 0.7134\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 941us/step - loss: 0.5530 - accuracy: 0.7036\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 993us/step - loss: 0.5521 - accuracy: 0.7068\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 993us/step - loss: 0.5549 - accuracy: 0.7150\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 996us/step - loss: 0.5354 - accuracy: 0.7199\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 936us/step - loss: 0.5540 - accuracy: 0.7068\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 998us/step - loss: 0.5323 - accuracy: 0.7394\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 950us/step - loss: 0.5268 - accuracy: 0.7313\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5279 - accuracy: 0.7329\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7134\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5420 - accuracy: 0.7085\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 899us/step - loss: 0.5189 - accuracy: 0.7296\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 965us/step - loss: 0.5506 - accuracy: 0.7150\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 977us/step - loss: 0.5356 - accuracy: 0.7166\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 973us/step - loss: 0.5494 - accuracy: 0.7085\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5195 - accuracy: 0.7378\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.7378\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.7199\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 973us/step - loss: 0.5228 - accuracy: 0.7117\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 973us/step - loss: 0.5437 - accuracy: 0.7329\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 923us/step - loss: 0.5206 - accuracy: 0.7296\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.5402 - accuracy: 0.7329\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 990us/step - loss: 0.5363 - accuracy: 0.7117\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 998us/step - loss: 0.5356 - accuracy: 0.7394\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 988us/step - loss: 0.5272 - accuracy: 0.7394\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 994us/step - loss: 0.5433 - accuracy: 0.7020\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 911us/step - loss: 0.5160 - accuracy: 0.7410\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5298 - accuracy: 0.7329\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 935us/step - loss: 0.5151 - accuracy: 0.7573\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 909us/step - loss: 0.5397 - accuracy: 0.7362\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 984us/step - loss: 0.5158 - accuracy: 0.7590\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 943us/step - loss: 0.5102 - accuracy: 0.7362\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 962us/step - loss: 0.5038 - accuracy: 0.7508\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5176 - accuracy: 0.7215\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 941us/step - loss: 0.5229 - accuracy: 0.7280\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 960us/step - loss: 0.5116 - accuracy: 0.7394\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 936us/step - loss: 0.5176 - accuracy: 0.7443\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5232 - accuracy: 0.7362\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5205 - accuracy: 0.7231\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 882us/step - loss: 0.5342 - accuracy: 0.7378\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 955us/step - loss: 0.5107 - accuracy: 0.7280\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5080 - accuracy: 0.7590\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 982us/step - loss: 0.4994 - accuracy: 0.7541\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 949us/step - loss: 0.5071 - accuracy: 0.7476\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.7345\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 964us/step - loss: 0.5226 - accuracy: 0.7280\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 930us/step - loss: 0.5130 - accuracy: 0.7443\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 955us/step - loss: 0.5239 - accuracy: 0.7264\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 929us/step - loss: 0.5096 - accuracy: 0.7378\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 964us/step - loss: 0.5137 - accuracy: 0.7492\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7508\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 979us/step - loss: 0.5143 - accuracy: 0.7410\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.4956 - accuracy: 0.7427\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 962us/step - loss: 0.4971 - accuracy: 0.7622\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5140 - accuracy: 0.7427\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.7541\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5223 - accuracy: 0.7459\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 988us/step - loss: 0.5188 - accuracy: 0.7508\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7443\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.7296\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.7590\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.7378\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5162 - accuracy: 0.7410\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 937us/step - loss: 0.5193 - accuracy: 0.7362\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7345\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 947us/step - loss: 0.4943 - accuracy: 0.7362\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.7622\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 926us/step - loss: 0.5125 - accuracy: 0.7443\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 988us/step - loss: 0.5209 - accuracy: 0.7313\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5168 - accuracy: 0.7345\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.7524\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7687\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7704\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.7410\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7410\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7476\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.7394\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7476\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.7378\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7476\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 996us/step - loss: 0.5101 - accuracy: 0.7524\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5061 - accuracy: 0.7557\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5216 - accuracy: 0.7410\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.7329\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 987us/step - loss: 0.5021 - accuracy: 0.7541\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 999us/step - loss: 0.5046 - accuracy: 0.7443\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.7313\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.7508\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.7410\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 998us/step - loss: 0.5039 - accuracy: 0.7524\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5182 - accuracy: 0.7394\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5177 - accuracy: 0.7524\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 986us/step - loss: 0.5039 - accuracy: 0.7541\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4800 - accuracy: 0.7638\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 997us/step - loss: 0.5117 - accuracy: 0.7443\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7443\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5050 - accuracy: 0.7622\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 981us/step - loss: 0.5159 - accuracy: 0.7345\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.7638\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5087 - accuracy: 0.7557\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5038 - accuracy: 0.7492\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4908 - accuracy: 0.7655\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5136 - accuracy: 0.7541\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5198 - accuracy: 0.7557\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4989 - accuracy: 0.7606\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5231 - accuracy: 0.7296\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.4989 - accuracy: 0.7476\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7345\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.5045 - accuracy: 0.7410\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 938us/step - loss: 0.5145 - accuracy: 0.7459\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 994us/step - loss: 0.5003 - accuracy: 0.7459\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7655\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7557\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 967us/step - loss: 0.5012 - accuracy: 0.7622\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7606\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4968 - accuracy: 0.7410\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5183 - accuracy: 0.7378\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5086 - accuracy: 0.7671\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5179 - accuracy: 0.7427\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.7280\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5080 - accuracy: 0.7443\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7476\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7606\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7573\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4935 - accuracy: 0.7573\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 984us/step - loss: 0.4944 - accuracy: 0.7492\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 994us/step - loss: 0.5218 - accuracy: 0.7394\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7280\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.5105 - accuracy: 0.7443\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 994us/step - loss: 0.4974 - accuracy: 0.7492\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7508\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.7378\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.7671\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5132 - accuracy: 0.7459\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7427\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7541\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.7508\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7427\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7622\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5011 - accuracy: 0.7557\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4811 - accuracy: 0.7638\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7410\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7524\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5168 - accuracy: 0.7443\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7492\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7638\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.7459\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7541\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5338 - accuracy: 0.7427\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.7427\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7655\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.7362\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5131 - accuracy: 0.7345\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7606\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 967us/step - loss: 0.5157 - accuracy: 0.7427\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5120 - accuracy: 0.7443\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7329\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5117 - accuracy: 0.7410\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 967us/step - loss: 0.4947 - accuracy: 0.7590\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 958us/step - loss: 0.5260 - accuracy: 0.7199\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 984us/step - loss: 0.4780 - accuracy: 0.7557\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 952us/step - loss: 0.5173 - accuracy: 0.7524\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.7362\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 968us/step - loss: 0.5103 - accuracy: 0.7378\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 980us/step - loss: 0.5110 - accuracy: 0.7394\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4969 - accuracy: 0.7459\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5107 - accuracy: 0.7313\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.4872 - accuracy: 0.7622\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 972us/step - loss: 0.5033 - accuracy: 0.7492\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 938us/step - loss: 0.5225 - accuracy: 0.7394\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5237 - accuracy: 0.7492\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.4946 - accuracy: 0.7687\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 939us/step - loss: 0.4985 - accuracy: 0.7638\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7296\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 0s 930us/step - loss: 0.8387 - accuracy: 0.4153\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.7468 - accuracy: 0.5130\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.7135 - accuracy: 0.5456\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.6506 - accuracy: 0.6173\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.6190 - accuracy: 0.6596\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 923us/step - loss: 0.5983 - accuracy: 0.6612\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5668 - accuracy: 0.7231\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5635 - accuracy: 0.7134\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5715 - accuracy: 0.7166\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5489 - accuracy: 0.7085\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5557 - accuracy: 0.7134\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5324 - accuracy: 0.7459\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5390 - accuracy: 0.7199\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 940us/step - loss: 0.5200 - accuracy: 0.7362\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 954us/step - loss: 0.5253 - accuracy: 0.7362\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 913us/step - loss: 0.5250 - accuracy: 0.7362\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 921us/step - loss: 0.5367 - accuracy: 0.7215\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5202 - accuracy: 0.7345\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5100 - accuracy: 0.7492\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 953us/step - loss: 0.5175 - accuracy: 0.7410\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5141 - accuracy: 0.7410\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5134 - accuracy: 0.7443\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5265 - accuracy: 0.7215\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 954us/step - loss: 0.5211 - accuracy: 0.7362\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 896us/step - loss: 0.5134 - accuracy: 0.7280\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 919us/step - loss: 0.5190 - accuracy: 0.7264\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5171 - accuracy: 0.7296\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 925us/step - loss: 0.5053 - accuracy: 0.7394\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 908us/step - loss: 0.5108 - accuracy: 0.7410\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 908us/step - loss: 0.5153 - accuracy: 0.7231\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.4934 - accuracy: 0.7573\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 925us/step - loss: 0.4994 - accuracy: 0.7557\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5192 - accuracy: 0.7524\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 959us/step - loss: 0.5139 - accuracy: 0.7362\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 968us/step - loss: 0.4926 - accuracy: 0.7622\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5018 - accuracy: 0.7378\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 964us/step - loss: 0.5185 - accuracy: 0.7313\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 956us/step - loss: 0.4974 - accuracy: 0.7492\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5152 - accuracy: 0.7524\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5137 - accuracy: 0.7427\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 969us/step - loss: 0.5112 - accuracy: 0.7524\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4985 - accuracy: 0.7590\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.5146 - accuracy: 0.7427\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5031 - accuracy: 0.7508\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5135 - accuracy: 0.7313\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 996us/step - loss: 0.5252 - accuracy: 0.7459\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 971us/step - loss: 0.4935 - accuracy: 0.7524\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 991us/step - loss: 0.5048 - accuracy: 0.7476\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4979 - accuracy: 0.7573\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 958us/step - loss: 0.5070 - accuracy: 0.7410\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 990us/step - loss: 0.5074 - accuracy: 0.7573\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 928us/step - loss: 0.5136 - accuracy: 0.7362\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4972 - accuracy: 0.7492\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5005 - accuracy: 0.7362\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 1000us/step - loss: 0.5032 - accuracy: 0.7671\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 981us/step - loss: 0.5252 - accuracy: 0.7313\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4906 - accuracy: 0.7476\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5021 - accuracy: 0.7622\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7557\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 984us/step - loss: 0.4890 - accuracy: 0.7427\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 992us/step - loss: 0.5044 - accuracy: 0.7459\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4925 - accuracy: 0.7362\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 933us/step - loss: 0.4942 - accuracy: 0.7687\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 990us/step - loss: 0.5258 - accuracy: 0.7378\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 938us/step - loss: 0.4984 - accuracy: 0.7524\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 934us/step - loss: 0.5234 - accuracy: 0.7492\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 969us/step - loss: 0.5129 - accuracy: 0.7394\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 958us/step - loss: 0.4881 - accuracy: 0.7573\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 987us/step - loss: 0.4895 - accuracy: 0.7606\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 920us/step - loss: 0.4842 - accuracy: 0.7687\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.4765 - accuracy: 0.7541\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5169 - accuracy: 0.7443\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 962us/step - loss: 0.5022 - accuracy: 0.7573\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 950us/step - loss: 0.4894 - accuracy: 0.7541\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 976us/step - loss: 0.4938 - accuracy: 0.7427\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 941us/step - loss: 0.4908 - accuracy: 0.7476\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.7704\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4892 - accuracy: 0.7606\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 978us/step - loss: 0.4843 - accuracy: 0.7687\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.4768 - accuracy: 0.7638\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 993us/step - loss: 0.4973 - accuracy: 0.7443\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7394\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.7524\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5104 - accuracy: 0.7573\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5098 - accuracy: 0.7557\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5119 - accuracy: 0.7492\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 950us/step - loss: 0.5058 - accuracy: 0.7622\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 929us/step - loss: 0.4821 - accuracy: 0.7622\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 976us/step - loss: 0.4997 - accuracy: 0.7508\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.5013 - accuracy: 0.7573\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 955us/step - loss: 0.5016 - accuracy: 0.7704\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5028 - accuracy: 0.7345\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 988us/step - loss: 0.4829 - accuracy: 0.7557\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4908 - accuracy: 0.7671\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 947us/step - loss: 0.5040 - accuracy: 0.7378\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.7508\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 983us/step - loss: 0.4915 - accuracy: 0.7524\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 919us/step - loss: 0.4849 - accuracy: 0.7818\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 936us/step - loss: 0.4774 - accuracy: 0.7573\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 978us/step - loss: 0.4946 - accuracy: 0.7899\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 968us/step - loss: 0.4934 - accuracy: 0.7524\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4895 - accuracy: 0.7590\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 940us/step - loss: 0.5006 - accuracy: 0.7590\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.4970 - accuracy: 0.7573\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.4950 - accuracy: 0.7590\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 977us/step - loss: 0.4938 - accuracy: 0.7508\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7573\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7573\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7638\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 949us/step - loss: 0.5079 - accuracy: 0.7508\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4867 - accuracy: 0.7752\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 946us/step - loss: 0.4949 - accuracy: 0.7524\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 960us/step - loss: 0.5064 - accuracy: 0.7557\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 970us/step - loss: 0.4972 - accuracy: 0.7590\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 967us/step - loss: 0.5019 - accuracy: 0.7427\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7736\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7557\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 981us/step - loss: 0.4999 - accuracy: 0.7541\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7427\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 990us/step - loss: 0.4879 - accuracy: 0.7557\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 992us/step - loss: 0.4969 - accuracy: 0.7492\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 964us/step - loss: 0.4974 - accuracy: 0.7476\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4740 - accuracy: 0.7785\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5036 - accuracy: 0.7394\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7622\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.7704\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7508\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4880 - accuracy: 0.7606\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5071 - accuracy: 0.7557\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5004 - accuracy: 0.7508\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5086 - accuracy: 0.7573\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7557\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4721 - accuracy: 0.7638\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 954us/step - loss: 0.5067 - accuracy: 0.7296\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.7443\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7671\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4963 - accuracy: 0.7492\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 965us/step - loss: 0.4914 - accuracy: 0.7687\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4817 - accuracy: 0.7638\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4860 - accuracy: 0.7704\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.7866\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.4874 - accuracy: 0.7492\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7410\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7687\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 990us/step - loss: 0.4938 - accuracy: 0.7622\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5041 - accuracy: 0.7541\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.7590\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 989us/step - loss: 0.4892 - accuracy: 0.7508\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.7638\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.7655\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7459\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7704\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 986us/step - loss: 0.5175 - accuracy: 0.7345\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.4970 - accuracy: 0.7427\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4940 - accuracy: 0.7638\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 990us/step - loss: 0.4908 - accuracy: 0.7638\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 988us/step - loss: 0.4990 - accuracy: 0.7508\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7720\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 993us/step - loss: 0.4766 - accuracy: 0.7687\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 995us/step - loss: 0.4956 - accuracy: 0.7508\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4843 - accuracy: 0.7557\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5026 - accuracy: 0.7557\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7752\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.7541\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7638\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 991us/step - loss: 0.4866 - accuracy: 0.7476\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7850\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.4856 - accuracy: 0.7573\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.7720\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.7541\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.7541\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 984us/step - loss: 0.4887 - accuracy: 0.7785\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.7606\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 978us/step - loss: 0.4991 - accuracy: 0.7492\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5085 - accuracy: 0.7557\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7866\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7834\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7476\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7508\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7622\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7557\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7492\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.7476\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.7655\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7622\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 952us/step - loss: 0.4965 - accuracy: 0.7541\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 985us/step - loss: 0.4728 - accuracy: 0.7655\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.7606\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.7329\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 950us/step - loss: 0.4954 - accuracy: 0.7508\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.7541\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7606\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 984us/step - loss: 0.4889 - accuracy: 0.7622\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7573\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.7671\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.7524\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.7622\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 988us/step - loss: 0.4731 - accuracy: 0.7687\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7557\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7541\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.7500 - accuracy: 0.5684\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.6759 - accuracy: 0.6401\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.6334 - accuracy: 0.6384\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.6152 - accuracy: 0.6661\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5834 - accuracy: 0.6759\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 958us/step - loss: 0.5776 - accuracy: 0.6938\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5540 - accuracy: 0.7264\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.6954\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5455 - accuracy: 0.7199\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.7378\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5484 - accuracy: 0.7199\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.7410\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.7427\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5223 - accuracy: 0.7362\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7443\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.7362\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5174 - accuracy: 0.7378\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 968us/step - loss: 0.5063 - accuracy: 0.7606\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5115 - accuracy: 0.7345\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 939us/step - loss: 0.5017 - accuracy: 0.7557\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.7508\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 999us/step - loss: 0.4925 - accuracy: 0.7427\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 969us/step - loss: 0.5079 - accuracy: 0.7394\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5062 - accuracy: 0.7524\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7557\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7394\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.7394\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.7459\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7427\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.7476\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7524\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.7590\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7492\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4992 - accuracy: 0.7524\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 984us/step - loss: 0.4852 - accuracy: 0.7704\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4929 - accuracy: 0.7508\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.7378\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4897 - accuracy: 0.7622\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7622\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.7427\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7492\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7573\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 985us/step - loss: 0.4884 - accuracy: 0.7638\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 978us/step - loss: 0.4960 - accuracy: 0.7720\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 966us/step - loss: 0.4976 - accuracy: 0.7410\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 951us/step - loss: 0.5117 - accuracy: 0.7492\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.4835 - accuracy: 0.7541\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4969 - accuracy: 0.7557\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 988us/step - loss: 0.5051 - accuracy: 0.7492\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 975us/step - loss: 0.4738 - accuracy: 0.7801\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 962us/step - loss: 0.4947 - accuracy: 0.7655\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5064 - accuracy: 0.7524\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 972us/step - loss: 0.4918 - accuracy: 0.7394\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 938us/step - loss: 0.5002 - accuracy: 0.7362\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 953us/step - loss: 0.4866 - accuracy: 0.7834\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 932us/step - loss: 0.5159 - accuracy: 0.7345\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.4960 - accuracy: 0.7720\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5022 - accuracy: 0.7622\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4803 - accuracy: 0.7638\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 961us/step - loss: 0.4845 - accuracy: 0.7638\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 975us/step - loss: 0.4919 - accuracy: 0.7590\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 940us/step - loss: 0.4866 - accuracy: 0.7557\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 974us/step - loss: 0.4898 - accuracy: 0.7752\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5123 - accuracy: 0.7329\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4927 - accuracy: 0.7459\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.5120 - accuracy: 0.7508\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4950 - accuracy: 0.7508\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 967us/step - loss: 0.4804 - accuracy: 0.7785\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 938us/step - loss: 0.4834 - accuracy: 0.7524\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 964us/step - loss: 0.4732 - accuracy: 0.7687\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 955us/step - loss: 0.4897 - accuracy: 0.7704\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 965us/step - loss: 0.5067 - accuracy: 0.7410\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 954us/step - loss: 0.4915 - accuracy: 0.7704\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 937us/step - loss: 0.4890 - accuracy: 0.7541\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 951us/step - loss: 0.4814 - accuracy: 0.7508\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 912us/step - loss: 0.4842 - accuracy: 0.7573\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4972 - accuracy: 0.7410\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 929us/step - loss: 0.4878 - accuracy: 0.7508\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 934us/step - loss: 0.4908 - accuracy: 0.7687\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.4791 - accuracy: 0.7508\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 966us/step - loss: 0.4880 - accuracy: 0.7638\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 994us/step - loss: 0.4940 - accuracy: 0.7524\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 976us/step - loss: 0.4861 - accuracy: 0.7720\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 964us/step - loss: 0.5018 - accuracy: 0.7541\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 943us/step - loss: 0.4815 - accuracy: 0.7752\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 937us/step - loss: 0.5030 - accuracy: 0.7606\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 967us/step - loss: 0.4927 - accuracy: 0.7638\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 939us/step - loss: 0.4786 - accuracy: 0.7638\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 991us/step - loss: 0.4862 - accuracy: 0.7573\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7622\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.7573\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 961us/step - loss: 0.4945 - accuracy: 0.7459\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7476\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7655\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7459\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7573\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.7590\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 996us/step - loss: 0.4787 - accuracy: 0.7720\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7655\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7622\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 979us/step - loss: 0.4796 - accuracy: 0.7704\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7655\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.7655\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7590\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7590\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 989us/step - loss: 0.4865 - accuracy: 0.7622\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 977us/step - loss: 0.4682 - accuracy: 0.7704\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7785\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.7818\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.7573\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7606\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7671\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.7671\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7769\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7378\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7622\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.7671\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4841 - accuracy: 0.7622\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.7655\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4706 - accuracy: 0.7687\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7606\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7720\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7606\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4659 - accuracy: 0.7785\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4691 - accuracy: 0.7736\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4803 - accuracy: 0.7590\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 935us/step - loss: 0.4948 - accuracy: 0.7638\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 940us/step - loss: 0.4829 - accuracy: 0.7687\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 916us/step - loss: 0.5021 - accuracy: 0.7524\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.4950 - accuracy: 0.7671\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 891us/step - loss: 0.4968 - accuracy: 0.7410\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 899us/step - loss: 0.4684 - accuracy: 0.7590\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 950us/step - loss: 0.4784 - accuracy: 0.7622\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.4989 - accuracy: 0.7313\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.4868 - accuracy: 0.7410\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.4630 - accuracy: 0.7818\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 983us/step - loss: 0.4780 - accuracy: 0.7736\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4750 - accuracy: 0.7720\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 923us/step - loss: 0.4745 - accuracy: 0.7818\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4740 - accuracy: 0.7704\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.4803 - accuracy: 0.7801\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 926us/step - loss: 0.4716 - accuracy: 0.7638\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.4981 - accuracy: 0.7459\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5028 - accuracy: 0.7736\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4914 - accuracy: 0.7590\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 994us/step - loss: 0.4856 - accuracy: 0.7394\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 932us/step - loss: 0.4872 - accuracy: 0.7671\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 949us/step - loss: 0.4906 - accuracy: 0.7671\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7638\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 934us/step - loss: 0.4823 - accuracy: 0.7687\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 982us/step - loss: 0.4716 - accuracy: 0.7655\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4670 - accuracy: 0.7524\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 990us/step - loss: 0.4975 - accuracy: 0.7362\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4927 - accuracy: 0.7508\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4935 - accuracy: 0.7704\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.4781 - accuracy: 0.7622\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4841 - accuracy: 0.7622\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.4832 - accuracy: 0.7671\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4682 - accuracy: 0.7736\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4850 - accuracy: 0.7671\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 927us/step - loss: 0.4709 - accuracy: 0.7638\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 920us/step - loss: 0.4832 - accuracy: 0.7622\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 865us/step - loss: 0.4766 - accuracy: 0.7687\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 969us/step - loss: 0.4608 - accuracy: 0.7752\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 960us/step - loss: 0.4711 - accuracy: 0.7785\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4818 - accuracy: 0.7752\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.4620 - accuracy: 0.7752\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7834\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 924us/step - loss: 0.4801 - accuracy: 0.7752\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 967us/step - loss: 0.4855 - accuracy: 0.7476\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7704\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7655\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.7752\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 988us/step - loss: 0.4827 - accuracy: 0.7573\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 973us/step - loss: 0.4969 - accuracy: 0.7590\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4639 - accuracy: 0.7769\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 990us/step - loss: 0.4576 - accuracy: 0.7883\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4808 - accuracy: 0.7638\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4954 - accuracy: 0.7427\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4921 - accuracy: 0.7541\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4890 - accuracy: 0.7590\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4936 - accuracy: 0.7492\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4945 - accuracy: 0.7638\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4739 - accuracy: 0.7671\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7638\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7573\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 995us/step - loss: 0.4654 - accuracy: 0.7752\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 948us/step - loss: 0.4852 - accuracy: 0.7834\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.7524\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7834\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4848 - accuracy: 0.7638\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7655\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 971us/step - loss: 0.4963 - accuracy: 0.7427\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 984us/step - loss: 0.4706 - accuracy: 0.7622\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 984us/step - loss: 0.4778 - accuracy: 0.7818\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 987us/step - loss: 0.4884 - accuracy: 0.7671\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.7492\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 980us/step - loss: 0.4672 - accuracy: 0.7704\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4773 - accuracy: 0.7622\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 949us/step - loss: 0.4864 - accuracy: 0.7606\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 0s 971us/step - loss: 0.6728 - accuracy: 0.5912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 984us/step - loss: 0.5942 - accuracy: 0.7134\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5502 - accuracy: 0.7199\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5480 - accuracy: 0.7345\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5313 - accuracy: 0.7362\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 935us/step - loss: 0.5331 - accuracy: 0.7313\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 938us/step - loss: 0.5057 - accuracy: 0.7459\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 940us/step - loss: 0.5142 - accuracy: 0.7378\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 985us/step - loss: 0.5250 - accuracy: 0.7280\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 991us/step - loss: 0.5113 - accuracy: 0.7427\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.7443\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 984us/step - loss: 0.5085 - accuracy: 0.7313\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 926us/step - loss: 0.5072 - accuracy: 0.7459\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 942us/step - loss: 0.4999 - accuracy: 0.7345\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 954us/step - loss: 0.4977 - accuracy: 0.7524\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 971us/step - loss: 0.5100 - accuracy: 0.7459\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 948us/step - loss: 0.5136 - accuracy: 0.7313\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7524\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7541\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 980us/step - loss: 0.4907 - accuracy: 0.7622\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 981us/step - loss: 0.4936 - accuracy: 0.7541\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 983us/step - loss: 0.4872 - accuracy: 0.7524\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.7443\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4981 - accuracy: 0.7492\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7557\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4951 - accuracy: 0.7541\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5025 - accuracy: 0.7476\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.7541\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 998us/step - loss: 0.4818 - accuracy: 0.7606\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 990us/step - loss: 0.4929 - accuracy: 0.7524\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 990us/step - loss: 0.4806 - accuracy: 0.7541\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 976us/step - loss: 0.4824 - accuracy: 0.7671\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 972us/step - loss: 0.4844 - accuracy: 0.7524\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.4950 - accuracy: 0.7476\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 991us/step - loss: 0.4841 - accuracy: 0.7736\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.7671\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7248\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7573\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7476\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7671\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 994us/step - loss: 0.4959 - accuracy: 0.7427\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7590\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.7541\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 994us/step - loss: 0.4800 - accuracy: 0.7590\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 950us/step - loss: 0.4881 - accuracy: 0.7492\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7655\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.7590\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.7590\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.7638\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4819 - accuracy: 0.7524\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.7606\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.7362\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7557\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7492\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7834\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7443\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7655\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7736\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7590\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.7541\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7410\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.7638\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7459\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7427\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4768 - accuracy: 0.7671\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7508\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7622\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4683 - accuracy: 0.7720\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7704\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7541\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7834\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.7362\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7492\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7524\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7492\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.7508\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.7638\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.7541\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7671\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7687\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7573\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7508\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7655\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.7590\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7606\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7573\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7801\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7671\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7590\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.7524\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7720\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.7573\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7557\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7622\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7557\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.7524\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.7606\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7818\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.7704\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7720\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7622\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7590\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7573\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7671\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7769\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.7655\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7638\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.7378\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7720\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7557\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4785 - accuracy: 0.7590\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4839 - accuracy: 0.7524\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4909 - accuracy: 0.7508\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4826 - accuracy: 0.7606\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7573\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7932\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7655\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.7704\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7720\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.7834\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7606\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7590\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4588 - accuracy: 0.7932\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4637 - accuracy: 0.7590\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7834\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7704\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7606\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7769\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7557\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7752\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4956 - accuracy: 0.7427\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.7557\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.4689 - accuracy: 0.7638\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.7459\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7590\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7736\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7752\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7590\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7785\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7638\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7785\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7704\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7590\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7752\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7736\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7769\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7785\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7492\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7752\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7704\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7704\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.7818\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.7508\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.7394\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7606\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7704\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7638\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.7704\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7769\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7622\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7752\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7622\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7720\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7638\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.7752\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7769\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7915\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7720\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7736\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.7573\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7638\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7736\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7704\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7541\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.7362\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7834\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7899\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7573\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7508\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7508\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7557\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7590\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7573\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7606\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7720\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7508\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7964\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7866\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7541\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7720\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7476\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7704\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4763 - accuracy: 0.7573\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7622\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7720\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7655\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.7655\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7769\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7834\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7655\n"
     ]
    }
   ],
   "source": [
    "layers = []\n",
    "i = [0, 8, 16, 32, 64]\n",
    "\n",
    "\n",
    "for a in i:\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(8, )))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    \n",
    "    if(a != 0):\n",
    "        model.add(tf.keras.layers.Dense(a, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer = \"RMSprop\", loss = \"binary_crossentropy\" , metrics = ['accuracy'])\n",
    "\n",
    "    #fitting the ANN to the training set\n",
    "    model.fit(X_train, Y_train , batch_size = 24 , epochs = 200)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_pred = (Y_pred>0.5)\n",
    "\n",
    "    cm = confusion_matrix(Y_test,Y_pred)\n",
    "    accuracy=((cm[0,0]+cm[1,1])/(cm[0,1]+cm[1,1]+cm[0,0]+cm[1,0]))\n",
    "    layers.append(str(accuracy) + '%; L1 = 8 ' + '; L2 = '+ str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61eee76",
   "metadata": {},
   "source": [
    "### Best Combination of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "288c8788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8311688311688312%; L1 = 8 ; L2 = 0\n",
      "0.8051948051948052%; L1 = 8 ; L2 = 8\n",
      "0.8246753246753247%; L1 = 8 ; L2 = 16\n",
      "0.8116883116883117%; L1 = 8 ; L2 = 32\n",
      "0.8051948051948052%; L1 = 8 ; L2 = 64\n"
     ]
    }
   ],
   "source": [
    "for value in layers: print(value, end = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671afbd7",
   "metadata": {},
   "source": [
    "## Final Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fa9444",
   "metadata": {},
   "source": [
    "### Best Hyperparameter Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef67e6",
   "metadata": {},
   "source": [
    "1. Layers 1 ; Units = 8\n",
    "2. Batch_Size = 24\n",
    "3. Epochs = 200\n",
    "4. Optimizer = 'RMSprop'\n",
    "5. Drop Out Layer Value = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd571e0",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6faade54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_57 (Flatten)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(8, )))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573c2fbc",
   "metadata": {},
   "source": [
    "### Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bc7045d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "26/26 [==============================] - 0s 838us/step - loss: 1.1130 - accuracy: 0.3730\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 866us/step - loss: 1.0778 - accuracy: 0.3648\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 1.0534 - accuracy: 0.3681\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 1.0047 - accuracy: 0.3974\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.9805 - accuracy: 0.4169\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.9366 - accuracy: 0.4137\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.9024 - accuracy: 0.4169\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.9004 - accuracy: 0.4235\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.8612 - accuracy: 0.4430\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.8637 - accuracy: 0.4609\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.8252 - accuracy: 0.4870\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.7983 - accuracy: 0.4919\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 985us/step - loss: 0.7931 - accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 966us/step - loss: 0.7508 - accuracy: 0.5261\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7302 - accuracy: 0.5440\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.5733\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7152 - accuracy: 0.5928\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.6156\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.6303\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6614 - accuracy: 0.6515\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6564\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 994us/step - loss: 0.6473 - accuracy: 0.6417\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.6421 - accuracy: 0.6498\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.6282 - accuracy: 0.6612\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.6125 - accuracy: 0.6775\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.6045 - accuracy: 0.6612\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 995us/step - loss: 0.5923 - accuracy: 0.6840\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5931 - accuracy: 0.6824\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5901 - accuracy: 0.6840\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.6938\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 989us/step - loss: 0.5683 - accuracy: 0.7101\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 994us/step - loss: 0.5679 - accuracy: 0.6889\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.7117\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 995us/step - loss: 0.5569 - accuracy: 0.7117\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 942us/step - loss: 0.5480 - accuracy: 0.7313\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 978us/step - loss: 0.5473 - accuracy: 0.7248\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5557 - accuracy: 0.7199\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 940us/step - loss: 0.5416 - accuracy: 0.7313\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5490 - accuracy: 0.7182\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5418 - accuracy: 0.7248\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5409 - accuracy: 0.7150\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5333 - accuracy: 0.7231\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.7280\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5320 - accuracy: 0.7231\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5268 - accuracy: 0.7329\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5469 - accuracy: 0.7215\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5191 - accuracy: 0.7296\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5241 - accuracy: 0.7427\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5290 - accuracy: 0.7394\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5139 - accuracy: 0.7508\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5184 - accuracy: 0.7492\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5357 - accuracy: 0.7345\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5198 - accuracy: 0.7345\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5299 - accuracy: 0.7280\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.5162 - accuracy: 0.7541\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5335 - accuracy: 0.7313\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5104 - accuracy: 0.7590\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5207 - accuracy: 0.7524\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5169 - accuracy: 0.7492\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5167 - accuracy: 0.7362\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5200 - accuracy: 0.7443\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.7427\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7687\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5317 - accuracy: 0.7410\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7557\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5302 - accuracy: 0.7313\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7329\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7541\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5100 - accuracy: 0.7557\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7427\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5055 - accuracy: 0.7508\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 953us/step - loss: 0.5289 - accuracy: 0.7345\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5150 - accuracy: 0.7345\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5112 - accuracy: 0.7394\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 978us/step - loss: 0.5074 - accuracy: 0.7443\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5134 - accuracy: 0.7476\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5057 - accuracy: 0.7459\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 945us/step - loss: 0.5135 - accuracy: 0.7410\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 993us/step - loss: 0.5027 - accuracy: 0.7638\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.5049 - accuracy: 0.7655\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5207 - accuracy: 0.7329\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5226 - accuracy: 0.7378\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5167 - accuracy: 0.7427\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5139 - accuracy: 0.7557\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 896us/step - loss: 0.5080 - accuracy: 0.7524\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 870us/step - loss: 0.5188 - accuracy: 0.7443\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 939us/step - loss: 0.5022 - accuracy: 0.7590\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 913us/step - loss: 0.4991 - accuracy: 0.7459\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 898us/step - loss: 0.5123 - accuracy: 0.7443\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 875us/step - loss: 0.5204 - accuracy: 0.7264\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5225 - accuracy: 0.7476\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7394\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.7459\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7557\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5194 - accuracy: 0.7329\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.7362\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5159 - accuracy: 0.7410\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7622\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5132 - accuracy: 0.7459\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 931us/step - loss: 0.5209 - accuracy: 0.7280\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5141 - accuracy: 0.7606\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5089 - accuracy: 0.7427\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5152 - accuracy: 0.7378\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.5060 - accuracy: 0.7573\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.4986 - accuracy: 0.7541\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 876us/step - loss: 0.5045 - accuracy: 0.7476\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 876us/step - loss: 0.5026 - accuracy: 0.7573\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 896us/step - loss: 0.5130 - accuracy: 0.7557\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 960us/step - loss: 0.5204 - accuracy: 0.7524\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 912us/step - loss: 0.5265 - accuracy: 0.7378\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5061 - accuracy: 0.7557\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 931us/step - loss: 0.5140 - accuracy: 0.7492\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5217 - accuracy: 0.7427\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.4994 - accuracy: 0.7524\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 927us/step - loss: 0.5178 - accuracy: 0.7329\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 988us/step - loss: 0.5078 - accuracy: 0.7296\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7573\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 941us/step - loss: 0.5158 - accuracy: 0.7476\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 927us/step - loss: 0.5147 - accuracy: 0.7541\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 949us/step - loss: 0.4885 - accuracy: 0.7524\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 941us/step - loss: 0.5098 - accuracy: 0.7394\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 952us/step - loss: 0.5197 - accuracy: 0.7313\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 951us/step - loss: 0.5149 - accuracy: 0.7541\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 988us/step - loss: 0.5122 - accuracy: 0.7476\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 877us/step - loss: 0.5118 - accuracy: 0.7459\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 832us/step - loss: 0.5146 - accuracy: 0.7508\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 928us/step - loss: 0.5216 - accuracy: 0.7313\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 926us/step - loss: 0.5022 - accuracy: 0.7508\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 864us/step - loss: 0.5232 - accuracy: 0.7362\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 921us/step - loss: 0.5273 - accuracy: 0.7378\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5166 - accuracy: 0.7459\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5160 - accuracy: 0.7248\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 958us/step - loss: 0.5095 - accuracy: 0.7394\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5264 - accuracy: 0.7264\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7606\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 986us/step - loss: 0.5112 - accuracy: 0.7345\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 969us/step - loss: 0.5149 - accuracy: 0.7541\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.4948 - accuracy: 0.7573\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 970us/step - loss: 0.5074 - accuracy: 0.7476\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 962us/step - loss: 0.5141 - accuracy: 0.7394\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 980us/step - loss: 0.5033 - accuracy: 0.7606\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 866us/step - loss: 0.5141 - accuracy: 0.7427\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 911us/step - loss: 0.5287 - accuracy: 0.7378\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 892us/step - loss: 0.5154 - accuracy: 0.7638\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 889us/step - loss: 0.5216 - accuracy: 0.7459\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 890us/step - loss: 0.5213 - accuracy: 0.7264\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5192 - accuracy: 0.7459\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 936us/step - loss: 0.5214 - accuracy: 0.7329\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 939us/step - loss: 0.5170 - accuracy: 0.7590\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5128 - accuracy: 0.7541\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 874us/step - loss: 0.5088 - accuracy: 0.7410\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 854us/step - loss: 0.4999 - accuracy: 0.7606\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5245 - accuracy: 0.7313\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5250 - accuracy: 0.7313\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.7524\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.4959 - accuracy: 0.7638\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 959us/step - loss: 0.5177 - accuracy: 0.7459\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 900us/step - loss: 0.5112 - accuracy: 0.7410\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 967us/step - loss: 0.5077 - accuracy: 0.7590\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 967us/step - loss: 0.5126 - accuracy: 0.7313\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 951us/step - loss: 0.5070 - accuracy: 0.7410\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 885us/step - loss: 0.5255 - accuracy: 0.7427\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 920us/step - loss: 0.5031 - accuracy: 0.7557\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 919us/step - loss: 0.5201 - accuracy: 0.7459\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.5039 - accuracy: 0.7655\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 853us/step - loss: 0.5093 - accuracy: 0.7508\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.5009 - accuracy: 0.7590\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 984us/step - loss: 0.5113 - accuracy: 0.7492\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 984us/step - loss: 0.5084 - accuracy: 0.7492\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 938us/step - loss: 0.5189 - accuracy: 0.7394\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 981us/step - loss: 0.5137 - accuracy: 0.7345\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 894us/step - loss: 0.5021 - accuracy: 0.7573\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 869us/step - loss: 0.5179 - accuracy: 0.7313\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 890us/step - loss: 0.5188 - accuracy: 0.7492\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 902us/step - loss: 0.5354 - accuracy: 0.7329\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 907us/step - loss: 0.4982 - accuracy: 0.7459\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 825us/step - loss: 0.5036 - accuracy: 0.7606\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 887us/step - loss: 0.5105 - accuracy: 0.7508\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 962us/step - loss: 0.5191 - accuracy: 0.7313\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 954us/step - loss: 0.5084 - accuracy: 0.7573\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 916us/step - loss: 0.5166 - accuracy: 0.7443\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 965us/step - loss: 0.5172 - accuracy: 0.7394\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 879us/step - loss: 0.5265 - accuracy: 0.7410\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 880us/step - loss: 0.5066 - accuracy: 0.7459\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 927us/step - loss: 0.5115 - accuracy: 0.7410\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 888us/step - loss: 0.5159 - accuracy: 0.7410\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.4965 - accuracy: 0.7573\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5183 - accuracy: 0.7443\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5299 - accuracy: 0.7492\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 997us/step - loss: 0.5124 - accuracy: 0.7459\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.7329\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 931us/step - loss: 0.5248 - accuracy: 0.7345\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.5043 - accuracy: 0.7573\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.5138 - accuracy: 0.7606\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 874us/step - loss: 0.5070 - accuracy: 0.7557\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 912us/step - loss: 0.5218 - accuracy: 0.7541\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 876us/step - loss: 0.5224 - accuracy: 0.7427\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 951us/step - loss: 0.5006 - accuracy: 0.7622\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 932us/step - loss: 0.5117 - accuracy: 0.7345\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.7410\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'RMSprop', loss =\"binary_crossentropy\" , metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 24, epochs = 200)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0dd440",
   "metadata": {},
   "source": [
    "### Model Effeciency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28e08995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix -\n",
      "\n",
      "[[99  8]\n",
      " [18 29]]\n",
      "\n",
      "Artificial Neural Network Accuracy - 83.12%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(f\"Confusion Matrix -\\n\\n{cm}\")\n",
    "\n",
    "accuracy=((cm[0,0]+cm[1,1])/(cm[0,1]+cm[1,1]+cm[0,0]+cm[1,0]))*100\n",
    "print(\"\\nArtificial Neural Network Accuracy - {a:.2f}%\".format(a = accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
